// Day 4: Polars ÏÜåÍ∞ú Î∞è ÎπÑÍµê
import type { Task } from '../../types'

export const day4Tasks: Task[] = [
  // Task 1: Polars ÏÜåÍ∞ú (Video)
  {
    id: 'w2d4-task1',
    title: 'Polars: Ï∞®ÏÑ∏ÎåÄ DataFrame ÎùºÏù¥Î∏åÎü¨Î¶¨',
    type: 'video',
    duration: 15,
    content: {
      videoUrl: 'https://www.youtube.com/watch?v=placeholder',
      objectives: [
        'PolarsÏùò ÌÉÑÏÉù Î∞∞Í≤Ω Ïù¥Ìï¥',
        'pandasÏôÄ PolarsÏùò ÌïµÏã¨ Ï∞®Ïù¥Ï†ê',
        'PolarsÏùò ÏïÑÌÇ§ÌÖçÏ≤ò ÌäπÏßï',
        'Ïñ∏Ï†ú PolarsÎ•º ÏÇ¨Ïö©Ìï¥Ïïº ÌïòÎäîÏßÄ ÌåêÎã®'
      ],
      transcript: `
# Polars: Ï∞®ÏÑ∏ÎåÄ DataFrame ÎùºÏù¥Î∏åÎü¨Î¶¨

## PolarsÎûÄ?

PolarsÎäî **RustÎ°ú ÏûëÏÑ±Îêú** Ï¥àÍ≥†ÏÜç DataFrame ÎùºÏù¥Î∏åÎü¨Î¶¨ÏûÖÎãàÎã§.

\`\`\`python
import polars as pl

# Polars DataFrame ÏÉùÏÑ±
df = pl.DataFrame({
    'name': ['Alice', 'Bob', 'Charlie'],
    'age': [25, 30, 35],
    'city': ['Seoul', 'Busan', 'Daegu']
})

print(df)
\`\`\`

## Ïôú PolarsÏù∏Í∞Ä?

### 1. ÏïïÎèÑÏ†ÅÏù∏ ÏÑ±Îä•
- RustÏùò Î©îÎ™®Î¶¨ ÏïàÏ†ÑÏÑ± + Ï†úÎ°úÏΩîÏä§Ìä∏ Ï∂îÏÉÅÌôî
- Î©ÄÌã∞Ïä§Î†àÎìú Í∏∞Î≥∏ ÏßÄÏõê
- SIMD Î≤°ÌÑ∞Ìôî Ïó∞ÏÇ∞
- ÏßÄÏó∞ ÌèâÍ∞Ä(Lazy Evaluation)Î°ú ÏµúÏ†ÅÌôî

### 2. Î©îÎ™®Î¶¨ Ìö®Ïú®ÏÑ±
- Apache Arrow Î©îÎ™®Î¶¨ Ìè¨Îß∑ ÏÇ¨Ïö©
- Î≥µÏÇ¨ ÏµúÏÜåÌôî
- Ïª¨Îüº Í∏∞Î∞ò Ïä§ÌÜ†Î¶¨ÏßÄ

### 3. ÏßÅÍ¥ÄÏ†ÅÏù∏ API
- pandasÏôÄ Ïú†ÏÇ¨ÌïòÎ©¥ÏÑúÎèÑ Îçî ÏùºÍ¥ÄÏÑ± ÏûàÎäî API
- Î©îÏÑúÎìú Ï≤¥Ïù¥Îãù ÏµúÏ†ÅÌôî
- Î™ÖÏãúÏ†ÅÏù∏ ÌëúÌòÑÏãù ÏãúÏä§ÌÖú

## pandas vs Polars ÌïµÏã¨ Ï∞®Ïù¥

| ÌäπÏÑ± | pandas | Polars |
|------|--------|--------|
| Ïñ∏Ïñ¥ | Python/C | Rust |
| Í∏∞Î≥∏ Ïä§Î†àÎî© | Îã®Ïùº Ïä§Î†àÎìú | Î©ÄÌã∞Ïä§Î†àÎìú |
| ÌèâÍ∞Ä Ï†ÑÎûµ | Ï¶âÏãú ÌèâÍ∞Ä | Lazy ÏßÄÏõê |
| Î©îÎ™®Î¶¨ Î™®Îç∏ | NumPy Í∏∞Î∞ò | Arrow Í∏∞Î∞ò |
| Î¨∏ÏûêÏó¥ Ï≤òÎ¶¨ | ÎäêÎ¶º (object) | Îπ†Î¶Ñ (Rust String) |
| Ïù∏Îç±Ïä§ | ÏûàÏùå | ÏóÜÏùå |

## ÏÑ±Îä• Î≤§ÏπòÎßàÌÅ¨

\`\`\`python
# 1Ïñµ Ìñâ Îç∞Ïù¥ÌÑ∞ ÏßëÍ≥Ñ ÏòàÏãú

# pandas: ~30Ï¥à
df_pandas.groupby('category')['value'].sum()

# Polars: ~2Ï¥à (15Î∞∞ Îπ†Î¶Ñ!)
df_polars.group_by('category').agg(pl.col('value').sum())
\`\`\`

## PolarsÏùò ÌïµÏã¨ Í∞úÎÖê

### 1. ÌëúÌòÑÏãù (Expression)
\`\`\`python
# Î™®Îì† Ïó∞ÏÇ∞ÏùÄ ÌëúÌòÑÏãù
pl.col('age')           # Ïª¨Îüº ÏÑ†ÌÉù
pl.col('age') + 1       # Ïó∞ÏÇ∞
pl.col('age').mean()    # ÏßëÍ≥Ñ
pl.col('name').str.to_uppercase()  # Î¨∏ÏûêÏó¥ Ï≤òÎ¶¨
\`\`\`

### 2. ÏßÄÏó∞ ÌèâÍ∞Ä (Lazy Evaluation)
\`\`\`python
# ÏøºÎ¶¨Î•º Ï†ïÏùòÌïòÍ≥† ÎßàÏßÄÎßâÏóê Ïã§Ìñâ
result = (
    df.lazy()
    .filter(pl.col('age') > 25)
    .group_by('city')
    .agg(pl.col('age').mean())
    .collect()  # Ïó¨Í∏∞ÏÑú Ïã§Ï†ú Ïã§Ìñâ!
)
\`\`\`

### 3. Ïä§Ìä∏Î¶¨Î∞ç Î™®Îìú
\`\`\`python
# Î©îÎ™®Î¶¨Î≥¥Îã§ ÌÅ∞ Îç∞Ïù¥ÌÑ∞ Ï≤òÎ¶¨
result = (
    pl.scan_csv('huge_file.csv')  # Ïä§Ï∫îÎßå (Î°úÎìú X)
    .filter(pl.col('value') > 100)
    .group_by('category')
    .agg(pl.col('value').sum())
    .collect(streaming=True)  # Ï≤≠ÌÅ¨ Îã®ÏúÑ Ï≤òÎ¶¨
)
\`\`\`

## Ïñ∏Ï†ú PolarsÎ•º ÏÇ¨Ïö©Ìï¥Ïïº Ìï†Íπå?

### ‚úÖ PolarsÍ∞Ä Ï¢ãÏùÄ Í≤ΩÏö∞
- ÎåÄÏö©Îüâ Îç∞Ïù¥ÌÑ∞ (100Îßå+ Ìñâ)
- Î≥µÏû°Ìïú ÏßëÍ≥Ñ/Î≥ÄÌôò
- Î©ÄÌã∞ÏΩîÏñ¥ ÌôúÏö© ÌïÑÏöî
- Î©îÎ™®Î¶¨ Ï†úÏïΩ ÌôòÍ≤Ω
- Ïã†Í∑ú ÌîÑÎ°úÏ†ùÌä∏

### ‚úÖ pandasÍ∞Ä Ï¢ãÏùÄ Í≤ΩÏö∞
- ÏÜåÍ∑úÎ™® Îç∞Ïù¥ÌÑ∞
- Î†àÍ±∞Ïãú ÏΩîÎìú Ìò∏Ìôò
- ÏãúÍ≥ÑÏó¥ Î∂ÑÏÑù (pandasÍ∞Ä Îçî ÏÑ±Ïàô)
- ÌíçÎ∂ÄÌïú ÏóêÏΩîÏãúÏä§ÌÖú ÌïÑÏöî
      `,
      keyPoints: [
        'PolarsÎäî Rust Í∏∞Î∞ò Í≥†ÏÑ±Îä• DataFrame ÎùºÏù¥Î∏åÎü¨Î¶¨',
        'Î©ÄÌã∞Ïä§Î†àÎìú + SIMDÎ°ú pandas ÎåÄÎπÑ 10-100Î∞∞ Îπ†Î¶Ñ',
        'Lazy EvaluationÏúºÎ°ú ÏøºÎ¶¨ ÏûêÎèô ÏµúÏ†ÅÌôî',
        'Apache Arrow Ìè¨Îß∑ÏúºÎ°ú Î©îÎ™®Î¶¨ Ìö®Ïú®Ï†Å'
      ]
    }
  },

  // Task 2: Polars Í∏∞Î≥∏ Î¨∏Î≤ï (Reading)
  {
    id: 'w2d4-task2',
    title: 'Polars Í∏∞Î≥∏ Î¨∏Î≤ï ÎßàÏä§ÌÑ∞',
    type: 'reading',
    duration: 15,
    content: {
      objectives: [
        'Polars DataFrame ÏÉùÏÑ± Î∞©Î≤ï',
        'Ïª¨Îüº ÏÑ†ÌÉùÍ≥º ÌïÑÌÑ∞ÎßÅ',
        'select()ÏôÄ with_columns() Ï∞®Ïù¥',
        'pandasÏóêÏÑú PolarsÎ°ú ÎßàÏù¥Í∑∏Î†àÏù¥ÏÖò Ìå®ÌÑ¥'
      ],
      markdown: `
# Polars Í∏∞Î≥∏ Î¨∏Î≤ï ÎßàÏä§ÌÑ∞

## ÏÑ§Ïπò

\`\`\`bash
pip install polars
# ÎòêÎäî CPU ÏµúÏ†ÅÌôî Î≤ÑÏ†Ñ
pip install polars[all]
\`\`\`

## DataFrame ÏÉùÏÑ±

\`\`\`python
import polars as pl

# ÎîïÏÖîÎÑàÎ¶¨Î°ú ÏÉùÏÑ±
df = pl.DataFrame({
    'name': ['Alice', 'Bob', 'Charlie', 'David'],
    'age': [25, 30, 35, 28],
    'salary': [50000, 60000, 70000, 55000]
})

# pandas DataFrameÏóêÏÑú Î≥ÄÌôò
import pandas as pd
df_pandas = pd.DataFrame({'a': [1, 2, 3]})
df_polars = pl.from_pandas(df_pandas)

# CSVÏóêÏÑú Î°úÎìú
df = pl.read_csv('data.csv')

# Lazy Î™®ÎìúÎ°ú Î°úÎìú (ÎåÄÏö©Îüâ Ï∂îÏ≤ú)
lf = pl.scan_csv('data.csv')
\`\`\`

## Ïª¨Îüº ÏÑ†ÌÉù (select)

pandasÏôÄ Í∞ÄÏû• Îã§Î•∏ Î∂ÄÎ∂ÑÏûÖÎãàÎã§!

\`\`\`python
# pandas Î∞©Ïãù (PolarsÏóêÏÑú ÎπÑÍ∂åÏû•)
# df['name']  # Í∞ÄÎä•ÌïòÏßÄÎßå...

# Polars Í∂åÏû• Î∞©Ïãù: select()
df.select('name')
df.select(['name', 'age'])

# ÌëúÌòÑÏãù ÏÇ¨Ïö© (Îçî Í∞ïÎ†•Ìï®)
df.select(pl.col('name'))
df.select(pl.col('name', 'age'))

# Ìå®ÌÑ¥ Îß§Ïπ≠
df.select(pl.col('^s.*$'))  # 's'Î°ú ÏãúÏûëÌïòÎäî Î™®Îì† Ïª¨Îüº
df.select(pl.all())          # Î™®Îì† Ïª¨Îüº
df.select(pl.exclude('name')) # name Ï†úÏô∏
\`\`\`

## ÌïÑÌÑ∞ÎßÅ (filter)

\`\`\`python
# Îã®Ïùº Ï°∞Í±¥
df.filter(pl.col('age') > 25)

# Î≥µÌï© Ï°∞Í±¥
df.filter(
    (pl.col('age') > 25) & (pl.col('salary') > 55000)
)

# Î¨∏ÏûêÏó¥ ÌïÑÌÑ∞
df.filter(pl.col('name').str.starts_with('A'))

# is_in ÏÇ¨Ïö©
df.filter(pl.col('name').is_in(['Alice', 'Bob']))
\`\`\`

## ÏÉà Ïª¨Îüº Ï∂îÍ∞Ä (with_columns)

\`\`\`python
# Îã®Ïùº Ïª¨Îüº Ï∂îÍ∞Ä
df.with_columns(
    (pl.col('salary') / 12).alias('monthly_salary')
)

# Ïó¨Îü¨ Ïª¨Îüº ÎèôÏãú Ï∂îÍ∞Ä
df.with_columns([
    (pl.col('salary') / 12).alias('monthly_salary'),
    (pl.col('age') + 1).alias('next_age'),
    pl.lit('KR').alias('country')  # Î¶¨ÌÑ∞Îü¥ Í∞í
])

# Ï°∞Í±¥Î∂Ä Ïª¨Îüº
df.with_columns(
    pl.when(pl.col('age') > 30)
    .then(pl.lit('Senior'))
    .otherwise(pl.lit('Junior'))
    .alias('level')
)
\`\`\`

## select() vs with_columns()

| Î©îÏÑúÎìú | Í≤∞Í≥º |
|--------|------|
| select() | ÏÑ†ÌÉùÌïú Ïª¨ÎüºÎßå Î∞òÌôò |
| with_columns() | Í∏∞Ï°¥ Ïª¨Îüº + ÏÉà Ïª¨Îüº |

\`\`\`python
# select: nameÍ≥º ÏÉà Ïª¨ÎüºÎßå Î∞òÌôò
df.select([
    pl.col('name'),
    (pl.col('salary') * 1.1).alias('raised_salary')
])

# with_columns: Î™®Îì† Ïª¨Îüº + ÏÉà Ïª¨Îüº
df.with_columns(
    (pl.col('salary') * 1.1).alias('raised_salary')
)
\`\`\`

## Ï†ïÎ†¨ (sort)

\`\`\`python
# Ïò§Î¶ÑÏ∞®Ïàú
df.sort('age')

# ÎÇ¥Î¶ºÏ∞®Ïàú
df.sort('age', descending=True)

# Ïó¨Îü¨ Ïª¨Îüº
df.sort(['age', 'salary'], descending=[True, False])
\`\`\`

## pandas ‚Üí Polars ÎßàÏù¥Í∑∏Î†àÏù¥ÏÖò

| pandas | Polars |
|--------|--------|
| df['col'] | df.select('col') |
| df[['a', 'b']] | df.select(['a', 'b']) |
| df[df['a'] > 0] | df.filter(pl.col('a') > 0) |
| df['new'] = ... | df.with_columns(...) |
| df.groupby() | df.group_by() |
| df.reset_index() | Î∂àÌïÑÏöî (Ïù∏Îç±Ïä§ ÏóÜÏùå) |
      `,
      keyPoints: [
        'select()Î°ú Ïª¨Îüº ÏÑ†ÌÉù, with_columns()Î°ú Ïª¨Îüº Ï∂îÍ∞Ä',
        'pl.col()Î°ú Ïª¨Îüº Ï∞∏Ï°∞ÌïòÎäî ÌëúÌòÑÏãù ÏÉùÏÑ±',
        'filter()Î°ú Ìñâ ÌïÑÌÑ∞ÎßÅ',
        'PolarsÎäî Ïù∏Îç±Ïä§Í∞Ä ÏóÜÏñ¥ reset_index() Î∂àÌïÑÏöî'
      ]
    }
  },

  // Task 3: Polars Ïã§Ïäµ (Code)
  {
    id: 'w2d4-task3',
    title: 'Polars Í∏∞Î≥∏ Ïó∞ÏÇ∞ Ïã§Ïäµ',
    type: 'code',
    duration: 20,
    content: {
      objectives: [
        'Polars DataFrame ÏÉùÏÑ± Î∞è Ï°∞Ïûë',
        'ÌëúÌòÑÏãù Í∏∞Î∞ò Ïª¨Îüº Ïó∞ÏÇ∞',
        'Ï°∞Í±¥Î∂Ä Î°úÏßÅ Íµ¨ÌòÑ',
        'pandas ÏΩîÎìúÎ•º PolarsÎ°ú Î≥ÄÌôò'
      ],
      starterCode: `import polars as pl
import numpy as np

# ===========================================
# Ïã§Ïäµ 1: DataFrame ÏÉùÏÑ±
# ===========================================

# ÌåêÎß§ Îç∞Ïù¥ÌÑ∞ ÏÉùÏÑ±
np.random.seed(42)
n_rows = 10000

# TODO: Polars DataFrame ÏÉùÏÑ±
# - order_id: 1Î∂ÄÌÑ∞ n_rowsÍπåÏßÄ
# - product: ['A', 'B', 'C', 'D'] Ï§ë ÎûúÎç§ ÏÑ†ÌÉù
# - quantity: 1~100 ÏÇ¨Ïù¥ Ï†ïÏàò
# - unit_price: 10.0~1000.0 ÏÇ¨Ïù¥ Ïã§Ïàò
# - discount: 0.0~0.3 ÏÇ¨Ïù¥ Ïã§Ïàò

df = None  # TODO: Íµ¨ÌòÑ

print("=== DataFrame ÏÉùÏÑ± ===")
print(df)

# ===========================================
# Ïã§Ïäµ 2: Ïª¨Îüº Ïó∞ÏÇ∞
# ===========================================

# TODO: Îã§Ïùå Ïª¨ÎüºÎì§ÏùÑ Ï∂îÍ∞ÄÌïòÏÑ∏Ïöî
# - total_price: quantity * unit_price
# - discounted_price: total_price * (1 - discount)
# - price_tier: unit_price Í∏∞Ï§ÄÏúºÎ°ú
#   - > 500: 'Premium'
#   - > 200: 'Standard'
#   - else: 'Budget'

df_with_cols = None  # TODO: Íµ¨ÌòÑ

print("\\n=== Ïª¨Îüº Ï∂îÍ∞Ä ===")
print(df_with_cols.head())

# ===========================================
# Ïã§Ïäµ 3: ÌïÑÌÑ∞ÎßÅ
# ===========================================

# TODO: Îã§Ïùå Ï°∞Í±¥ÏúºÎ°ú ÌïÑÌÑ∞ÎßÅ
# - productÍ∞Ä 'A' ÎòêÎäî 'B'
# - discounted_price > 5000
# - quantity >= 50

df_filtered = None  # TODO: Íµ¨ÌòÑ

print("\\n=== ÌïÑÌÑ∞ÎßÅ Í≤∞Í≥º ===")
print(f"ÌïÑÌÑ∞ÎßÅ ÌõÑ Ìñâ Ïàò: {len(df_filtered)}")
print(df_filtered.head())

# ===========================================
# Ïã§Ïäµ 4: Ï†ïÎ†¨
# ===========================================

# TODO: discounted_price ÎÇ¥Î¶ºÏ∞®Ïàú, quantity Ïò§Î¶ÑÏ∞®ÏàúÏúºÎ°ú Ï†ïÎ†¨

df_sorted = None  # TODO: Íµ¨ÌòÑ

print("\\n=== Ï†ïÎ†¨ Í≤∞Í≥º ===")
print(df_sorted.head(10))

# ===========================================
# Ïã§Ïäµ 5: pandas ÏΩîÎìú Î≥ÄÌôò
# ===========================================

# Îã§Ïùå pandas ÏΩîÎìúÎ•º PolarsÎ°ú Î≥ÄÌôòÌïòÏÑ∏Ïöî:
'''
import pandas as pd

# pandas ÏΩîÎìú
df_pandas = df_pandas[df_pandas['quantity'] > 30]
df_pandas['revenue'] = df_pandas['quantity'] * df_pandas['unit_price']
df_pandas = df_pandas[['product', 'revenue']]
df_pandas = df_pandas.groupby('product')['revenue'].sum().reset_index()
df_pandas = df_pandas.sort_values('revenue', ascending=False)
'''

# TODO: PolarsÎ°ú Î≥ÄÌôò
df_result = None  # TODO: Íµ¨ÌòÑ

print("\\n=== pandas ‚Üí Polars Î≥ÄÌôò Í≤∞Í≥º ===")
print(df_result)
`,
      solutionCode: `import polars as pl
import numpy as np

# ===========================================
# Ïã§Ïäµ 1: DataFrame ÏÉùÏÑ±
# ===========================================

np.random.seed(42)
n_rows = 10000

df = pl.DataFrame({
    'order_id': range(1, n_rows + 1),
    'product': np.random.choice(['A', 'B', 'C', 'D'], n_rows),
    'quantity': np.random.randint(1, 101, n_rows),
    'unit_price': np.random.uniform(10.0, 1000.0, n_rows),
    'discount': np.random.uniform(0.0, 0.3, n_rows)
})

print("=== DataFrame ÏÉùÏÑ± ===")
print(df)
print(f"\\nShape: {df.shape}")
print(f"Dtypes:\\n{df.dtypes}")

# ===========================================
# Ïã§Ïäµ 2: Ïª¨Îüº Ïó∞ÏÇ∞
# ===========================================

df_with_cols = df.with_columns([
    # total_price: quantity * unit_price
    (pl.col('quantity') * pl.col('unit_price')).alias('total_price'),

    # discounted_price: total_price * (1 - discount)
    (pl.col('quantity') * pl.col('unit_price') * (1 - pl.col('discount'))).alias('discounted_price'),

    # price_tier: Ï°∞Í±¥Î∂Ä Î∂ÑÎ•ò
    pl.when(pl.col('unit_price') > 500)
    .then(pl.lit('Premium'))
    .when(pl.col('unit_price') > 200)
    .then(pl.lit('Standard'))
    .otherwise(pl.lit('Budget'))
    .alias('price_tier')
])

print("\\n=== Ïª¨Îüº Ï∂îÍ∞Ä ===")
print(df_with_cols.head())

# ===========================================
# Ïã§Ïäµ 3: ÌïÑÌÑ∞ÎßÅ
# ===========================================

df_filtered = df_with_cols.filter(
    (pl.col('product').is_in(['A', 'B'])) &
    (pl.col('discounted_price') > 5000) &
    (pl.col('quantity') >= 50)
)

print("\\n=== ÌïÑÌÑ∞ÎßÅ Í≤∞Í≥º ===")
print(f"ÌïÑÌÑ∞ÎßÅ ÌõÑ Ìñâ Ïàò: {len(df_filtered)}")
print(df_filtered.head())

# ===========================================
# Ïã§Ïäµ 4: Ï†ïÎ†¨
# ===========================================

df_sorted = df_with_cols.sort(
    ['discounted_price', 'quantity'],
    descending=[True, False]
)

print("\\n=== Ï†ïÎ†¨ Í≤∞Í≥º ===")
print(df_sorted.head(10))

# ===========================================
# Ïã§Ïäµ 5: pandas ÏΩîÎìú Î≥ÄÌôò
# ===========================================

# ÏõêÎ≥∏ pandas ÏΩîÎìú:
# df_pandas = df_pandas[df_pandas['quantity'] > 30]
# df_pandas['revenue'] = df_pandas['quantity'] * df_pandas['unit_price']
# df_pandas = df_pandas[['product', 'revenue']]
# df_pandas = df_pandas.groupby('product')['revenue'].sum().reset_index()
# df_pandas = df_pandas.sort_values('revenue', ascending=False)

# Polars Î≥ÄÌôò (Ï≤¥Ïù¥ÎãùÏúºÎ°ú ÍπîÎÅîÌïòÍ≤å)
df_result = (
    df
    .filter(pl.col('quantity') > 30)
    .with_columns(
        (pl.col('quantity') * pl.col('unit_price')).alias('revenue')
    )
    .select(['product', 'revenue'])
    .group_by('product')
    .agg(pl.col('revenue').sum())
    .sort('revenue', descending=True)
)

print("\\n=== pandas ‚Üí Polars Î≥ÄÌôò Í≤∞Í≥º ===")
print(df_result)

# Ï∂îÍ∞Ä: Lazy Î™®ÎìúÎ°ú ÎèôÏùºÌïú ÏøºÎ¶¨
print("\\n=== Lazy Î™®Îìú ÏòàÏãú ===")
df_lazy_result = (
    df.lazy()
    .filter(pl.col('quantity') > 30)
    .with_columns(
        (pl.col('quantity') * pl.col('unit_price')).alias('revenue')
    )
    .select(['product', 'revenue'])
    .group_by('product')
    .agg(pl.col('revenue').sum())
    .sort('revenue', descending=True)
    .collect()  # Ïó¨Í∏∞ÏÑú Ïã§Ï†ú Ïã§Ìñâ
)
print(df_lazy_result)
`,
      instructions: 'PolarsÏùò Í∏∞Î≥∏ Î¨∏Î≤ïÏùÑ Ïã§ÏäµÌï©ÎãàÎã§. DataFrame ÏÉùÏÑ±, Ïª¨Îüº Ïó∞ÏÇ∞, ÌïÑÌÑ∞ÎßÅ, Ï†ïÎ†¨ÏùÑ ÏàòÌñâÌïòÍ≥†, pandas ÏΩîÎìúÎ•º PolarsÎ°ú Î≥ÄÌôòÌï©ÎãàÎã§.',
      keyPoints: [
        'pl.DataFrame()ÏúºÎ°ú DataFrame ÏÉùÏÑ±',
        'with_columns()Î°ú ÏÉà Ïª¨Îüº Ï∂îÍ∞Ä',
        'pl.when().then().otherwise()Î°ú Ï°∞Í±¥Î∂Ä Î°úÏßÅ',
        'Î©îÏÑúÎìú Ï≤¥Ïù¥ÎãùÏúºÎ°ú ÍπîÎÅîÌïú Îç∞Ïù¥ÌÑ∞ ÌååÏù¥ÌîÑÎùºÏù∏'
      ]
    }
  },

  // Task 4: Lazy Evaluation (Video)
  {
    id: 'w2d4-task4',
    title: 'Lazy EvaluationÏúºÎ°ú ÏøºÎ¶¨ ÏµúÏ†ÅÌôî',
    type: 'video',
    duration: 12,
    content: {
      videoUrl: 'https://www.youtube.com/watch?v=placeholder',
      objectives: [
        'Lazy vs Eager Ïã§ÌñâÏùò Ï∞®Ïù¥',
        'ÏøºÎ¶¨ ÏµúÏ†ÅÌôî ÏõêÎ¶¨ Ïù¥Ìï¥',
        'LazyFrame ÏÇ¨Ïö©Î≤ï',
        'Ïã§Ìñâ Í≥ÑÌöç Î∂ÑÏÑù'
      ],
      transcript: `
# Polars Lazy Evaluation

## Eager vs Lazy Ïã§Ìñâ

### Eager (Ï¶âÏãú Ïã§Ìñâ)
\`\`\`python
# pandas Î∞©Ïãù - Í∞Å Ï§ÑÎßàÎã§ Ïã§ÌñâÎê®
df = df[df['age'] > 25]        # 1. ÌïÑÌÑ∞ÎßÅ Ïã§Ìñâ
df = df[['name', 'salary']]    # 2. Ïª¨Îüº ÏÑ†ÌÉù Ïã§Ìñâ
df = df.sort_values('salary')  # 3. Ï†ïÎ†¨ Ïã§Ìñâ
\`\`\`

### Lazy (ÏßÄÏó∞ Ïã§Ìñâ)
\`\`\`python
# Polars Lazy - ÎßàÏßÄÎßâÏóê ÌïúÎ≤àÎßå Ïã§Ìñâ
result = (
    df.lazy()                           # ÏøºÎ¶¨ Í≥ÑÌöç ÏãúÏûë
    .filter(pl.col('age') > 25)         # Í≥ÑÌöçÏóê Ï∂îÍ∞Ä
    .select(['name', 'salary'])         # Í≥ÑÌöçÏóê Ï∂îÍ∞Ä
    .sort('salary')                     # Í≥ÑÌöçÏóê Ï∂îÍ∞Ä
    .collect()                          # Ïó¨Í∏∞ÏÑú ÏµúÏ†ÅÌôî ÌõÑ ÌïúÎ≤àÏóê Ïã§Ìñâ!
)
\`\`\`

## LazyÏùò Ïû•Ï†ê

### 1. ÏøºÎ¶¨ ÏµúÏ†ÅÌôî
\`\`\`python
# PolarsÍ∞Ä ÏûêÎèôÏúºÎ°ú ÏµúÏ†ÅÌôî
lf = (
    df.lazy()
    .select(['a', 'b', 'c', 'd', 'e'])  # 5Í∞ú Ïª¨Îüº ÏÑ†ÌÉù
    .filter(pl.col('a') > 10)           # a ÌïÑÌÑ∞ÎßÅ
    .select(['a', 'b'])                 # 2Í∞úÎßå ÌïÑÏöî
)

# ÏµúÏ†ÅÌôî ÌõÑ: Ï≤òÏùåÎ∂ÄÌÑ∞ a, bÎßå ÏùΩÍ≥† ÌïÑÌÑ∞ÎßÅ!
# Predicate Pushdown + Projection Pushdown
\`\`\`

### 2. Î©îÎ™®Î¶¨ Ìö®Ïú®ÏÑ±
\`\`\`python
# ÎåÄÏö©Îüâ ÌååÏùº Ï≤òÎ¶¨
result = (
    pl.scan_csv('100GB_file.csv')  # ÌååÏùº Ïä§Ï∫îÎßå (Î°úÎìú X)
    .filter(pl.col('value') > 100)
    .group_by('category')
    .agg(pl.col('value').sum())
    .collect(streaming=True)        # Ï≤≠ÌÅ¨ Îã®ÏúÑ Ï≤òÎ¶¨
)
# 100GB ÌååÏùºÎèÑ 4GB Î©îÎ™®Î¶¨Î°ú Ï≤òÎ¶¨ Í∞ÄÎä•!
\`\`\`

## LazyFrame ÏÉùÏÑ±

\`\`\`python
# Î∞©Î≤ï 1: DataFrameÏùÑ LazyÎ°ú Î≥ÄÌôò
lf = df.lazy()

# Î∞©Î≤ï 2: ÌååÏùº Ïä§Ï∫î
lf = pl.scan_csv('data.csv')
lf = pl.scan_parquet('data.parquet')

# Î∞©Î≤ï 3: ÏßÅÏ†ë ÏÉùÏÑ±
lf = pl.LazyFrame({
    'a': [1, 2, 3],
    'b': [4, 5, 6]
})
\`\`\`

## Ïã§Ìñâ Í≥ÑÌöç Î∂ÑÏÑù

\`\`\`python
# Ïã§Ìñâ Í≥ÑÌöç Î≥¥Í∏∞
lf = (
    pl.scan_csv('data.csv')
    .filter(pl.col('age') > 25)
    .select(['name', 'age'])
)

# ÏµúÏ†ÅÌôî Ï†Ñ Í≥ÑÌöç
print(lf.explain())

# ÏµúÏ†ÅÌôî ÌõÑ Í≥ÑÌöç
print(lf.explain(optimized=True))
\`\`\`

\`\`\`
# Ï∂úÎ†• ÏòàÏãú (ÏµúÏ†ÅÌôî ÌõÑ)
FILTER col("age") > 25
  CSV SCAN data.csv
    PROJECT 2/5 COLUMNS  # 5Í∞ú Ï§ë 2Í∞úÎßå ÏùΩÏùå!
\`\`\`

## ÏµúÏ†ÅÌôî Í∏∞Î≤ï

### 1. Predicate Pushdown
- ÌïÑÌÑ∞ Ï°∞Í±¥ÏùÑ Îç∞Ïù¥ÌÑ∞ ÏÜåÏä§ Í∞ÄÍπåÏù¥Î°ú Ïù¥Îèô
- Î∂àÌïÑÏöîÌïú Îç∞Ïù¥ÌÑ∞Î•º ÏùºÏ∞ç Ï†úÍ±∞

### 2. Projection Pushdown
- ÌïÑÏöîÌïú Ïª¨ÎüºÎßå ÏùΩÍ∏∞
- Î∂àÌïÑÏöîÌïú Ïª¨Îüº Î°úÎî© Î∞©ÏßÄ

### 3. ÏøºÎ¶¨ Ïû¨Ï†ïÎ†¨
- ÎπÑÏö©Ïù¥ Ï†ÅÏùÄ Ïó∞ÏÇ∞ Î®ºÏ†Ä Ïã§Ìñâ
- Îç∞Ïù¥ÌÑ∞ ÌÅ¨Í∏∞Î•º ÏµúÎåÄÌïú Îπ®Î¶¨ Ï§ÑÏûÑ

### 4. Í≥µÌÜµ Î∂ÄÎ∂ÑÏãù Ï†úÍ±∞
- Ï§ëÎ≥µ Í≥ÑÏÇ∞ Ï†úÍ±∞
- Ï∫êÏã± ÌôúÏö©
      `,
      keyPoints: [
        'LazyÎäî collect() Ìò∏Ï∂ú ÏãúÏ†êÏóê Î™®Îì† Ïó∞ÏÇ∞ Ïã§Ìñâ',
        'ÏøºÎ¶¨ ÏµúÏ†ÅÌôîÎ°ú Î∂àÌïÑÏöîÌïú Îç∞Ïù¥ÌÑ∞ Î°úÎî© Î∞©ÏßÄ',
        'scan_csv/scan_parquetÎ°ú ÎåÄÏö©Îüâ ÌååÏùº Ìö®Ïú®Ï†Å Ï≤òÎ¶¨',
        'explain()ÏúºÎ°ú Ïã§Ìñâ Í≥ÑÌöç Î∂ÑÏÑù Í∞ÄÎä•'
      ]
    }
  },

  // Task 5: Group By & Aggregation (Reading)
  {
    id: 'w2d4-task5',
    title: 'Polars ÏßëÍ≥Ñ Ïó∞ÏÇ∞ ÎßàÏä§ÌÑ∞',
    type: 'reading',
    duration: 12,
    content: {
      objectives: [
        'group_by() ÏÇ¨Ïö©Î≤ï',
        'Îã§ÏñëÌïú ÏßëÍ≥Ñ Ìï®Ïàò ÌôúÏö©',
        'ÏúàÎèÑÏö∞ Ìï®Ïàò Ïù¥Ìï¥',
        'pandas groupbyÏôÄ ÎπÑÍµê'
      ],
      markdown: `
# Polars ÏßëÍ≥Ñ Ïó∞ÏÇ∞ ÎßàÏä§ÌÑ∞

## Í∏∞Î≥∏ group_by

\`\`\`python
import polars as pl

df = pl.DataFrame({
    'category': ['A', 'A', 'B', 'B', 'C'],
    'product': ['p1', 'p2', 'p1', 'p2', 'p1'],
    'sales': [100, 150, 200, 120, 80]
})

# Í∏∞Î≥∏ ÏßëÍ≥Ñ
result = df.group_by('category').agg(
    pl.col('sales').sum()
)
\`\`\`

## Îã§Ï§ë ÏßëÍ≥Ñ

\`\`\`python
# Ïó¨Îü¨ ÏßëÍ≥ÑÎ•º ÎèôÏãúÏóê
result = df.group_by('category').agg([
    pl.col('sales').sum().alias('total_sales'),
    pl.col('sales').mean().alias('avg_sales'),
    pl.col('sales').max().alias('max_sales'),
    pl.col('sales').min().alias('min_sales'),
    pl.col('sales').count().alias('count')
])
\`\`\`

## Îã§Ï§ë Ïª¨Îüº Í∑∏Î£πÌôî

\`\`\`python
result = df.group_by(['category', 'product']).agg([
    pl.col('sales').sum().alias('total'),
    pl.col('sales').count().alias('count')
])
\`\`\`

## ÏßëÍ≥Ñ Ìï®Ïàò Î™©Î°ù

\`\`\`python
pl.col('x').sum()        # Ìï©Í≥Ñ
pl.col('x').mean()       # ÌèâÍ∑†
pl.col('x').median()     # Ï§ëÏïôÍ∞í
pl.col('x').std()        # ÌëúÏ§ÄÌé∏Ï∞®
pl.col('x').var()        # Î∂ÑÏÇ∞
pl.col('x').min()        # ÏµúÏÜüÍ∞í
pl.col('x').max()        # ÏµúÎåìÍ∞í
pl.col('x').first()      # Ï≤´ Î≤àÏß∏ Í∞í
pl.col('x').last()       # ÎßàÏßÄÎßâ Í∞í
pl.col('x').count()      # Í∞úÏàò
pl.col('x').n_unique()   # Í≥†Ïú†Í∞í Í∞úÏàò
pl.col('x').quantile(0.5) # Î∂ÑÏúÑÏàò
\`\`\`

## Ï°∞Í±¥Î∂Ä ÏßëÍ≥Ñ

\`\`\`python
result = df.group_by('category').agg([
    # Ï†ÑÏ≤¥ Ìï©Í≥Ñ
    pl.col('sales').sum().alias('total'),

    # Ï°∞Í±¥Î∂Ä Ìï©Í≥Ñ (sales > 100Ïù∏ Í≤ÉÎßå)
    pl.col('sales').filter(pl.col('sales') > 100).sum().alias('high_sales'),

    # Ï°∞Í±¥Î∂Ä Ïπ¥Ïö¥Ìä∏
    pl.col('sales').filter(pl.col('sales') > 100).count().alias('high_count')
])
\`\`\`

## ÏúàÎèÑÏö∞ Ìï®Ïàò (Window Functions)

SQLÏùò ÏúàÎèÑÏö∞ Ìï®ÏàòÏôÄ Ïú†ÏÇ¨Ìï©ÎãàÎã§.

\`\`\`python
# Í∑∏Î£πÎ≥Ñ ÏàúÏúÑ
df.with_columns(
    pl.col('sales').rank().over('category').alias('rank_in_category')
)

# Í∑∏Î£πÎ≥Ñ ÎàÑÏ†ÅÌï©
df.with_columns(
    pl.col('sales').cum_sum().over('category').alias('cumsum')
)

# Í∑∏Î£πÎ≥Ñ Ïù¥ÎèôÌèâÍ∑†
df.with_columns(
    pl.col('sales').rolling_mean(window_size=2).over('category').alias('rolling_avg')
)

# Í∑∏Î£πÎ≥Ñ shift
df.with_columns(
    pl.col('sales').shift(1).over('category').alias('prev_sales')
)
\`\`\`

## pandas groupby vs Polars group_by

| Í∏∞Îä• | pandas | Polars |
|------|--------|--------|
| Í∏∞Î≥∏ Î¨∏Î≤ï | df.groupby('col') | df.group_by('col') |
| ÏßëÍ≥Ñ | .agg({'col': 'sum'}) | .agg(pl.col('col').sum()) |
| Í≤∞Í≥º ÌòïÌÉú | Ïù∏Îç±Ïä§ Ìè¨Ìï® | ÏùºÎ∞ò DataFrame |
| Î©ÄÌã∞ ÏßëÍ≥Ñ | ÎîïÏÖîÎÑàÎ¶¨/Î¶¨Ïä§Ìä∏ | ÌëúÌòÑÏãù Î¶¨Ïä§Ìä∏ |
| Ï†ïÎ†¨ | ÏûêÎèô Ï†ïÎ†¨ | Ï†ïÎ†¨ ÏóÜÏùå (maintain_order=TrueÎ°ú ÏÑ§Ï†ï Í∞ÄÎä•) |

\`\`\`python
# pandas
df_pd.groupby('category').agg({'sales': ['sum', 'mean']})

# Polars
df.group_by('category').agg([
    pl.col('sales').sum().alias('sales_sum'),
    pl.col('sales').mean().alias('sales_mean')
])
\`\`\`
      `,
      keyPoints: [
        'group_by().agg()Î°ú ÏßëÍ≥Ñ ÏàòÌñâ',
        'ÌëúÌòÑÏãùÏúºÎ°ú Îã§ÏñëÌïú ÏßëÍ≥Ñ Ìï®Ïàò Ï°∞Ìï© Í∞ÄÎä•',
        'over()Î°ú ÏúàÎèÑÏö∞ Ìï®Ïàò Íµ¨ÌòÑ',
        'pandasÏôÄ Îã¨Î¶¨ Í≤∞Í≥ºÏóê Ïù∏Îç±Ïä§ ÏóÜÏùå'
      ]
    }
  },

  // Task 6: ÏÑ±Îä• ÎπÑÍµê Ïã§Ïäµ (Code)
  {
    id: 'w2d4-task6',
    title: 'pandas vs Polars ÏÑ±Îä• ÎπÑÍµê',
    type: 'code',
    duration: 20,
    content: {
      objectives: [
        'ÎèôÏùº ÏûëÏóÖÏùò pandas/Polars ÏÑ±Îä• ÎπÑÍµê',
        'ÎåÄÏö©Îüâ Îç∞Ïù¥ÌÑ∞ÏóêÏÑúÏùò Ï∞®Ïù¥ Ï≤¥Ìóò',
        'Lazy Evaluation Ìö®Í≥º Ï∏°Ï†ï',
        'Ïã§Î¨¥ Ï†ÅÏö© ÌåêÎã® Í∏∞Ï§Ä ÌôïÎ¶Ω'
      ],
      starterCode: `import pandas as pd
import polars as pl
import numpy as np
import time

# ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞ ÏÉùÏÑ±
np.random.seed(42)
n_rows = 1_000_000  # 100Îßå Ìñâ

print(f"ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞ ÌÅ¨Í∏∞: {n_rows:,} Ìñâ")

# pandas DataFrame
data = {
    'category': np.random.choice(['A', 'B', 'C', 'D', 'E'], n_rows),
    'sub_category': np.random.choice(['X', 'Y', 'Z'], n_rows),
    'value1': np.random.randn(n_rows),
    'value2': np.random.randn(n_rows) * 100,
    'quantity': np.random.randint(1, 100, n_rows),
    'price': np.random.uniform(10, 1000, n_rows)
}

df_pandas = pd.DataFrame(data)
df_polars = pl.DataFrame(data)

print(f"pandas Î©îÎ™®Î¶¨: {df_pandas.memory_usage(deep=True).sum() / 1024**2:.2f} MB")
print(f"Polars Î©îÎ™®Î¶¨: {df_polars.estimated_size() / 1024**2:.2f} MB")

# ===========================================
# Î≤§ÏπòÎßàÌÅ¨ 1: ÌïÑÌÑ∞ÎßÅ
# ===========================================

def benchmark_filter():
    """ÌïÑÌÑ∞ÎßÅ ÏÑ±Îä• ÎπÑÍµê"""
    # TODO: pandas ÌïÑÌÑ∞ÎßÅ
    # Ï°∞Í±¥: (category == 'A') & (value1 > 0) & (quantity >= 50)

    # TODO: Polars ÌïÑÌÑ∞ÎßÅ

    # TODO: ÏãúÍ∞Ñ Ï∏°Ï†ï Î∞è ÎπÑÍµê
    pass

# ===========================================
# Î≤§ÏπòÎßàÌÅ¨ 2: Ïª¨Îüº Ïó∞ÏÇ∞
# ===========================================

def benchmark_column_ops():
    """Ïª¨Îüº Ïó∞ÏÇ∞ ÏÑ±Îä• ÎπÑÍµê"""
    # TODO: pandasÎ°ú ÏÉà Ïª¨Îüº ÏÉùÏÑ±
    # - total = quantity * price
    # - adjusted = value1 * value2
    # - ratio = total / adjusted (adjusted != 0 Ï°∞Í±¥)

    # TODO: PolarsÎ°ú ÎèôÏùºÌïú Ïó∞ÏÇ∞

    # TODO: ÏãúÍ∞Ñ Ï∏°Ï†ï Î∞è ÎπÑÍµê
    pass

# ===========================================
# Î≤§ÏπòÎßàÌÅ¨ 3: Í∑∏Î£π ÏßëÍ≥Ñ
# ===========================================

def benchmark_groupby():
    """Í∑∏Î£π ÏßëÍ≥Ñ ÏÑ±Îä• ÎπÑÍµê"""
    # TODO: pandas groupby
    # category, sub_categoryÎ≥ÑÎ°ú:
    # - value1 Ìï©Í≥Ñ, ÌèâÍ∑†
    # - quantity Ìï©Í≥Ñ
    # - price ÌèâÍ∑†

    # TODO: Polars group_by

    # TODO: ÏãúÍ∞Ñ Ï∏°Ï†ï Î∞è ÎπÑÍµê
    pass

# ===========================================
# Î≤§ÏπòÎßàÌÅ¨ 4: Î≥µÌï© ÌååÏù¥ÌîÑÎùºÏù∏
# ===========================================

def benchmark_pipeline():
    """Î≥µÌï© ÌååÏù¥ÌîÑÎùºÏù∏ ÏÑ±Îä• ÎπÑÍµê"""
    # TODO: ÏïÑÎûò ÌååÏù¥ÌîÑÎùºÏù∏ÏùÑ pandasÏôÄ PolarsÎ°ú Íµ¨ÌòÑ
    # 1. quantity > 30 ÌïÑÌÑ∞ÎßÅ
    # 2. ÏÉà Ïª¨Îüº revenue = quantity * price Ï∂îÍ∞Ä
    # 3. category, sub_category Í∑∏Î£πÎ≥Ñ revenue Ìï©Í≥Ñ
    # 4. revenue ÎÇ¥Î¶ºÏ∞®Ïàú Ï†ïÎ†¨
    # 5. ÏÉÅÏúÑ 10Í∞ú Î∞òÌôò

    # TODO: Polars Lazy Î™®ÎìúÎ°úÎèÑ ÌÖåÏä§Ìä∏
    pass

# ===========================================
# Í≤∞Í≥º ÏöîÏïΩ
# ===========================================

def run_all_benchmarks():
    """Î™®Îì† Î≤§ÏπòÎßàÌÅ¨ Ïã§Ìñâ"""
    print("\\n" + "=" * 50)
    print("pandas vs Polars ÏÑ±Îä• ÎπÑÍµê")
    print("=" * 50)

    # TODO: Î™®Îì† Î≤§ÏπòÎßàÌÅ¨ Ïã§Ìñâ Î∞è Í≤∞Í≥º Ï†ïÎ¶¨

    print("\\nÎ≤§ÏπòÎßàÌÅ¨ ÏôÑÎ£å!")

# Ïã§Ìñâ
if __name__ == "__main__":
    run_all_benchmarks()
`,
      solutionCode: `import pandas as pd
import polars as pl
import numpy as np
import time

# ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞ ÏÉùÏÑ±
np.random.seed(42)
n_rows = 1_000_000  # 100Îßå Ìñâ

print(f"ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞ ÌÅ¨Í∏∞: {n_rows:,} Ìñâ")

data = {
    'category': np.random.choice(['A', 'B', 'C', 'D', 'E'], n_rows),
    'sub_category': np.random.choice(['X', 'Y', 'Z'], n_rows),
    'value1': np.random.randn(n_rows),
    'value2': np.random.randn(n_rows) * 100,
    'quantity': np.random.randint(1, 100, n_rows),
    'price': np.random.uniform(10, 1000, n_rows)
}

df_pandas = pd.DataFrame(data)
df_polars = pl.DataFrame(data)

print(f"pandas Î©îÎ™®Î¶¨: {df_pandas.memory_usage(deep=True).sum() / 1024**2:.2f} MB")
print(f"Polars Î©îÎ™®Î¶¨: {df_polars.estimated_size() / 1024**2:.2f} MB")

# ===========================================
# Î≤§ÏπòÎßàÌÅ¨ 1: ÌïÑÌÑ∞ÎßÅ
# ===========================================

def benchmark_filter():
    """ÌïÑÌÑ∞ÎßÅ ÏÑ±Îä• ÎπÑÍµê"""
    results = {}

    # pandas
    start = time.time()
    result_pd = df_pandas[
        (df_pandas['category'] == 'A') &
        (df_pandas['value1'] > 0) &
        (df_pandas['quantity'] >= 50)
    ]
    results['pandas'] = time.time() - start

    # Polars
    start = time.time()
    result_pl = df_polars.filter(
        (pl.col('category') == 'A') &
        (pl.col('value1') > 0) &
        (pl.col('quantity') >= 50)
    )
    results['polars'] = time.time() - start

    print("\\n[Î≤§ÏπòÎßàÌÅ¨ 1: ÌïÑÌÑ∞ÎßÅ]")
    print(f"  pandas: {results['pandas']:.4f}Ï¥à ({len(result_pd):,} Ìñâ)")
    print(f"  Polars: {results['polars']:.4f}Ï¥à ({len(result_pl):,} Ìñâ)")
    print(f"  ÏÜçÎèÑ Ìñ•ÏÉÅ: {results['pandas']/results['polars']:.1f}Î∞∞")

    return results

# ===========================================
# Î≤§ÏπòÎßàÌÅ¨ 2: Ïª¨Îüº Ïó∞ÏÇ∞
# ===========================================

def benchmark_column_ops():
    """Ïª¨Îüº Ïó∞ÏÇ∞ ÏÑ±Îä• ÎπÑÍµê"""
    results = {}

    # pandas
    start = time.time()
    df_pd = df_pandas.copy()
    df_pd['total'] = df_pd['quantity'] * df_pd['price']
    df_pd['adjusted'] = df_pd['value1'] * df_pd['value2']
    df_pd['ratio'] = np.where(df_pd['adjusted'] != 0,
                               df_pd['total'] / df_pd['adjusted'], 0)
    results['pandas'] = time.time() - start

    # Polars
    start = time.time()
    df_pl = df_polars.with_columns([
        (pl.col('quantity') * pl.col('price')).alias('total'),
        (pl.col('value1') * pl.col('value2')).alias('adjusted'),
        pl.when(pl.col('value1') * pl.col('value2') != 0)
        .then(
            (pl.col('quantity') * pl.col('price')) /
            (pl.col('value1') * pl.col('value2'))
        )
        .otherwise(0)
        .alias('ratio')
    ])
    results['polars'] = time.time() - start

    print("\\n[Î≤§ÏπòÎßàÌÅ¨ 2: Ïª¨Îüº Ïó∞ÏÇ∞]")
    print(f"  pandas: {results['pandas']:.4f}Ï¥à")
    print(f"  Polars: {results['polars']:.4f}Ï¥à")
    print(f"  ÏÜçÎèÑ Ìñ•ÏÉÅ: {results['pandas']/results['polars']:.1f}Î∞∞")

    return results

# ===========================================
# Î≤§ÏπòÎßàÌÅ¨ 3: Í∑∏Î£π ÏßëÍ≥Ñ
# ===========================================

def benchmark_groupby():
    """Í∑∏Î£π ÏßëÍ≥Ñ ÏÑ±Îä• ÎπÑÍµê"""
    results = {}

    # pandas
    start = time.time()
    result_pd = df_pandas.groupby(['category', 'sub_category']).agg({
        'value1': ['sum', 'mean'],
        'quantity': 'sum',
        'price': 'mean'
    }).reset_index()
    results['pandas'] = time.time() - start

    # Polars
    start = time.time()
    result_pl = df_polars.group_by(['category', 'sub_category']).agg([
        pl.col('value1').sum().alias('value1_sum'),
        pl.col('value1').mean().alias('value1_mean'),
        pl.col('quantity').sum().alias('quantity_sum'),
        pl.col('price').mean().alias('price_mean')
    ])
    results['polars'] = time.time() - start

    print("\\n[Î≤§ÏπòÎßàÌÅ¨ 3: Í∑∏Î£π ÏßëÍ≥Ñ]")
    print(f"  pandas: {results['pandas']:.4f}Ï¥à")
    print(f"  Polars: {results['polars']:.4f}Ï¥à")
    print(f"  ÏÜçÎèÑ Ìñ•ÏÉÅ: {results['pandas']/results['polars']:.1f}Î∞∞")

    return results

# ===========================================
# Î≤§ÏπòÎßàÌÅ¨ 4: Î≥µÌï© ÌååÏù¥ÌîÑÎùºÏù∏
# ===========================================

def benchmark_pipeline():
    """Î≥µÌï© ÌååÏù¥ÌîÑÎùºÏù∏ ÏÑ±Îä• ÎπÑÍµê"""
    results = {}

    # pandas
    start = time.time()
    result_pd = (
        df_pandas[df_pandas['quantity'] > 30]
        .assign(revenue=lambda x: x['quantity'] * x['price'])
        .groupby(['category', 'sub_category'])['revenue']
        .sum()
        .reset_index()
        .sort_values('revenue', ascending=False)
        .head(10)
    )
    results['pandas'] = time.time() - start

    # Polars Eager
    start = time.time()
    result_pl = (
        df_polars
        .filter(pl.col('quantity') > 30)
        .with_columns(
            (pl.col('quantity') * pl.col('price')).alias('revenue')
        )
        .group_by(['category', 'sub_category'])
        .agg(pl.col('revenue').sum())
        .sort('revenue', descending=True)
        .head(10)
    )
    results['polars_eager'] = time.time() - start

    # Polars Lazy
    start = time.time()
    result_lazy = (
        df_polars.lazy()
        .filter(pl.col('quantity') > 30)
        .with_columns(
            (pl.col('quantity') * pl.col('price')).alias('revenue')
        )
        .group_by(['category', 'sub_category'])
        .agg(pl.col('revenue').sum())
        .sort('revenue', descending=True)
        .head(10)
        .collect()
    )
    results['polars_lazy'] = time.time() - start

    print("\\n[Î≤§ÏπòÎßàÌÅ¨ 4: Î≥µÌï© ÌååÏù¥ÌîÑÎùºÏù∏]")
    print(f"  pandas:       {results['pandas']:.4f}Ï¥à")
    print(f"  Polars Eager: {results['polars_eager']:.4f}Ï¥à")
    print(f"  Polars Lazy:  {results['polars_lazy']:.4f}Ï¥à")
    print(f"  ÏÜçÎèÑ Ìñ•ÏÉÅ (Eager): {results['pandas']/results['polars_eager']:.1f}Î∞∞")
    print(f"  ÏÜçÎèÑ Ìñ•ÏÉÅ (Lazy):  {results['pandas']/results['polars_lazy']:.1f}Î∞∞")

    return results

# ===========================================
# Í≤∞Í≥º ÏöîÏïΩ
# ===========================================

def run_all_benchmarks():
    """Î™®Îì† Î≤§ÏπòÎßàÌÅ¨ Ïã§Ìñâ"""
    print("\\n" + "=" * 50)
    print("pandas vs Polars ÏÑ±Îä• ÎπÑÍµê")
    print("=" * 50)

    r1 = benchmark_filter()
    r2 = benchmark_column_ops()
    r3 = benchmark_groupby()
    r4 = benchmark_pipeline()

    # ÌèâÍ∑† ÏÜçÎèÑ Ìñ•ÏÉÅ
    avg_speedup = np.mean([
        r1['pandas']/r1['polars'],
        r2['pandas']/r2['polars'],
        r3['pandas']/r3['polars'],
        r4['pandas']/r4['polars_lazy']
    ])

    print("\\n" + "=" * 50)
    print(f"ÌèâÍ∑† ÏÜçÎèÑ Ìñ•ÏÉÅ: {avg_speedup:.1f}Î∞∞")
    print("=" * 50)

if __name__ == "__main__":
    run_all_benchmarks()
`,
      instructions: 'pandasÏôÄ PolarsÏùò ÏÑ±Îä•ÏùÑ ÏßÅÏ†ë ÎπÑÍµêÌï©ÎãàÎã§. ÌïÑÌÑ∞ÎßÅ, Ïª¨Îüº Ïó∞ÏÇ∞, Í∑∏Î£π ÏßëÍ≥Ñ, Î≥µÌï© ÌååÏù¥ÌîÑÎùºÏù∏ÏóêÏÑúÏùò ÏÑ±Îä• Ï∞®Ïù¥Î•º Ï∏°Ï†ïÌï©ÎãàÎã§.',
      keyPoints: [
        'PolarsÎäî ÎåÄÏö©Îüâ Îç∞Ïù¥ÌÑ∞ÏóêÏÑú pandas ÎåÄÎπÑ 5-20Î∞∞ Îπ†Î¶Ñ',
        'Lazy Î™®ÎìúÍ∞Ä Eager Î™®ÎìúÎ≥¥Îã§ Îçî Îπ†Î•∏ Í≤ΩÏö∞Í∞Ä ÎßéÏùå',
        'Î©îÎ™®Î¶¨ ÏÇ¨Ïö©ÎüâÎèÑ PolarsÍ∞Ä Îçî Ìö®Ïú®Ï†Å',
        'Ï≤¥Ïù¥Îãù Íµ¨Î¨∏Ïù¥ Îçî ÍπîÎÅîÌïòÍ≥† ÏµúÏ†ÅÌôîÏóê Ïú†Î¶¨'
      ]
    }
  },

  // Task 7: pandas-Polars ÏÉÅÌò∏Ïö¥Ïö© (Reading)
  {
    id: 'w2d4-task7',
    title: 'pandas-Polars ÏÉÅÌò∏Ïö¥Ïö©ÏÑ±',
    type: 'reading',
    duration: 10,
    content: {
      objectives: [
        'pandas ‚Üî Polars Î≥ÄÌôò Î∞©Î≤ï',
        'Í∏∞Ï°¥ pandas ÏΩîÎìú Ï†êÏßÑÏ†Å ÎßàÏù¥Í∑∏Î†àÏù¥ÏÖò',
        'NumPy Î∞∞Ïó¥Í≥ºÏùò Ìò∏ÌôòÏÑ±',
        'ÌååÏùº I/O Ìò∏ÌôòÏÑ±'
      ],
      markdown: `
# pandas-Polars ÏÉÅÌò∏Ïö¥Ïö©ÏÑ±

Ïã§Î¨¥ÏóêÏÑúÎäî Í∏∞Ï°¥ pandas ÏΩîÎìúÏôÄ Ìï®Íªò PolarsÎ•º ÏÇ¨Ïö©ÌïòÎäî Í≤ΩÏö∞Í∞Ä ÎßéÏäµÎãàÎã§.

## DataFrame Î≥ÄÌôò

### pandas ‚Üí Polars
\`\`\`python
import pandas as pd
import polars as pl

# pandas DataFrame
df_pandas = pd.DataFrame({
    'a': [1, 2, 3],
    'b': ['x', 'y', 'z']
})

# PolarsÎ°ú Î≥ÄÌôò
df_polars = pl.from_pandas(df_pandas)

# ÎòêÎäî
df_polars = pl.DataFrame(df_pandas)
\`\`\`

### Polars ‚Üí pandas
\`\`\`python
# Polars DataFrame
df_polars = pl.DataFrame({
    'a': [1, 2, 3],
    'b': ['x', 'y', 'z']
})

# pandasÎ°ú Î≥ÄÌôò
df_pandas = df_polars.to_pandas()
\`\`\`

## Series Î≥ÄÌôò

\`\`\`python
# pandas Series ‚Üí Polars Series
s_pandas = pd.Series([1, 2, 3], name='numbers')
s_polars = pl.from_pandas(s_pandas)

# Polars Series ‚Üí pandas Series
s_pandas = s_polars.to_pandas()
\`\`\`

## NumPy Î∞∞Ïó¥ Ìò∏Ìôò

\`\`\`python
import numpy as np

# NumPy ‚Üí Polars
arr = np.array([1, 2, 3, 4, 5])
s_polars = pl.Series('values', arr)

# Polars ‚Üí NumPy
arr = s_polars.to_numpy()

# DataFrame Ï†ÑÏ≤¥Î•º NumPyÎ°ú
arr_2d = df_polars.to_numpy()
\`\`\`

## ÌååÏùº I/O Ìò∏Ìôò

PolarsÏôÄ pandas Î™®Îëê ÎèôÏùºÌïú ÌååÏùº ÌòïÏãùÏùÑ ÏßÄÏõêÌï©ÎãàÎã§.

### CSV
\`\`\`python
# pandas ÏûëÏÑ± ‚Üí Polars ÏùΩÍ∏∞
df_pandas.to_csv('data.csv', index=False)
df_polars = pl.read_csv('data.csv')

# Polars ÏûëÏÑ± ‚Üí pandas ÏùΩÍ∏∞
df_polars.write_csv('data.csv')
df_pandas = pd.read_csv('data.csv')
\`\`\`

### Parquet (Í∂åÏû•)
\`\`\`python
# pandas ÏûëÏÑ± ‚Üí Polars ÏùΩÍ∏∞
df_pandas.to_parquet('data.parquet')
df_polars = pl.read_parquet('data.parquet')

# Polars ÏûëÏÑ± ‚Üí pandas ÏùΩÍ∏∞
df_polars.write_parquet('data.parquet')
df_pandas = pd.read_parquet('data.parquet')
\`\`\`

## Ï†êÏßÑÏ†Å ÎßàÏù¥Í∑∏Î†àÏù¥ÏÖò Ï†ÑÎûµ

### 1. Î≥ëÎ™© ÏßÄÏ†êÎ∂ÄÌÑ∞ ÏãúÏûë
\`\`\`python
# Í∏∞Ï°¥ pandas ÏΩîÎìú
def process_data(df_pandas):
    # Ï†ÑÏ≤òÎ¶¨ (pandas Ïú†ÏßÄ)
    df = df_pandas.dropna()

    # Î¨¥Í±∞Ïö¥ ÏßëÍ≥Ñ (PolarsÎ°ú Ï†ÑÌôò)
    df_polars = pl.from_pandas(df)
    result_polars = (
        df_polars
        .group_by('category')
        .agg(pl.col('value').sum())
    )
    result_pandas = result_polars.to_pandas()

    # ÌõÑÏ≤òÎ¶¨ (pandas Ïú†ÏßÄ)
    return result_pandas.merge(other_df, on='category')
\`\`\`

### 2. ÏÉà Í∏∞Îä•ÏùÄ PolarsÎ°ú
\`\`\`python
# Í∏∞Ï°¥ ÏΩîÎìú: pandas Ïú†ÏßÄ
# ÏÉà Í∏∞Îä•: PolarsÎ°ú ÏûëÏÑ±
# Ïù∏ÌÑ∞ÌéòÏù¥Ïä§: pandas DataFrame ÏûÖÏ∂úÎ†•
def new_feature(df_pandas):
    df = pl.from_pandas(df_pandas)
    # Polars Î°úÏßÅ...
    return result.to_pandas()
\`\`\`

### 3. ÌÖåÏä§Ìä∏ Ï∂îÍ∞Ä ÌõÑ Ï†ÑÌôò
\`\`\`python
def test_equivalence():
    # pandas Í≤∞Í≥º
    result_pd = pandas_function(df)

    # Polars Í≤∞Í≥º
    result_pl = polars_function(pl.from_pandas(df)).to_pandas()

    # Í≤∞Í≥º ÎπÑÍµê
    pd.testing.assert_frame_equal(result_pd, result_pl)
\`\`\`

## Ï£ºÏùòÏÇ¨Ìï≠

### ÌÉÄÏûÖ Ï∞®Ïù¥
| pandas | Polars | ÎπÑÍ≥† |
|--------|--------|------|
| object | Utf8 | Î¨∏ÏûêÏó¥ |
| datetime64[ns] | Datetime | ÏãúÍ∞ÑÎåÄ Ï≤òÎ¶¨ Îã§Î¶Ñ |
| category | Categorical | Í±∞Ïùò ÎèôÏùº |
| Int64 (nullable) | Int64 | PolarsÎäî Í∏∞Î≥∏ nullable |

### Ïù∏Îç±Ïä§
\`\`\`python
# pandas Ïù∏Îç±Ïä§Îäî Î≥ÄÌôò Ïãú ÏÇ¨ÎùºÏßê
df_pandas = df_pandas.reset_index()  # Ïù∏Îç±Ïä§Î•º Ïª¨ÎüºÏúºÎ°ú Î≥ÄÌôò
df_polars = pl.from_pandas(df_pandas)
\`\`\`
      `,
      keyPoints: [
        'pl.from_pandas(), to_pandas()Î°ú ÏâΩÍ≤å Î≥ÄÌôò',
        'Parquet ÌòïÏãùÏúºÎ°ú ÌååÏùº Ìò∏ÌôòÏÑ± ÌôïÎ≥¥',
        'Î≥ëÎ™© ÏßÄÏ†êÎ∂ÄÌÑ∞ Ï†êÏßÑÏ†Å ÎßàÏù¥Í∑∏Î†àÏù¥ÏÖò',
        'pandas Ïù∏Îç±Ïä§Îäî reset_index() ÌõÑ Î≥ÄÌôò'
      ]
    }
  },

  // Task 8: Polars Ï¢ÖÌï© ÌÄ¥Ï¶à
  {
    id: 'w2d4-task8',
    title: 'Polars Ï¢ÖÌï© ÌÄ¥Ï¶à',
    type: 'quiz',
    duration: 8,
    content: {
      objectives: [
        'Polars ÌïµÏã¨ Í∞úÎÖê Ï†êÍ≤Ä',
        'pandas-Polars Ï∞®Ïù¥ Ïù¥Ìï¥ ÌôïÏù∏',
        'Lazy Evaluation Ïù¥Ìï¥ ÌôïÏù∏',
        'Ïã§Î¨¥ Ï†ÅÏö© ÌåêÎã®Î†• Ï†êÍ≤Ä'
      ],
      questions: [
        {
          question: 'PolarsÍ∞Ä pandasÎ≥¥Îã§ Îπ†Î•∏ Ï£ºÎêú Ïù¥Ïú†Îäî?',
          options: [
            'PythonÏúºÎ°ú ÏûëÏÑ±ÎêòÏñ¥ ÏµúÏ†ÅÌôîÍ∞Ä Ïûò Îê®',
            'RustÎ°ú ÏûëÏÑ±ÎêòÏñ¥ GIL Ï†úÏïΩÏù¥ ÏóÜÍ≥† Î©ÄÌã∞Ïä§Î†àÎìú ÏßÄÏõê',
            'Îçî Ï†ÅÏùÄ Í∏∞Îä•ÏùÑ Ï†úÍ≥µÌïòÏó¨ Îã®ÏàúÌï®',
            'ÌÅ¥ÎùºÏö∞Îìú Ïª¥Ìì®ÌåÖÏóê ÏµúÏ†ÅÌôîÎê®'
          ],
          answer: 1,
          explanation: 'PolarsÎäî RustÎ°ú ÏûëÏÑ±ÎêòÏñ¥ PythonÏùò GIL Ï†úÏïΩÏù¥ ÏóÜÍ≥†, Í∏∞Î≥∏Ï†ÅÏúºÎ°ú Î©ÄÌã∞Ïä§Î†àÎìúÎ•º ÌôúÏö©Ìï©ÎãàÎã§. ÎòêÌïú SIMD Î≤°ÌÑ∞ÌôîÏôÄ ÏøºÎ¶¨ ÏµúÏ†ÅÌôîÎ•º ÌÜµÌï¥ ÎÜíÏùÄ ÏÑ±Îä•ÏùÑ Îã¨ÏÑ±Ìï©ÎãàÎã§.'
        },
        {
          question: 'PolarsÏóêÏÑú ÏÉà Ïª¨ÎüºÏùÑ Ï∂îÍ∞ÄÌïòÎ©¥ÏÑú Í∏∞Ï°¥ Ïª¨ÎüºÏùÑ Ïú†ÏßÄÌïòÎ†§Î©¥?',
          options: [
            'df.select()',
            'df.with_columns()',
            'df.filter()',
            'df.append()'
          ],
          answer: 1,
          explanation: 'with_columns()Îäî Í∏∞Ï°¥ DataFrameÏóê ÏÉà Ïª¨ÎüºÏùÑ Ï∂îÍ∞ÄÌïòÍ≥† Í∏∞Ï°¥ Ïª¨ÎüºÏùÄ Í∑∏ÎåÄÎ°ú Ïú†ÏßÄÌï©ÎãàÎã§. select()Îäî Î™ÖÏãúÌïú Ïª¨ÎüºÎßå Î∞òÌôòÌï©ÎãàÎã§.'
        },
        {
          question: 'Polars Lazy EvaluationÏùò Ïû•Ï†êÏù¥ ÏïÑÎãå Í≤ÉÏùÄ?',
          options: [
            'ÏøºÎ¶¨ ÏûêÎèô ÏµúÏ†ÅÌôî',
            'Î∂àÌïÑÏöîÌïú Ïª¨Îüº Î°úÎî© Î∞©ÏßÄ',
            'Ï¶âÏãú Í≤∞Í≥º ÌôïÏù∏ Í∞ÄÎä•',
            'Î©îÎ™®Î¶¨ Ìö®Ïú®Ï†Å Ï≤òÎ¶¨'
          ],
          answer: 2,
          explanation: 'Lazy EvaluationÏùÄ collect()Î•º Ìò∏Ï∂úÌï¥Ïïº Ïã§Ï†ú Í≤∞Í≥ºÎ•º Î≥º Ïàò ÏûàÏäµÎãàÎã§. Ï¶âÏãú Í≤∞Í≥º ÌôïÏù∏Ïù¥ ÌïÑÏöîÌïòÎ©¥ Eager Î™®Îìú(Í∏∞Î≥∏)Î•º ÏÇ¨Ïö©Ìï¥Ïïº Ìï©ÎãàÎã§.'
        },
        {
          question: 'pandas DataFrameÏùÑ PolarsÎ°ú Î≥ÄÌôòÌï† Îïå Ï£ºÏùòÌï† Ï†êÏùÄ?',
          options: [
            'Ïª¨ÎüºÎ™ÖÏù¥ Î™®Îëê ÎåÄÎ¨∏ÏûêÎ°ú Î≥ÄÌôòÎê®',
            'pandas Ïù∏Îç±Ïä§Í∞Ä ÏÇ¨ÎùºÏßê',
            'Î¨∏ÏûêÏó¥Ïù¥ Ïà´ÏûêÎ°ú Î≥ÄÌôòÎê®',
            'Î™®Îì† Í∞íÏù¥ nullableÎ°ú Î≥ÄÌôòÎê®'
          ],
          answer: 1,
          explanation: 'PolarsÎäî Ïù∏Îç±Ïä§ Í∞úÎÖêÏù¥ ÏóÜÏúºÎØÄÎ°ú pandasÏùò Ïù∏Îç±Ïä§Îäî Î≥ÄÌôò Ïãú ÏÇ¨ÎùºÏßëÎãàÎã§. Ïù∏Îç±Ïä§Î•º Î≥¥Ï°¥ÌïòÎ†§Î©¥ reset_index()Î°ú Ïª¨ÎüºÏúºÎ°ú Î≥ÄÌôò ÌõÑ ÏßÑÌñâÌï¥Ïïº Ìï©ÎãàÎã§.'
        },
        {
          question: 'Polars group_by()ÏóêÏÑú ÏßëÍ≥Ñ Í≤∞Í≥º Ïª¨ÎüºÎ™ÖÏùÑ ÏßÄÏ†ïÌïòÎ†§Î©¥?',
          options: [
            '.rename() Î©îÏÑúÎìú ÏÇ¨Ïö©',
            '.alias() Î©îÏÑúÎìú ÏÇ¨Ïö©',
            '.name() Î©îÏÑúÎìú ÏÇ¨Ïö©',
            'ÏûêÎèôÏúºÎ°ú ÏßÄÏ†ïÎê®'
          ],
          answer: 1,
          explanation: 'PolarsÏóêÏÑúÎäî pl.col("x").sum().alias("total_x")Ï≤òÎüº alias() Î©îÏÑúÎìúÎ°ú Í≤∞Í≥º Ïª¨ÎüºÎ™ÖÏùÑ ÏßÄÏ†ïÌï©ÎãàÎã§.'
        }
      ]
    }
  },

  // Task 9: Îç∞ÏùºÎ¶¨ Ï±åÎ¶∞ÏßÄ
  {
    id: 'w2d4-task9',
    title: 'üî• Daily Challenge: pandas-Polars ÎìÄÏñº ÌååÏù¥ÌîÑÎùºÏù∏',
    type: 'code',
    duration: 20,
    content: {
      objectives: [
        'pandas/Polars Î™®Îëê ÏßÄÏõêÌïòÎäî Ï∂îÏÉÅÌôî Î†àÏù¥Ïñ¥ ÏÑ§Í≥Ñ',
        'ÏûêÎèô Î∞±ÏóîÎìú ÏÑ†ÌÉù Î°úÏßÅ Íµ¨ÌòÑ',
        'ÏÑ±Îä• Î≤§ÏπòÎßàÌÇπ ÎÇ¥Ïû•',
        'Ïã§Î¨¥ Ï†ÅÏö© Í∞ÄÎä•Ìïú Ïú†Ìã∏Î¶¨Ìã∞ Í∞úÎ∞ú'
      ],
      starterCode: `import pandas as pd
import polars as pl
import numpy as np
from typing import Union, Optional, Literal
from abc import ABC, abstractmethod
import time

# ÌÉÄÏûÖ Ï†ïÏùò
DataFrameType = Union[pd.DataFrame, pl.DataFrame]
Backend = Literal['pandas', 'polars', 'auto']

class DataPipeline(ABC):
    """
    pandas/Polars ÎìÄÏñº Î∞±ÏóîÎìú Îç∞Ïù¥ÌÑ∞ ÌååÏù¥ÌîÑÎùºÏù∏

    ÏÇ¨Ïö©Î≤ï:
        pipeline = SmartPipeline(df, backend='auto')
        result = (
            pipeline
            .filter('age > 25')
            .add_column('salary_monthly', 'salary / 12')
            .group_by('department')
            .aggregate({'salary': 'mean', 'age': 'max'})
            .sort('salary', descending=True)
            .execute()
        )
    """

    @abstractmethod
    def filter(self, condition: str) -> 'DataPipeline':
        """Ï°∞Í±¥ÏúºÎ°ú ÌïÑÌÑ∞ÎßÅ"""
        pass

    @abstractmethod
    def add_column(self, name: str, expression: str) -> 'DataPipeline':
        """ÏÉà Ïª¨Îüº Ï∂îÍ∞Ä"""
        pass

    @abstractmethod
    def group_by(self, columns: Union[str, list]) -> 'DataPipeline':
        """Í∑∏Î£πÌôî"""
        pass

    @abstractmethod
    def aggregate(self, agg_dict: dict) -> 'DataPipeline':
        """ÏßëÍ≥Ñ"""
        pass

    @abstractmethod
    def sort(self, column: str, descending: bool = False) -> 'DataPipeline':
        """Ï†ïÎ†¨"""
        pass

    @abstractmethod
    def execute(self) -> DataFrameType:
        """ÌååÏù¥ÌîÑÎùºÏù∏ Ïã§Ìñâ"""
        pass

class SmartPipeline(DataPipeline):
    """ÏûêÎèô Î∞±ÏóîÎìú ÏÑ†ÌÉù ÌååÏù¥ÌîÑÎùºÏù∏"""

    def __init__(self, df: DataFrameType, backend: Backend = 'auto'):
        self.original_df = df
        self.backend = self._select_backend(df, backend)
        self.operations = []
        self.benchmark_results = {}

    def _select_backend(self, df: DataFrameType, backend: Backend) -> str:
        """Î∞±ÏóîÎìú ÏûêÎèô ÏÑ†ÌÉù"""
        if backend != 'auto':
            return backend

        # TODO: Îç∞Ïù¥ÌÑ∞ ÌÅ¨Í∏∞ Í∏∞Î∞ò ÏûêÎèô ÏÑ†ÌÉù
        # - 10Îßå Ìñâ ÎØ∏Îßå: pandas (Ïò§Î≤ÑÌó§Îìú Ï†ÅÏùå)
        # - 10Îßå Ìñâ Ïù¥ÏÉÅ: polars (ÏÑ±Îä• Ïù¥Ï†ê)
        pass

    def filter(self, condition: str) -> 'SmartPipeline':
        """Ï°∞Í±¥ÏúºÎ°ú ÌïÑÌÑ∞ÎßÅ"""
        # TODO: Íµ¨ÌòÑ
        pass

    def add_column(self, name: str, expression: str) -> 'SmartPipeline':
        """ÏÉà Ïª¨Îüº Ï∂îÍ∞Ä"""
        # TODO: Íµ¨ÌòÑ
        pass

    def group_by(self, columns: Union[str, list]) -> 'SmartPipeline':
        """Í∑∏Î£πÌôî"""
        # TODO: Íµ¨ÌòÑ
        pass

    def aggregate(self, agg_dict: dict) -> 'SmartPipeline':
        """ÏßëÍ≥Ñ"""
        # TODO: Íµ¨ÌòÑ
        pass

    def sort(self, column: str, descending: bool = False) -> 'SmartPipeline':
        """Ï†ïÎ†¨"""
        # TODO: Íµ¨ÌòÑ
        pass

    def execute(self) -> DataFrameType:
        """ÌååÏù¥ÌîÑÎùºÏù∏ Ïã§Ìñâ Î∞è Î≤§ÏπòÎßàÌÇπ"""
        # TODO: Íµ¨ÌòÑ
        pass

    def compare_backends(self) -> dict:
        """pandas/Polars ÏÑ±Îä• ÎπÑÍµê"""
        # TODO: Íµ¨ÌòÑ
        pass

# ===========================================
# ÌÖåÏä§Ìä∏
# ===========================================

np.random.seed(42)
n_rows = 100_000

df = pd.DataFrame({
    'department': np.random.choice(['Sales', 'Engineering', 'Marketing', 'HR'], n_rows),
    'age': np.random.randint(22, 60, n_rows),
    'salary': np.random.randint(40000, 150000, n_rows),
    'years_exp': np.random.randint(0, 30, n_rows)
})

print(f"ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞: {len(df):,} Ìñâ")

# ÌÖåÏä§Ìä∏ Ïã§Ìñâ
if __name__ == "__main__":
    # ÌååÏù¥ÌîÑÎùºÏù∏ ÌÖåÏä§Ìä∏
    pipeline = SmartPipeline(df, backend='auto')

    result = (
        pipeline
        .filter('age > 30')
        .add_column('salary_monthly', 'salary / 12')
        .group_by('department')
        .aggregate({'salary': 'mean', 'years_exp': 'max'})
        .sort('salary', descending=True)
        .execute()
    )

    print("\\nÍ≤∞Í≥º:")
    print(result)

    # Î∞±ÏóîÎìú ÎπÑÍµê
    print("\\nÎ∞±ÏóîÎìú ÏÑ±Îä• ÎπÑÍµê:")
    print(pipeline.compare_backends())
`,
      solutionCode: `import pandas as pd
import polars as pl
import numpy as np
from typing import Union, Optional, Literal, List, Dict, Any
from abc import ABC, abstractmethod
import time
import re

DataFrameType = Union[pd.DataFrame, pl.DataFrame]
Backend = Literal['pandas', 'polars', 'auto']

class DataPipeline(ABC):
    @abstractmethod
    def filter(self, condition: str) -> 'DataPipeline': pass
    @abstractmethod
    def add_column(self, name: str, expression: str) -> 'DataPipeline': pass
    @abstractmethod
    def group_by(self, columns: Union[str, list]) -> 'DataPipeline': pass
    @abstractmethod
    def aggregate(self, agg_dict: dict) -> 'DataPipeline': pass
    @abstractmethod
    def sort(self, column: str, descending: bool = False) -> 'DataPipeline': pass
    @abstractmethod
    def execute(self) -> DataFrameType: pass

class SmartPipeline(DataPipeline):
    """ÏûêÎèô Î∞±ÏóîÎìú ÏÑ†ÌÉù ÌååÏù¥ÌîÑÎùºÏù∏"""

    def __init__(self, df: DataFrameType, backend: Backend = 'auto'):
        self.original_df = df
        self.backend = self._select_backend(df, backend)
        self.operations: List[Dict[str, Any]] = []
        self.benchmark_results = {}
        self._group_cols = None

    def _select_backend(self, df: DataFrameType, backend: Backend) -> str:
        if backend != 'auto':
            return backend

        n_rows = len(df) if isinstance(df, (pd.DataFrame, pl.DataFrame)) else 0
        return 'polars' if n_rows >= 100_000 else 'pandas'

    def _to_backend_df(self, df: DataFrameType, target: str) -> DataFrameType:
        """DataFrameÏùÑ ÏßÄÏ†ïÎêú Î∞±ÏóîÎìúÎ°ú Î≥ÄÌôò"""
        if target == 'polars':
            if isinstance(df, pd.DataFrame):
                return pl.from_pandas(df)
            return df
        else:  # pandas
            if isinstance(df, pl.DataFrame):
                return df.to_pandas()
            return df

    def filter(self, condition: str) -> 'SmartPipeline':
        self.operations.append({'type': 'filter', 'condition': condition})
        return self

    def add_column(self, name: str, expression: str) -> 'SmartPipeline':
        self.operations.append({'type': 'add_column', 'name': name, 'expression': expression})
        return self

    def group_by(self, columns: Union[str, list]) -> 'SmartPipeline':
        if isinstance(columns, str):
            columns = [columns]
        self._group_cols = columns
        self.operations.append({'type': 'group_by', 'columns': columns})
        return self

    def aggregate(self, agg_dict: dict) -> 'SmartPipeline':
        self.operations.append({'type': 'aggregate', 'agg_dict': agg_dict})
        return self

    def sort(self, column: str, descending: bool = False) -> 'SmartPipeline':
        self.operations.append({'type': 'sort', 'column': column, 'descending': descending})
        return self

    def _execute_pandas(self, df: pd.DataFrame) -> pd.DataFrame:
        """pandas Î∞±ÏóîÎìúÎ°ú Ïã§Ìñâ"""
        for op in self.operations:
            if op['type'] == 'filter':
                df = df.query(op['condition'])
            elif op['type'] == 'add_column':
                df = df.assign(**{op['name']: df.eval(op['expression'])})
            elif op['type'] == 'group_by':
                pass  # aggregateÏóêÏÑú Ï≤òÎ¶¨
            elif op['type'] == 'aggregate':
                if self._group_cols:
                    df = df.groupby(self._group_cols).agg(op['agg_dict']).reset_index()
            elif op['type'] == 'sort':
                df = df.sort_values(op['column'], ascending=not op['descending'])
        return df

    def _execute_polars(self, df: pl.DataFrame) -> pl.DataFrame:
        """Polars Î∞±ÏóîÎìúÎ°ú Ïã§Ìñâ"""
        lf = df.lazy()

        for op in self.operations:
            if op['type'] == 'filter':
                # Í∞ÑÎã®Ìïú Ï°∞Í±¥ ÌååÏã± (Ïã§Ï†úÎ°úÎäî Îçî Ï†ïÍµêÌïú ÌååÏÑú ÌïÑÏöî)
                cond = op['condition']
                # 'col > value' ÌòïÌÉú ÌååÏã±
                match = re.match(r'(\w+)\s*([><=!]+)\s*(\d+)', cond)
                if match:
                    col, operator, value = match.groups()
                    value = int(value)
                    if operator == '>':
                        lf = lf.filter(pl.col(col) > value)
                    elif operator == '<':
                        lf = lf.filter(pl.col(col) < value)
                    elif operator == '>=':
                        lf = lf.filter(pl.col(col) >= value)
                    elif operator == '<=':
                        lf = lf.filter(pl.col(col) <= value)
                    elif operator == '==':
                        lf = lf.filter(pl.col(col) == value)

            elif op['type'] == 'add_column':
                # Í∞ÑÎã®Ìïú ÌëúÌòÑÏãù ÌååÏã±
                expr = op['expression']
                name = op['name']
                # 'col / value' ÌòïÌÉú ÌååÏã±
                match = re.match(r'(\w+)\s*([/+\-*])\s*(\d+)', expr)
                if match:
                    col, operator, value = match.groups()
                    value = int(value)
                    if operator == '/':
                        lf = lf.with_columns((pl.col(col) / value).alias(name))
                    elif operator == '*':
                        lf = lf.with_columns((pl.col(col) * value).alias(name))
                    elif operator == '+':
                        lf = lf.with_columns((pl.col(col) + value).alias(name))
                    elif operator == '-':
                        lf = lf.with_columns((pl.col(col) - value).alias(name))

            elif op['type'] == 'group_by':
                pass  # aggregateÏóêÏÑú Ï≤òÎ¶¨

            elif op['type'] == 'aggregate':
                if self._group_cols:
                    agg_exprs = []
                    for col, func in op['agg_dict'].items():
                        if func == 'mean':
                            agg_exprs.append(pl.col(col).mean().alias(col))
                        elif func == 'sum':
                            agg_exprs.append(pl.col(col).sum().alias(col))
                        elif func == 'max':
                            agg_exprs.append(pl.col(col).max().alias(col))
                        elif func == 'min':
                            agg_exprs.append(pl.col(col).min().alias(col))
                        elif func == 'count':
                            agg_exprs.append(pl.col(col).count().alias(col))
                    lf = lf.group_by(self._group_cols).agg(agg_exprs)

            elif op['type'] == 'sort':
                lf = lf.sort(op['column'], descending=op['descending'])

        return lf.collect()

    def execute(self) -> DataFrameType:
        """ÌååÏù¥ÌîÑÎùºÏù∏ Ïã§Ìñâ"""
        start = time.time()

        if self.backend == 'polars':
            df = self._to_backend_df(self.original_df, 'polars')
            result = self._execute_polars(df)
        else:
            df = self._to_backend_df(self.original_df, 'pandas')
            result = self._execute_pandas(df)

        self.benchmark_results[self.backend] = time.time() - start
        return result

    def compare_backends(self) -> dict:
        """pandas/Polars ÏÑ±Îä• ÎπÑÍµê"""
        results = {}

        # pandas Ïã§Ìñâ
        df_pd = self._to_backend_df(self.original_df, 'pandas')
        start = time.time()
        _ = self._execute_pandas(df_pd.copy())
        results['pandas'] = time.time() - start

        # Polars Ïã§Ìñâ
        df_pl = self._to_backend_df(self.original_df, 'polars')
        start = time.time()
        _ = self._execute_polars(df_pl)
        results['polars'] = time.time() - start

        results['speedup'] = results['pandas'] / results['polars'] if results['polars'] > 0 else float('inf')
        results['recommended'] = 'polars' if results['speedup'] > 1.5 else 'pandas'

        return results

# ===========================================
# ÌÖåÏä§Ìä∏
# ===========================================

np.random.seed(42)
n_rows = 100_000

df = pd.DataFrame({
    'department': np.random.choice(['Sales', 'Engineering', 'Marketing', 'HR'], n_rows),
    'age': np.random.randint(22, 60, n_rows),
    'salary': np.random.randint(40000, 150000, n_rows),
    'years_exp': np.random.randint(0, 30, n_rows)
})

print(f"ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞: {len(df):,} Ìñâ")

if __name__ == "__main__":
    # ÌååÏù¥ÌîÑÎùºÏù∏ ÌÖåÏä§Ìä∏
    pipeline = SmartPipeline(df, backend='auto')
    print(f"ÏÑ†ÌÉùÎêú Î∞±ÏóîÎìú: {pipeline.backend}")

    result = (
        pipeline
        .filter('age > 30')
        .add_column('salary_monthly', 'salary / 12')
        .group_by('department')
        .aggregate({'salary': 'mean', 'years_exp': 'max'})
        .sort('salary', descending=True)
        .execute()
    )

    print("\\nÍ≤∞Í≥º:")
    print(result)

    # Î∞±ÏóîÎìú ÎπÑÍµê
    comparison = SmartPipeline(df).compare_backends()
    print("\\n=== Î∞±ÏóîÎìú ÏÑ±Îä• ÎπÑÍµê ===")
    print(f"pandas: {comparison['pandas']:.4f}Ï¥à")
    print(f"Polars: {comparison['polars']:.4f}Ï¥à")
    print(f"ÏÜçÎèÑ Ìñ•ÏÉÅ: {comparison['speedup']:.2f}Î∞∞")
    print(f"Í∂åÏû• Î∞±ÏóîÎìú: {comparison['recommended']}")
`,
      instructions: 'pandasÏôÄ Polars Î™®ÎëêÎ•º ÏßÄÏõêÌïòÎäî ÌÜµÌï© ÌååÏù¥ÌîÑÎùºÏù∏ ÌÅ¥ÎûòÏä§Î•º Íµ¨ÌòÑÌï©ÎãàÎã§. Îç∞Ïù¥ÌÑ∞ ÌÅ¨Í∏∞Ïóê Îî∞Îùº ÏûêÎèôÏúºÎ°ú ÏµúÏ†ÅÏùò Î∞±ÏóîÎìúÎ•º ÏÑ†ÌÉùÌïòÍ≥†, ÏÑ±Îä• ÎπÑÍµê Í∏∞Îä•ÎèÑ Ï†úÍ≥µÌï©ÎãàÎã§.',
      keyPoints: [
        'Ï∂îÏÉÅÌôî Î†àÏù¥Ïñ¥Î°ú Î∞±ÏóîÎìú ÎèÖÎ¶ΩÏ†Å API Ï†úÍ≥µ',
        'Îç∞Ïù¥ÌÑ∞ ÌÅ¨Í∏∞ Í∏∞Î∞ò ÏûêÎèô Î∞±ÏóîÎìú ÏÑ†ÌÉù',
        'Î¨∏ÏûêÏó¥ ÌëúÌòÑÏãùÏùÑ Í∞Å Î∞±ÏóîÎìú APIÎ°ú Î≥ÄÌôò',
        'Î≤§ÏπòÎßàÌÇπÏúºÎ°ú ÏµúÏ†Å Î∞±ÏóîÎìú Ï∂îÏ≤ú'
      ]
    }
  }
]
