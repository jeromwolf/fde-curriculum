// Week 8 Day 3: Knowledge Graph êµ¬ì¶•

import type { Day } from './types'
import { createVideoTask, createCodeTask, createReadingTask } from './types'

const task1 = createVideoTask('w8d3-kg-architecture', 'KG ì•„í‚¤í…ì²˜ ì„¤ê³„', 25, {
  introduction: `
## Knowledge Graph ì•„í‚¤í…ì²˜

### 3ê³„ì¸µ ì•„í‚¤í…ì²˜

\`\`\`
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Application Layer            â”‚
â”‚   (GraphRAG, Text2Cypher, Streamlit)    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚              Service Layer              â”‚
â”‚  (Query Engine, Reasoner, Validator)    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚              Storage Layer              â”‚
â”‚    (Neo4j Graph + Vector Index)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\`\`\`

### Neo4j ìŠ¤í‚¤ë§ˆ ì„¤ê³„

\`\`\`cypher
// ë…¸ë“œ ë ˆì´ë¸”
(:Article)     - ë‰´ìŠ¤ ê¸°ì‚¬
(:Person)      - ì¸ë¬¼
(:Organization)- ê¸°ê´€
(:Location)    - ì¥ì†Œ
(:Topic)       - ì£¼ì œ

// ê´€ê³„ íƒ€ì…
-[:MENTIONS]->        - ì–¸ê¸‰
-[:AFFILIATED_WITH]-> - ì†Œì†
-[:COMPETES_WITH]->   - ê²½ìŸ
-[:LOCATED_IN]->      - ìœ„ì¹˜
-[:COVERS]->          - ë‹¤ë£¸
\`\`\`

### ì†ì„± ì„¤ê³„

| ë…¸ë“œ | í•„ìˆ˜ ì†ì„± | ì„ íƒ ì†ì„± |
|------|----------|----------|
| Article | uri, title, published_date | content, source |
| Person | uri, name | role, organization |
| Organization | uri, name | industry, founded |
| Location | uri, name | country, type |
| Topic | uri, name | category |

### ì¸ë±ìŠ¤ ì „ëµ

\`\`\`cypher
// Unique ì œì•½ì¡°ê±´ (í•„ìˆ˜)
CREATE CONSTRAINT article_uri FOR (a:Article) REQUIRE a.uri IS UNIQUE;
CREATE CONSTRAINT person_uri FOR (p:Person) REQUIRE p.uri IS UNIQUE;

// ê²€ìƒ‰ ì¸ë±ìŠ¤ (ì„±ëŠ¥)
CREATE INDEX article_title FOR (a:Article) ON (a.title);
CREATE INDEX person_name FOR (p:Person) ON (p.name);

// ì „ë¬¸ ê²€ìƒ‰ ì¸ë±ìŠ¤ (Optional)
CREATE FULLTEXT INDEX article_content FOR (a:Article) ON EACH [a.title, a.content];
\`\`\`
`,
  keyPoints: ['3ê³„ì¸µ ì•„í‚¤í…ì²˜ ì„¤ê³„', 'Neo4j ë…¸ë“œ/ê´€ê³„ ìŠ¤í‚¤ë§ˆ', 'ì¸ë±ìŠ¤ ì „ëµ'],
  practiceGoal: 'KG ì•„í‚¤í…ì²˜ ì´í•´',
})

const task2 = createCodeTask('w8d3-kg-builder', 'ì‹¤ìŠµ: KG ë¹Œë” êµ¬í˜„', 60, {
  introduction: `
## Knowledge Graph ë¹Œë”

### ê¸°ë³¸ KG ë¹Œë”

\`\`\`python
# kg/builder.py

from neo4j import GraphDatabase
from dataclasses import dataclass
from typing import List, Optional
import logging

@dataclass
class Triple:
    subject: str
    predicate: str
    object: str
    confidence: float
    source_url: str

class KnowledgeGraphBuilder:
    """Neo4j Knowledge Graph ë¹Œë”"""

    def __init__(self, uri: str, user: str, password: str):
        self.driver = GraphDatabase.driver(uri, auth=(user, password))
        self.logger = logging.getLogger("kg_builder")

    def close(self):
        self.driver.close()

    def setup_schema(self):
        """ìŠ¤í‚¤ë§ˆ ë° ì¸ë±ìŠ¤ ì„¤ì •"""
        constraints = [
            "CREATE CONSTRAINT article_uri IF NOT EXISTS FOR (a:Article) REQUIRE a.uri IS UNIQUE",
            "CREATE CONSTRAINT person_uri IF NOT EXISTS FOR (p:Person) REQUIRE p.uri IS UNIQUE",
            "CREATE CONSTRAINT org_uri IF NOT EXISTS FOR (o:Organization) REQUIRE o.uri IS UNIQUE",
            "CREATE CONSTRAINT location_uri IF NOT EXISTS FOR (l:Location) REQUIRE l.uri IS UNIQUE",
        ]

        indexes = [
            "CREATE INDEX article_title IF NOT EXISTS FOR (a:Article) ON (a.title)",
            "CREATE INDEX person_name IF NOT EXISTS FOR (p:Person) ON (p.name)",
            "CREATE INDEX org_name IF NOT EXISTS FOR (o:Organization) ON (o.name)",
        ]

        with self.driver.session() as session:
            for query in constraints + indexes:
                try:
                    session.run(query)
                except Exception as e:
                    self.logger.warning(f"ìŠ¤í‚¤ë§ˆ ì„¤ì • ê²½ê³ : {e}")

    def _parse_uri(self, uri: str) -> tuple:
        """URIì—ì„œ íƒ€ì…ê³¼ ì´ë¦„ ì¶”ì¶œ"""
        # format: namespace:Type_Name
        if ":" not in uri:
            return "Entity", uri

        parts = uri.split(":", 1)[1]
        if "_" in parts:
            type_name = parts.split("_", 1)
            return type_name[0], type_name[1].replace("_", " ")
        return "Entity", parts

    def add_node(self, uri: str, properties: dict = None):
        """ë…¸ë“œ ì¶”ê°€ ë˜ëŠ” ì—…ë°ì´íŠ¸"""
        node_type, name = self._parse_uri(uri)

        props = properties or {}
        props["uri"] = uri
        props["name"] = name

        query = f"""
        MERGE (n:{node_type} {{uri: $uri}})
        SET n += $props
        RETURN n
        """

        with self.driver.session() as session:
            session.run(query, uri=uri, props=props)

    def add_triple(self, triple: Triple):
        """Tripleì„ ê·¸ë˜í”„ì— ì¶”ê°€"""
        # 1. Subject ë…¸ë“œ ìƒì„±
        self.add_node(triple.subject)

        # 2. Object ë…¸ë“œ ìƒì„±
        self.add_node(triple.object)

        # 3. ê´€ê³„ ìƒì„±
        rel_type = triple.predicate.split(":")[-1].upper()

        query = f"""
        MATCH (s {{uri: $subject}})
        MATCH (o {{uri: $object}})
        MERGE (s)-[r:{rel_type}]->(o)
        SET r.confidence = $confidence,
            r.source_url = $source_url
        RETURN r
        """

        with self.driver.session() as session:
            session.run(
                query,
                subject=triple.subject,
                object=triple.object,
                confidence=triple.confidence,
                source_url=triple.source_url
            )

    def add_triples_batch(self, triples: List[Triple]):
        """ë°°ì¹˜ë¡œ Triple ì¶”ê°€"""
        for triple in triples:
            try:
                self.add_triple(triple)
            except Exception as e:
                self.logger.error(f"Triple ì¶”ê°€ ì‹¤íŒ¨: {e}")

    def get_stats(self) -> dict:
        """ê·¸ë˜í”„ í†µê³„"""
        query = """
        MATCH (n)
        WITH labels(n)[0] as label, count(*) as cnt
        RETURN label, cnt
        ORDER BY cnt DESC
        """

        with self.driver.session() as session:
            result = session.run(query)
            return {r["label"]: r["cnt"] for r in result}
\`\`\`

---

## ğŸ’¥ Common Pitfalls (ìì£¼ í•˜ëŠ” ì‹¤ìˆ˜)

### 1. [ì¤‘ë³µ ë…¸ë“œ] CREATE ëŒ€ì‹  MERGE ì‚¬ìš© í•„ìˆ˜

\`\`\`python
# âŒ ì˜ëª»ëœ ì˜ˆì‹œ: CREATEë¡œ ë…¸ë“œ ìƒì„±
session.run("CREATE (n:Person {name: 'ì´ì¬ìš©'})")
session.run("CREATE (n:Person {name: 'ì´ì¬ìš©'})")  # ğŸ”´ ì¤‘ë³µ ë…¸ë“œ ìƒì„±!

# âœ… ì˜¬ë°”ë¥¸ ì˜ˆì‹œ: MERGEë¡œ upsert
session.run("MERGE (n:Person {name: 'ì´ì¬ìš©'})")  # âœ… ì¤‘ë³µ ë°©ì§€
\`\`\`

**ê¸°ì–µí•  ì **: KG êµ¬ì¶•ì—ì„œëŠ” CREATE ëŒ€ì‹  MERGE. ì¤‘ë³µ ë…¸ë“œëŠ” ì¿¼ë¦¬ ê²°ê³¼ ì™œê³¡.

---

### 2. [ì¸ë±ìŠ¤ ëˆ„ë½] ëŒ€ëŸ‰ ë°ì´í„° ì „ ì¸ë±ìŠ¤ ìƒì„±

\`\`\`python
# âŒ ì˜ëª»ëœ ì˜ˆì‹œ: ë°ì´í„° ì¶”ê°€ í›„ ì¸ë±ìŠ¤ ìƒì„±
for triple in 100000_triples:
    builder.add_triple(triple)  # ğŸ”´ ì¸ë±ìŠ¤ ì—†ì´ MERGE â†’ ë§¤ìš° ëŠë¦¼!
session.run("CREATE INDEX ...")  # ë’¤ëŠ¦ê²Œ ì¸ë±ìŠ¤

# âœ… ì˜¬ë°”ë¥¸ ì˜ˆì‹œ: ì¸ë±ìŠ¤ ë¨¼ì €, ë°ì´í„° ë‚˜ì¤‘
session.run("CREATE INDEX node_uri FOR (n:Entity) ON (n.uri)")
session.run("CREATE INDEX edge_source FOR ()-[r:RELATION]->() ON (r.source_url)")
for triple in 100000_triples:
    builder.add_triple(triple)  # âœ… ì¸ë±ìŠ¤ ìˆì–´ì„œ ë¹ ë¦„
\`\`\`

**ê¸°ì–µí•  ì **: ì¸ë±ìŠ¤ ì—†ì´ MERGEëŠ” ì „ì²´ ìŠ¤ìº”. ëŒ€ëŸ‰ ë°ì´í„° ì „ ë°˜ë“œì‹œ ì¸ë±ìŠ¤ ìƒì„±.

---

### 3. [ì„¸ì…˜ ê´€ë¦¬] ì„¸ì…˜ ë¯¸ì¢…ë£Œë¡œ ì—°ê²° í’€ ê³ ê°ˆ

\`\`\`python
# âŒ ì˜ëª»ëœ ì˜ˆì‹œ: ì„¸ì…˜ ì¢…ë£Œ ì•ˆ í•¨
def add_triple(self, triple):
    session = self.driver.session()
    session.run("MERGE ...")  # ğŸ”´ session.close() ì—†ìŒ!
# 1000ë²ˆ í˜¸ì¶œ â†’ 1000ê°œ ì„¸ì…˜ ì—´ë¦¼ â†’ ì—°ê²° í’€ ê³ ê°ˆ

# âœ… ì˜¬ë°”ë¥¸ ì˜ˆì‹œ: with ë¬¸ìœ¼ë¡œ ìë™ ì¢…ë£Œ
def add_triple(self, triple):
    with self.driver.session() as session:  # âœ… ìë™ ì¢…ë£Œ
        session.run("MERGE ...")
\`\`\`

**ê¸°ì–µí•  ì **: Neo4j ì„¸ì…˜ì€ ë°˜ë“œì‹œ with ë¬¸ ë˜ëŠ” finallyì—ì„œ close().
`,
  keyPoints: ['MERGEë¡œ ì¤‘ë³µ ë°©ì§€', 'URI íŒŒì‹±ìœ¼ë¡œ ë…¸ë“œ íƒ€ì… ì¶”ë¡ ', 'ë°°ì¹˜ ì²˜ë¦¬ ì§€ì›'],
  practiceGoal: 'Neo4j KG ë¹Œë” êµ¬í˜„',
  codeExample: `# KG êµ¬ì¶• ì˜ˆì‹œ
builder = KnowledgeGraphBuilder(
    "bolt://localhost:7687", "neo4j", "password"
)

builder.setup_schema()

triple = Triple(
    subject="news:Person_ì´ì¬ìš©",
    predicate="news:affiliated_with",
    object="news:Organization_ì‚¼ì„±ì „ì",
    confidence=0.95,
    source_url="https://news.example.com/123"
)

builder.add_triple(triple)
print(builder.get_stats())`,
})

const task3 = createCodeTask('w8d3-vector-index', 'ì‹¤ìŠµ: ë²¡í„° ì¸ë±ìŠ¤ êµ¬ì„±', 45, {
  introduction: `
## ë²¡í„° ì¸ë±ìŠ¤ êµ¬ì„±

### Neo4j Vector Index

\`\`\`python
# kg/vector_index.py

from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Neo4jVector
from typing import List, Dict

class KGVectorIndex:
    """Knowledge Graph ë²¡í„° ì¸ë±ìŠ¤"""

    def __init__(
        self,
        neo4j_url: str,
        neo4j_user: str,
        neo4j_password: str,
        openai_key: str
    ):
        self.embeddings = OpenAIEmbeddings(api_key=openai_key)

        self.vector_store = Neo4jVector.from_existing_graph(
            embedding=self.embeddings,
            url=neo4j_url,
            username=neo4j_user,
            password=neo4j_password,
            index_name="article_index",
            node_label="Article",
            text_node_properties=["title", "content"],
            embedding_node_property="embedding"
        )

    def create_index_for_node_type(self, node_label: str, text_properties: List[str]):
        """íŠ¹ì • ë…¸ë“œ íƒ€ì…ì— ëŒ€í•œ ë²¡í„° ì¸ë±ìŠ¤ ìƒì„±"""
        return Neo4jVector.from_existing_graph(
            embedding=self.embeddings,
            url=self.vector_store._url,
            username=self.vector_store._username,
            password=self.vector_store._password,
            index_name=f"{node_label.lower()}_index",
            node_label=node_label,
            text_node_properties=text_properties,
            embedding_node_property="embedding"
        )

    def similarity_search(
        self,
        query: str,
        k: int = 5,
        filter: Dict = None
    ) -> List[Dict]:
        """ìœ ì‚¬ë„ ê²€ìƒ‰"""
        results = self.vector_store.similarity_search_with_score(
            query, k=k, filter=filter
        )

        return [
            {
                "content": doc.page_content,
                "metadata": doc.metadata,
                "score": score
            }
            for doc, score in results
        ]

    def hybrid_search(
        self,
        query: str,
        k: int = 5
    ) -> List[Dict]:
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (ë²¡í„° + í‚¤ì›Œë“œ)"""
        # ë²¡í„° ê²€ìƒ‰
        vector_results = self.similarity_search(query, k=k)

        # í‚¤ì›Œë“œ ê²€ìƒ‰ (Fulltext)
        keyword_query = f"""
        CALL db.index.fulltext.queryNodes('article_content', $query)
        YIELD node, score
        RETURN node.uri as uri, node.title as title, score
        LIMIT $k
        """

        with self.vector_store._driver.session() as session:
            keyword_results = session.run(keyword_query, query=query, k=k)
            keyword_data = [dict(r) for r in keyword_results]

        # ê²°ê³¼ ë³‘í•© (RRF)
        return self._reciprocal_rank_fusion(vector_results, keyword_data)

    def _reciprocal_rank_fusion(
        self,
        vector_results: List[Dict],
        keyword_results: List[Dict],
        k: int = 60
    ) -> List[Dict]:
        """RRFë¡œ ê²°ê³¼ ë³‘í•©"""
        scores = {}

        for rank, result in enumerate(vector_results):
            uri = result.get("metadata", {}).get("uri", str(rank))
            scores[uri] = scores.get(uri, 0) + 1 / (k + rank + 1)

        for rank, result in enumerate(keyword_results):
            uri = result.get("uri", str(rank))
            scores[uri] = scores.get(uri, 0) + 1 / (k + rank + 1)

        # ì ìˆ˜ìˆœ ì •ë ¬
        sorted_uris = sorted(scores.keys(), key=lambda x: scores[x], reverse=True)

        # ê²°ê³¼ ì¬êµ¬ì„±
        combined = []
        for uri in sorted_uris[:5]:
            for vr in vector_results:
                if vr.get("metadata", {}).get("uri") == uri:
                    combined.append(vr)
                    break

        return combined
\`\`\`
`,
  keyPoints: ['Neo4jVectorë¡œ ì„ë² ë”© ì €ì¥', 'ìœ ì‚¬ë„ ê²€ìƒ‰ êµ¬í˜„', 'RRFë¡œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰'],
  practiceGoal: 'ë²¡í„° ì¸ë±ìŠ¤ êµ¬ì¶• ë° í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰',
  codeExample: `# ë²¡í„° ì¸ë±ìŠ¤ ì‚¬ìš©
vector_index = KGVectorIndex(
    neo4j_url, neo4j_user, neo4j_password, openai_key
)

# ìœ ì‚¬ë„ ê²€ìƒ‰
results = vector_index.similarity_search("ì‚¼ì„±ì „ì ë°˜ë„ì²´", k=5)

# í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
hybrid_results = vector_index.hybrid_search("ì‚¼ì„±ì „ì ë°˜ë„ì²´", k=5)`,
})

const task4 = createCodeTask('w8d3-query-engine', 'ì‹¤ìŠµ: ì¿¼ë¦¬ ì—”ì§„ êµ¬í˜„', 50, {
  introduction: `
## ì¿¼ë¦¬ ì—”ì§„ êµ¬í˜„

### SPARQL-like ì¿¼ë¦¬ ì—”ì§„

\`\`\`python
# kg/query.py

from neo4j import GraphDatabase
from typing import List, Dict, Optional
import re

class KGQueryEngine:
    """Knowledge Graph ì¿¼ë¦¬ ì—”ì§„"""

    def __init__(self, uri: str, user: str, password: str):
        self.driver = GraphDatabase.driver(uri, auth=(user, password))

    def close(self):
        self.driver.close()

    # =====================
    # ê¸°ë³¸ ì¿¼ë¦¬
    # =====================

    def get_node(self, uri: str) -> Optional[Dict]:
        """URIë¡œ ë…¸ë“œ ì¡°íšŒ"""
        query = """
        MATCH (n {uri: $uri})
        RETURN n, labels(n) as labels
        """
        with self.driver.session() as session:
            result = session.run(query, uri=uri)
            record = result.single()
            if record:
                node = dict(record["n"])
                node["labels"] = record["labels"]
                return node
        return None

    def find_nodes(
        self,
        label: str,
        properties: Dict = None,
        limit: int = 10
    ) -> List[Dict]:
        """ë…¸ë“œ ê²€ìƒ‰"""
        where_clause = ""
        if properties:
            conditions = [f"n.{key} = $" + key for key in properties.keys()]
            where_clause = "WHERE " + " AND ".join(conditions)

        query = f"""
        MATCH (n:{label})
        {where_clause}
        RETURN n
        LIMIT $limit
        """

        params = {"limit": limit}
        if properties:
            params.update(properties)

        with self.driver.session() as session:
            result = session.run(query, **params)
            return [dict(r["n"]) for r in result]

    # =====================
    # ê´€ê³„ ì¿¼ë¦¬
    # =====================

    def get_neighbors(
        self,
        uri: str,
        relation_type: str = None,
        direction: str = "both",
        limit: int = 10
    ) -> List[Dict]:
        """ì´ì›ƒ ë…¸ë“œ ì¡°íšŒ"""
        rel = f":{relation_type}" if relation_type else ""

        if direction == "outgoing":
            pattern = f"-[r{rel}]->"
        elif direction == "incoming":
            pattern = f"<-[r{rel}]-"
        else:
            pattern = f"-[r{rel}]-"

        query = f"""
        MATCH (n {{uri: $uri}}){pattern}(neighbor)
        RETURN neighbor, type(r) as relation, r.confidence as confidence
        LIMIT $limit
        """

        with self.driver.session() as session:
            result = session.run(query, uri=uri, limit=limit)
            return [
                {
                    "node": dict(r["neighbor"]),
                    "relation": r["relation"],
                    "confidence": r["confidence"]
                }
                for r in result
            ]

    def find_path(
        self,
        start_uri: str,
        end_uri: str,
        max_hops: int = 3
    ) -> List[Dict]:
        """ë‘ ë…¸ë“œ ì‚¬ì´ì˜ ê²½ë¡œ ì°¾ê¸°"""
        query = f"""
        MATCH path = shortestPath(
            (start {{uri: $start}})-[*1..{max_hops}]-(end {{uri: $end}})
        )
        RETURN path
        """

        with self.driver.session() as session:
            result = session.run(query, start=start_uri, end=end_uri)
            paths = []
            for record in result:
                path = record["path"]
                nodes = [dict(node) for node in path.nodes]
                rels = [type(rel).__name__ for rel in path.relationships]
                paths.append({"nodes": nodes, "relationships": rels})
            return paths

    # =====================
    # ì§‘ê³„ ì¿¼ë¦¬
    # =====================

    def get_top_entities(
        self,
        label: str,
        relation_type: str,
        limit: int = 10
    ) -> List[Dict]:
        """ê°€ì¥ ë§ì´ ì—°ê²°ëœ ì—”í‹°í‹°"""
        query = f"""
        MATCH (n:{label})-[r:{relation_type}]->()
        WITH n, count(r) as cnt
        RETURN n.uri as uri, n.name as name, cnt
        ORDER BY cnt DESC
        LIMIT $limit
        """

        with self.driver.session() as session:
            result = session.run(query, limit=limit)
            return [dict(r) for r in result]

    def get_communities(self) -> List[Dict]:
        """ì»¤ë®¤ë‹ˆí‹° (ì—°ê²° ì»´í¬ë„ŒíŠ¸) ë¶„ì„"""
        query = """
        CALL gds.wcc.stream('myGraph')
        YIELD nodeId, componentId
        RETURN componentId, count(*) as size
        ORDER BY size DESC
        LIMIT 10
        """
        # Note: GDS í”ŒëŸ¬ê·¸ì¸ í•„ìš”

        with self.driver.session() as session:
            try:
                result = session.run(query)
                return [dict(r) for r in result]
            except:
                return []
\`\`\`
`,
  keyPoints: ['URI ê¸°ë°˜ ë…¸ë“œ ì¡°íšŒ', 'ë°©í–¥ì„± ìˆëŠ” ì´ì›ƒ íƒìƒ‰', 'shortestPath ê²½ë¡œ ì°¾ê¸°', 'ì§‘ê³„ ì¿¼ë¦¬'],
  practiceGoal: 'ë‹¤ì–‘í•œ ê·¸ë˜í”„ ì¿¼ë¦¬ êµ¬í˜„',
  codeExample: `# ì¿¼ë¦¬ ì—”ì§„ ì‚¬ìš©
engine = KGQueryEngine(neo4j_url, neo4j_user, neo4j_password)

# ë…¸ë“œ ì¡°íšŒ
node = engine.get_node("news:Organization_ì‚¼ì„±ì „ì")

# ì´ì›ƒ íƒìƒ‰
neighbors = engine.get_neighbors(
    "news:Organization_ì‚¼ì„±ì „ì",
    relation_type="COMPETES_WITH"
)

# ê²½ë¡œ ì°¾ê¸°
paths = engine.find_path(
    "news:Organization_ì‚¼ì„±ì „ì",
    "news:Organization_SKí•˜ì´ë‹‰ìŠ¤"
)`,
})

const task5 = createReadingTask('w8d3-quality', 'KG í’ˆì§ˆ ê´€ë¦¬', 30, {
  introduction: `
## Knowledge Graph í’ˆì§ˆ ê´€ë¦¬

### í’ˆì§ˆ ì§€í‘œ

| ì§€í‘œ | ì„¤ëª… | ëª©í‘œ |
|------|------|------|
| ì™„ì „ì„± | ëˆ„ë½ëœ ì—”í‹°í‹°/ê´€ê³„ ë¹„ìœ¨ | > 90% |
| ì •í™•ì„± | ì˜¬ë°”ë¥¸ ê´€ê³„ ë¹„ìœ¨ | > 95% |
| ì¼ê´€ì„± | ì¤‘ë³µ/ëª¨ìˆœ ì—†ëŠ” ë¹„ìœ¨ | > 98% |
| ì‹ ì„ ë„ | ìµœì‹  ë°ì´í„° ë¹„ìœ¨ | > 80% |

### ìë™ í’ˆì§ˆ ê²€ì‚¬

\`\`\`python
# kg/quality.py

class KGQualityChecker:
    """KG í’ˆì§ˆ ê²€ì‚¬ê¸°"""

    def __init__(self, query_engine: KGQueryEngine):
        self.engine = query_engine

    def check_orphan_nodes(self) -> List[str]:
        """ê³ ë¦½ ë…¸ë“œ (ê´€ê³„ ì—†ëŠ” ë…¸ë“œ) ì°¾ê¸°"""
        query = """
        MATCH (n)
        WHERE NOT (n)--()
        RETURN n.uri as uri
        """
        # ê³ ë¦½ ë…¸ë“œëŠ” ì‚­ì œ ë˜ëŠ” ì—°ê²° í•„ìš”

    def check_duplicate_relations(self) -> List[Dict]:
        """ì¤‘ë³µ ê´€ê³„ ì°¾ê¸°"""
        query = """
        MATCH (a)-[r1]->(b), (a)-[r2]->(b)
        WHERE id(r1) < id(r2) AND type(r1) = type(r2)
        RETURN a.uri, type(r1), b.uri, count(*) as duplicates
        """

    def check_low_confidence(self, threshold: float = 0.5) -> List[Dict]:
        """ì €ì‹ ë¢°ë„ ê´€ê³„ ì°¾ê¸°"""
        query = """
        MATCH (a)-[r]->(b)
        WHERE r.confidence < $threshold
        RETURN a.uri, type(r), b.uri, r.confidence
        """

    def check_stale_data(self, days: int = 30) -> int:
        """ì˜¤ë˜ëœ ë°ì´í„° ë¹„ìœ¨"""
        query = """
        MATCH (a:Article)
        WHERE a.published_date < datetime() - duration({days: $days})
        RETURN count(a) as stale_count
        """

    def generate_report(self) -> Dict:
        """í’ˆì§ˆ ë¦¬í¬íŠ¸ ìƒì„±"""
        return {
            "orphan_nodes": len(self.check_orphan_nodes()),
            "duplicate_relations": len(self.check_duplicate_relations()),
            "low_confidence": len(self.check_low_confidence()),
            "stale_percentage": self.check_stale_data()
        }
\`\`\`

### ìˆ˜ë™ ê²€ì¦ ì›Œí¬í”Œë¡œìš°

1. **ìƒ˜í”Œë§**: ëœë¤ 100ê°œ Triple ì¶”ì¶œ
2. **ë ˆì´ë¸”ë§**: ì •í™•/ë¶€ì •í™• í‘œì‹œ
3. **ë¶„ì„**: ì˜¤ë¥˜ ìœ í˜• ë¶„ë¥˜
4. **ê°œì„ **: ì¶”ì¶œ ë¡œì§ ìˆ˜ì •
5. **ì¬ê²€ì¦**: ê°œì„  íš¨ê³¼ ì¸¡ì •

### ì‚¬ìš©ì í”¼ë“œë°± ì‹œìŠ¤í…œ

\`\`\`cypher
// í”¼ë“œë°± ê´€ê³„ ì¶”ê°€
MATCH (a)-[r]->(b)
WHERE r.id = $relation_id
SET r.user_feedback = $feedback,  // 1 (ì •í™•) or -1 (ë¶€ì •í™•)
    r.feedback_date = datetime()

// í”¼ë“œë°± ê¸°ë°˜ ì‹ ë¢°ë„ ì¡°ì •
MATCH (a)-[r]->(b)
WHERE r.user_feedback IS NOT NULL
SET r.confidence = CASE
    WHEN r.user_feedback > 0 THEN 1.0
    WHEN r.user_feedback < 0 THEN 0.0
    ELSE r.confidence
END
\`\`\`
`,
  keyPoints: ['4ê°€ì§€ í’ˆì§ˆ ì§€í‘œ', 'ìë™ í’ˆì§ˆ ê²€ì‚¬ ì¿¼ë¦¬', 'ì‚¬ìš©ì í”¼ë“œë°± ì‹œìŠ¤í…œ'],
  practiceGoal: 'KG í’ˆì§ˆ ê´€ë¦¬ ì²´ê³„ ì´í•´',
})

export const day3KgConstruction: Day = {
  slug: 'kg-construction',
  title: 'Knowledge Graph êµ¬ì¶•',
  totalDuration: 210,
  tasks: [task1, task2, task3, task4, task5],
}
