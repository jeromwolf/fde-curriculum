// Day 1: Entity Resolution ê¸°ì´ˆ - ì¤‘ë³µ íƒì§€ì™€ ë³‘í•©

import type { Day } from '../../types'
import {
  createVideoTask,
  createReadingTask,
  createCodeTask,
  createQuizTask,
  createChallengeTask,
} from './types'

// ============================================
// Day 1: Entity Resolution ê¸°ì´ˆ
// ============================================
// í•™ìŠµ ëª©í‘œ:
// 1. Entity Resolutionì˜ ê°œë…ê³¼ í•„ìš”ì„±ì„ ì´í•´í•œë‹¤
// 2. ë¬¸ìì—´ ìœ ì‚¬ë„ ì•Œê³ ë¦¬ì¦˜ì„ í™œìš©í•œë‹¤
// 3. Python recordlinkage ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•œë‹¤
// 4. Neo4jì—ì„œ ì¤‘ë³µ ë…¸ë“œë¥¼ íƒì§€í•˜ê³  ë³‘í•©í•œë‹¤
// ============================================

export const day1EntityResolution: Day = {
  slug: 'entity-resolution-basics',
  title: 'Entity Resolution ê¸°ì´ˆ',
  totalDuration: 240,
  tasks: [
    // Task 1: Entity Resolution ê°œìš” (25ë¶„)
    createVideoTask(
      'w4d1-er-overview',
      'Entity Resolution ê°œìš”ì™€ í•„ìš”ì„±',
      25,
      {
        introduction: `
# Entity Resolution ê°œìš”

## í•™ìŠµ ëª©í‘œ
- Entity Resolutionì´ ë¬´ì—‡ì¸ì§€ ì´í•´í•œë‹¤
- ë°ì´í„° í’ˆì§ˆ ë¬¸ì œì™€ ERì˜ í•„ìš”ì„±ì„ íŒŒì•…í•œë‹¤
- ERì˜ ì£¼ìš” ê¸°ë²•ì„ ê°œê´€í•œë‹¤

## Entity Resolutionì´ë€?

\`\`\`
Entity Resolution (ER)
= ê°™ì€ ì‹¤ì„¸ê³„ ì—”í‹°í‹°ë¥¼ ê°€ë¦¬í‚¤ëŠ” ë‹¤ë¥¸ í‘œí˜„ë“¤ì„ ì‹ë³„í•˜ê³  í†µí•©í•˜ëŠ” ê³¼ì •
= Record Linkage, Deduplication, Entity Matching ë“±ìœ¼ë¡œë„ ë¶ˆë¦¼
\`\`\`

### ë¬¸ì œ ìƒí™©

\`\`\`
ë°ì´í„° ì†ŒìŠ¤ A:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ name: "ì‚¼ì„±ì „ì"                     â”‚
â”‚ industry: "ì „ì"                     â”‚
â”‚ employees: 270000                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ë°ì´í„° ì†ŒìŠ¤ B:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ name: "Samsung Electronics"          â”‚
â”‚ sector: "Technology"                 â”‚
â”‚ staff_count: 267000                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ë°ì´í„° ì†ŒìŠ¤ C:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ company: "ì‚¼ì„±ì „ìì£¼ì‹íšŒì‚¬"          â”‚
â”‚ type: "ëŒ€ê¸°ì—…"                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â†’ ëª¨ë‘ ê°™ì€ íšŒì‚¬! í•˜ì§€ë§Œ ê¸°ê³„ëŠ” ëª¨ë¦„
\`\`\`

## ERì´ í•„ìš”í•œ ìƒí™©

| ìƒí™© | ì˜ˆì‹œ |
|------|------|
| **ë°ì´í„° í†µí•©** | ì—¬ëŸ¬ DB/APIì˜ ê³ ê° ì •ë³´ í†µí•© |
| **ì¤‘ë³µ ì œê±°** | CRMì˜ ì¤‘ë³µ ê³ ê° ë ˆì½”ë“œ ì •ë¦¬ |
| **ì§€ì‹ ê·¸ë˜í”„** | ë‹¤ì¤‘ ì†ŒìŠ¤ì—ì„œ KG êµ¬ì¶• ì‹œ |
| **ë§ˆìŠ¤í„° ë°ì´í„°** | ê¸°ì—…ì˜ ë‹¨ì¼ ì§„ì‹¤ ì†ŒìŠ¤(SSOT) êµ¬ì¶• |

## ER íŒŒì´í”„ë¼ì¸

\`\`\`
1. Preprocessing (ì „ì²˜ë¦¬)
   - ì •ê·œí™” (ëŒ€ì†Œë¬¸ì, ê³µë°±, íŠ¹ìˆ˜ë¬¸ì)
   - í† í°í™”
   - í‘œì¤€í™” (ë‚ ì§œ, ì£¼ì†Œ í˜•ì‹)
       â†“
2. Blocking (ë¸”ë¡œí‚¹)
   - í›„ë³´ ìŒ ìƒì„±
   - ì „ì²´ ë¹„êµ ëŒ€ì‹  ìœ ì‚¬ ê·¸ë£¹ë§Œ ë¹„êµ
   - nÂ² â†’ n log n ë³µì¡ë„ ê°ì†Œ
       â†“
3. Comparison (ë¹„êµ)
   - ìœ ì‚¬ë„ ê³„ì‚°
   - ì—¬ëŸ¬ ì†ì„± ë¹„êµ
   - ê°€ì¤‘ì¹˜ ì ìš©
       â†“
4. Classification (ë¶„ë¥˜)
   - Match / Non-match íŒì •
   - ì„ê³„ê°’ ë˜ëŠ” ML ëª¨ë¸
       â†“
5. Clustering (í´ëŸ¬ìŠ¤í„°ë§)
   - ì¼ì¹˜ ìŒì„ ê·¸ë£¹ìœ¼ë¡œ ë¬¶ê¸°
   - Transitive closure
       â†“
6. Merging (ë³‘í•©)
   - ëŒ€í‘œ ë ˆì½”ë“œ ì„ ì •
   - ì •ë³´ í†µí•©
\`\`\`

## ì£¼ìš” ìœ ì‚¬ë„ ë©”íŠ¸ë¦­

| ë©”íŠ¸ë¦­ | íŠ¹ì§• | ì í•©í•œ ê²½ìš° |
|--------|------|------------|
| **Jaro-Winkler** | ë¬¸ì ìˆœì„œ ì¤‘ì‹œ, ì ‘ë‘ì‚¬ ê°€ì¤‘ì¹˜ | ì´ë¦„ ë§¤ì¹­ |
| **Levenshtein** | í¸ì§‘ ê±°ë¦¬ | ì˜¤íƒ€ ì²˜ë¦¬ |
| **Jaccard** | ì§‘í•© ìœ ì‚¬ë„ | í† í° ë¹„êµ |
| **Cosine** | ë²¡í„° ê°ë„ | TF-IDF ê¸°ë°˜ |
| **Soundex/Metaphone** | ë°œìŒ ê¸°ë°˜ | ì˜ì–´ ì´ë¦„ |

### Jaro-Winkler ì˜ˆì‹œ

\`\`\`python
# Jaro-Winkler: 0 ~ 1 (ë†’ì„ìˆ˜ë¡ ìœ ì‚¬)

"MARTHA" vs "MARHTA" â†’ 0.961  # ë§¤ìš° ìœ ì‚¬
"ê¹€ì² ìˆ˜" vs "ê¹€ì² í˜¸" â†’ 0.867    # ìœ ì‚¬
"ì‚¼ì„±" vs "Samsung" â†’ 0.0     # ë‹¤ë¥¸ ì–¸ì–´, ë‚®ìŒ
\`\`\`

## Blocking ì „ëµ

\`\`\`
ë¬¸ì œ: nê°œ ë ˆì½”ë“œ â†’ n(n-1)/2 ë¹„êµ í•„ìš”
     100ë§Œ ë ˆì½”ë“œ â†’ 5000ì–µ ë¹„êµ!

í•´ê²°: Blockingìœ¼ë¡œ í›„ë³´ ì¶•ì†Œ

Blocking ë°©ë²•:
1. Standard Blocking: ê°™ì€ í‚¤ ê°’ë¼ë¦¬ë§Œ ë¹„êµ
   - ì˜ˆ: ê°™ì€ ë„ì‹œ, ê°™ì€ ì‚°ì—…êµ°

2. Sorted Neighborhood: ì •ë ¬ í›„ ìœˆë„ìš° ë‚´ ë¹„êµ
   - ì˜ˆ: ì´ë¦„ ì •ë ¬ í›„ ì¸ì ‘ 10ê°œë§Œ ë¹„êµ

3. LSH (Locality-Sensitive Hashing): í•´ì‹œ ì¶©ëŒ ê¸°ë°˜
   - ì˜ˆ: MinHashë¡œ ìœ ì‚¬ ë¬¸ì„œ ê·¸ë£¹í™”
\`\`\`

## ì‹¤ì œ ì‚¬ë¡€: Palantir

\`\`\`
Palantir Gothamì˜ í•µì‹¬ ê¸°ëŠ¥:
- ë‹¤ì¤‘ ì •ë³´ ì†ŒìŠ¤ (SIGINT, HUMINT, OSINT ë“±) í†µí•©
- Entity Resolutionìœ¼ë¡œ ë™ì¼ ì¸ë¬¼/ì¡°ì§ ì‹ë³„
- ê´€ê³„ ì¶”ë¡ ìœ¼ë¡œ ë„¤íŠ¸ì›Œí¬ ë¶„ì„

ì˜ˆ: "Muhammad" vs "Mohammed" vs "Ù…Ø­Ù…Ø¯"
    â†’ ê°™ì€ ì‚¬ëŒ? ë‹¤ë¥¸ ì‚¬ëŒ?
    â†’ ì¶”ê°€ ì†ì„±(ìƒë…„ì›”ì¼, ìœ„ì¹˜ ë“±)ìœ¼ë¡œ íŒë‹¨
\`\`\`

## í•µì‹¬ í¬ì¸íŠ¸

1. **ER = ê°™ì€ ì—”í‹°í‹°ì˜ ë‹¤ë¥¸ í‘œí˜„ì„ í†µí•©**
2. **Blockingìœ¼ë¡œ ë¹„êµ ëŒ€ìƒ ì¶•ì†Œ**
3. **ìœ ì‚¬ë„ ë©”íŠ¸ë¦­ìœ¼ë¡œ ë§¤ì¹­ íŒë‹¨**
4. **Knowledge Graph êµ¬ì¶•ì˜ í•µì‹¬ ë‹¨ê³„**
        `,
        keyPoints: [
          'Entity Resolutionì€ ê°™ì€ ì—”í‹°í‹°ì˜ ë‹¤ë¥¸ í‘œí˜„ì„ ì‹ë³„í•˜ê³  í†µí•©',
          'Blockingìœ¼ë¡œ ë¹„êµ ëŒ€ìƒì„ ì¶•ì†Œí•˜ì—¬ ì„±ëŠ¥ í™•ë³´',
          'Jaro-Winkler, Levenshtein ë“± ìœ ì‚¬ë„ ë©”íŠ¸ë¦­ í™œìš©',
          'KG êµ¬ì¶•, ë°ì´í„° í†µí•©, ì¤‘ë³µ ì œê±°ì— í•„ìˆ˜',
        ],
        practiceGoal: 'Entity Resolutionì˜ ê°œë…ê³¼ íŒŒì´í”„ë¼ì¸ì„ ì´í•´í•œë‹¤',
      }
    ),

    // Task 2: ë¬¸ìì—´ ìœ ì‚¬ë„ ì•Œê³ ë¦¬ì¦˜ (35ë¶„)
    createCodeTask(
      'w4d1-string-similarity',
      'ë¬¸ìì—´ ìœ ì‚¬ë„ ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„',
      35,
      {
        introduction: `
# ë¬¸ìì—´ ìœ ì‚¬ë„ ì•Œê³ ë¦¬ì¦˜

## ğŸ¯ ì™œ ë¬¸ìì—´ ìœ ì‚¬ë„ê°€ í•„ìš”í•œê°€?

### ë¬¸ì œ ìƒí™©
ê¸°ì—… ë°ì´í„° í†µí•© ì‹œ **ì •í™•íˆ ê°™ì§€ ì•Šì§€ë§Œ ê°™ì€ ì˜ë¯¸**ì˜ í…ìŠ¤íŠ¸ë¥¼ ì–´ë–»ê²Œ ë¹„êµí• ê¹Œ?
- "ì‚¼ì„±ì „ì" vs "Samsung Electronics" vs "ì‚¼ì„±ì „ìì£¼ì‹íšŒì‚¬"
- "ê¹€ì² ìˆ˜" vs "ê¹€ì² í˜¸" (ì˜¤íƒ€)
- "Smith" vs "Smyth" (ë°œìŒì€ ê°™ìŒ)

### í•´ê²°ì±…
> ğŸ¯ **ë¹„ìœ **: ë¬¸ìì—´ ìœ ì‚¬ë„ëŠ” **DNA ìœ ì‚¬ë„ ê²€ì‚¬**ì™€ ê°™ìŠµë‹ˆë‹¤.
>
> ì™„ì „íˆ ì¼ì¹˜í•˜ì§€ ì•Šì•„ë„ ì–¼ë§ˆë‚˜ ë¹„ìŠ·í•œì§€ë¥¼ 0~1 ì‚¬ì´ ì ìˆ˜ë¡œ ì¸¡ì •í•©ë‹ˆë‹¤.
> - Levenshtein: "ëª‡ ë²ˆ ê³ ì¹˜ë©´ ê°™ì•„ì§€ë‚˜?" (í¸ì§‘ íšŸìˆ˜)
> - Jaro-Winkler: "ì´ë¦„ì²˜ëŸ¼ ì•ë¶€ë¶„ì´ ê°™ìœ¼ë©´ ì ìˆ˜ ë†’ì„"
> - Jaccard: "ê³µí†µ ë‹¨ì–´ê°€ ì–¼ë§ˆë‚˜ ë§ë‚˜?"

## í•™ìŠµ ëª©í‘œ
- ì£¼ìš” ë¬¸ìì—´ ìœ ì‚¬ë„ ì•Œê³ ë¦¬ì¦˜ì„ ì´í•´í•œë‹¤
- Pythonìœ¼ë¡œ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•œë‹¤
- ì ì ˆí•œ ë©”íŠ¸ë¦­ì„ ì„ íƒí•  ìˆ˜ ìˆë‹¤

## Python ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜

\`\`\`bash
pip install jellyfish python-Levenshtein fuzzywuzzy
\`\`\`

## 1. Levenshtein Distance (í¸ì§‘ ê±°ë¦¬)

\`\`\`python
import Levenshtein

# ë‘ ë¬¸ìì—´ ê°„ í¸ì§‘ ê±°ë¦¬
s1 = "ì‚¼ì„±ì „ì"
s2 = "ì‚¼ì„±ì „ìì£¼ì‹íšŒì‚¬"

distance = Levenshtein.distance(s1, s2)
print(f"í¸ì§‘ ê±°ë¦¬: {distance}")  # 4

# ì •ê·œí™”ëœ ìœ ì‚¬ë„ (0~1)
ratio = Levenshtein.ratio(s1, s2)
print(f"ìœ ì‚¬ë„: {ratio:.3f}")  # 0.667
\`\`\`

### í¸ì§‘ ê±°ë¦¬ ì‹œê°í™”

\`\`\`
"ì‚¼ì„±ì „ì" â†’ "ì‚¼ì„±ì „ìì£¼ì‹íšŒì‚¬"

ì‚½ì…: +ì£¼ +ì‹ +íšŒ +ì‚¬ = 4íšŒ í¸ì§‘
\`\`\`

## 2. Jaro-Winkler Similarity

\`\`\`python
import jellyfish

# Jaro similarity (0~1)
jaro = jellyfish.jaro_similarity("MARTHA", "MARHTA")
print(f"Jaro: {jaro:.3f}")  # 0.944

# Jaro-Winkler (ì ‘ë‘ì‚¬ ê°€ì¤‘ì¹˜ ì¶”ê°€)
jw = jellyfish.jaro_winkler_similarity("MARTHA", "MARHTA")
print(f"Jaro-Winkler: {jw:.3f}")  # 0.961

# í•œê¸€ ì˜ˆì‹œ
jw_ko = jellyfish.jaro_winkler_similarity("ê¹€ì² ìˆ˜", "ê¹€ì² í˜¸")
print(f"ê¹€ì² ìˆ˜ vs ê¹€ì² í˜¸: {jw_ko:.3f}")  # 0.867
\`\`\`

### ì–¸ì œ ì‚¬ìš©?
- ì´ë¦„ ë§¤ì¹­ì— ê°€ì¥ ì í•©
- ì ‘ë‘ì‚¬ê°€ ê°™ìœ¼ë©´ ë” ë†’ì€ ì ìˆ˜
- ì˜¤íƒ€ì— ê°•ì¸í•¨

## 3. Jaccard Similarity (í† í° ê¸°ë°˜)

\`\`\`python
def jaccard_similarity(s1, s2):
    """ë‹¨ì–´/ë¬¸ì ì§‘í•© ê¸°ë°˜ ìœ ì‚¬ë„"""
    set1 = set(s1.split())
    set2 = set(s2.split())

    intersection = len(set1 & set2)
    union = len(set1 | set2)

    return intersection / union if union > 0 else 0

# ì˜ˆì‹œ
s1 = "Samsung Electronics Co Ltd"
s2 = "Samsung Electronics Corporation"

print(f"Jaccard: {jaccard_similarity(s1, s2):.3f}")  # 0.4

# ë¬¸ì ë‹¨ìœ„ Jaccard
def char_jaccard(s1, s2):
    set1 = set(s1)
    set2 = set(s2)
    return len(set1 & set2) / len(set1 | set2)

print(f"Char Jaccard: {char_jaccard(s1, s2):.3f}")  # 0.64
\`\`\`

## 4. FuzzyWuzzy (ì¢…í•© ë„êµ¬)

\`\`\`python
from fuzzywuzzy import fuzz, process

# ë‹¤ì–‘í•œ ìœ ì‚¬ë„ ì¸¡ì •
s1 = "ì‚¼ì„±ì „ì ì£¼ì‹íšŒì‚¬"
s2 = "ì‚¼ì„±ì „ì"

print(f"Simple Ratio: {fuzz.ratio(s1, s2)}")           # 73
print(f"Partial Ratio: {fuzz.partial_ratio(s1, s2)}")  # 100
print(f"Token Sort: {fuzz.token_sort_ratio(s1, s2)}")  # 73
print(f"Token Set: {fuzz.token_set_ratio(s1, s2)}")    # 100

# ìµœì  ë§¤ì¹­ ì°¾ê¸°
companies = ["ì‚¼ì„±ì „ì", "SKí•˜ì´ë‹‰ìŠ¤", "LGì „ì", "í˜„ëŒ€ìë™ì°¨"]
query = "ì‚¼ì„±"

best_match = process.extractOne(query, companies)
print(f"Best match: {best_match}")  # ('ì‚¼ì„±ì „ì', 90)

# ìƒìœ„ Nê°œ ë§¤ì¹­
top_matches = process.extract(query, companies, limit=3)
print(f"Top 3: {top_matches}")
\`\`\`

## 5. ìŒì„± ê¸°ë°˜ (Soundex, Metaphone)

\`\`\`python
import jellyfish

# Soundex: ì˜ì–´ ë°œìŒ ê¸°ë°˜ ì½”ë“œ
print(jellyfish.soundex("Robert"))   # R163
print(jellyfish.soundex("Rupert"))   # R163 (ê°™ìŒ!)

# Metaphone: ë” ì •êµí•œ ë°œìŒ ì½”ë“œ
print(jellyfish.metaphone("Smith"))  # SM0
print(jellyfish.metaphone("Smyth"))  # SM0 (ê°™ìŒ!)

# NYSIIS: ë¯¸êµ­ì‹ ë°œìŒ ì½”ë“œ
print(jellyfish.nysiis("Macintosh"))  # MCANT
print(jellyfish.nysiis("McIntosh"))   # MCANT
\`\`\`

## 6. í•œê¸€ íŠ¹í™” ì²˜ë¦¬

\`\`\`python
from konlpy.tag import Okt
import jellyfish

okt = Okt()

def korean_similarity(s1, s2):
    """í•œê¸€ í† í° ê¸°ë°˜ ìœ ì‚¬ë„"""
    # í˜•íƒœì†Œ ë¶„ì„ìœ¼ë¡œ í† í° ì¶”ì¶œ
    tokens1 = set(okt.morphs(s1))
    tokens2 = set(okt.morphs(s2))

    # Jaccard ìœ ì‚¬ë„
    intersection = len(tokens1 & tokens2)
    union = len(tokens1 | tokens2)

    return intersection / union if union > 0 else 0

# ì˜ˆì‹œ
s1 = "ì‚¼ì„±ì „ì ë°˜ë„ì²´ ì‚¬ì—…ë¶€"
s2 = "ì‚¼ì„± ë°˜ë„ì²´"

print(f"Korean similarity: {korean_similarity(s1, s2):.3f}")

# ì´ˆì„± ì¶”ì¶œ
def get_chosung(text):
    """í•œê¸€ ì´ˆì„± ì¶”ì¶œ"""
    CHOSUNG = ['ã„±', 'ã„²', 'ã„´', 'ã„·', 'ã„¸', 'ã„¹', 'ã…', 'ã…‚', 'ã…ƒ',
               'ã……', 'ã…†', 'ã…‡', 'ã…ˆ', 'ã…‰', 'ã…Š', 'ã…‹', 'ã…Œ', 'ã…', 'ã…']
    result = []
    for char in text:
        if 'ê°€' <= char <= 'í£':
            code = ord(char) - ord('ê°€')
            result.append(CHOSUNG[code // 588])
        else:
            result.append(char)
    return ''.join(result)

print(get_chosung("ì‚¼ì„±ì „ì"))  # ã……ã……ã…ˆã…ˆ
print(get_chosung("ì‚¼ì„±"))      # ã……ã……
\`\`\`

## ìœ ì‚¬ë„ ë©”íŠ¸ë¦­ ë¹„êµí‘œ

| ë©”íŠ¸ë¦­ | ì¥ì  | ë‹¨ì  | ì í•©í•œ ê²½ìš° |
|--------|------|------|------------|
| Levenshtein | ì§ê´€ì , ë²”ìš© | ëŠë¦¼ | ì§§ì€ ë¬¸ìì—´, ì˜¤íƒ€ |
| Jaro-Winkler | ì´ë¦„ì— ìµœì í™” | ê¸´ ë¬¸ìì—´ì— ë¶€ì í•© | ì‚¬ëŒ ì´ë¦„ |
| Jaccard | ë‹¨ì–´ ìˆœì„œ ë¬´ê´€ | ì§§ì€ ë¬¸ìì—´ì— ë¶€ì •í™• | ë¬¸ì„œ, íƒœê·¸ |
| Soundex | ë°œìŒ ê¸°ë°˜ | ì˜ì–´ë§Œ | ì˜ì–´ ì´ë¦„ |
| FuzzyWuzzy | ë‹¤ì–‘í•œ ì˜µì…˜ | ëŠë¦¼ | ë²”ìš© |

## í•µì‹¬ í¬ì¸íŠ¸

1. **Jaro-Winkler** = ì´ë¦„ ë§¤ì¹­ì˜ í‘œì¤€
2. **Jaccard** = í† í°/ë‹¨ì–´ ê¸°ë°˜ ë¹„êµ
3. **FuzzyWuzzy** = ë‹¤ì–‘í•œ ìƒí™©ì— ëŒ€ì‘
4. **í•œê¸€** = í˜•íƒœì†Œ ë¶„ì„ + ì´ˆì„± ì¶”ì¶œ í™œìš©

---

## âš ï¸ Common Pitfalls (ìì£¼ í•˜ëŠ” ì‹¤ìˆ˜)

### 1. [ì„ê³„ê°’] ëª¨ë“  ìƒí™©ì— ê°™ì€ ì„ê³„ê°’ ì‚¬ìš©

**ì¦ìƒ**: ë„ˆë¬´ ë§ì€ ë§¤ì¹­ ë˜ëŠ” ë†“ì¹˜ëŠ” ë§¤ì¹­

\`\`\`python
# âŒ ì˜ëª»ëœ ì˜ˆì‹œ - ê³ ì • ì„ê³„ê°’
if similarity > 0.8:  # í•­ìƒ 80%?
    match = True
\`\`\`

**ì™œ ì˜ëª»ë˜ì—ˆë‚˜**:
- ì§§ì€ ì´ë¦„ (ì˜ˆ: "ì´ì² ìˆ˜")ì€ 0.9ì—ì„œë„ ì˜¤ë§¤ì¹­ ê°€ëŠ¥
- ê¸´ íšŒì‚¬ëª…ì€ 0.7ì—ì„œë„ ì •í™•íˆ ë§¤ì¹­

\`\`\`python
# âœ… ì˜¬ë°”ë¥¸ ì˜ˆì‹œ - ë°ì´í„° íŠ¹ì„±ì— ë§ì¶˜ ì„ê³„ê°’
if len(s1) <= 5:
    threshold = 0.9  # ì§§ì€ ë¬¸ìì—´ì€ ì—„ê²©í•˜ê²Œ
else:
    threshold = 0.75  # ê¸´ ë¬¸ìì—´ì€ ëŠìŠ¨í•˜ê²Œ
\`\`\`

---

### 2. [ë©”íŠ¸ë¦­ ì„ íƒ] ì´ë¦„ì— Jaccard ì‚¬ìš©

**ì¦ìƒ**: "ê¹€ì² ìˆ˜" vs "ì´ì² ìˆ˜"ê°€ ë†’ì€ ìœ ì‚¬ë„

\`\`\`python
# âŒ ì˜ëª»ëœ ì˜ˆì‹œ - ì´ë¦„ì— ë¬¸ì Jaccard
char_jaccard("ê¹€ì² ìˆ˜", "ì´ì² ìˆ˜")  # 0.6 (ì² , ìˆ˜ ê³µìœ )
\`\`\`

**ì™œ ì˜ëª»ë˜ì—ˆë‚˜**:
- ì´ë¦„ì€ ìˆœì„œê°€ ì¤‘ìš” (ì„± + ì´ë¦„)
- JaccardëŠ” ìˆœì„œë¥¼ ë¬´ì‹œ

\`\`\`python
# âœ… ì˜¬ë°”ë¥¸ ì˜ˆì‹œ - ì´ë¦„ì— Jaro-Winkler
jellyfish.jaro_winkler_similarity("ê¹€ì² ìˆ˜", "ì´ì² ìˆ˜")  # 0.56 (ë‚®ìŒ)
jellyfish.jaro_winkler_similarity("ê¹€ì² ìˆ˜", "ê¹€ì² í˜¸")  # 0.87 (ë†’ìŒ)
\`\`\`

**ê¸°ì–µí•  ì **:
> ì´ë¦„ = Jaro-Winkler, ë¬¸ì„œ/íƒœê·¸ = Jaccard
        `,
        keyPoints: [
          'ğŸ¯ Levenshteinì€ í¸ì§‘ ê±°ë¦¬ ê¸°ë°˜, ì˜¤íƒ€ ì²˜ë¦¬ì— ì í•©',
          'ğŸ‘¤ Jaro-WinklerëŠ” ì´ë¦„ ë§¤ì¹­ì— ìµœì í™”',
          'ğŸ”¤ JaccardëŠ” í† í° ì§‘í•© ê¸°ë°˜ ìœ ì‚¬ë„',
          'ğŸ‡°ğŸ‡· í•œê¸€ì€ í˜•íƒœì†Œ ë¶„ì„ê³¼ ì´ˆì„± ì¶”ì¶œ í™œìš©',
        ],
        practiceGoal: 'ë‹¤ì–‘í•œ ë¬¸ìì—´ ìœ ì‚¬ë„ ì•Œê³ ë¦¬ì¦˜ì„ Pythonìœ¼ë¡œ êµ¬í˜„í•˜ê³  ë¹„êµí•  ìˆ˜ ìˆë‹¤',
      }
    ),

    // Task 3: Python recordlinkage ë¼ì´ë¸ŒëŸ¬ë¦¬ (40ë¶„)
    createCodeTask(
      'w4d1-recordlinkage',
      'Python recordlinkage ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‹¤ìŠµ',
      40,
      {
        introduction: `
# Python recordlinkage ë¼ì´ë¸ŒëŸ¬ë¦¬

## ğŸ¯ ì™œ recordlinkageê°€ í•„ìš”í•œê°€?

### ë¬¸ì œ ìƒí™©
10ë§Œ ê°œ ê¸°ì—… ë°ì´í„°ë¥¼ í•˜ë‚˜í•˜ë‚˜ ë¹„êµí•˜ë©´?
- 100,000 Ã— 99,999 / 2 = **50ì–µ ë²ˆ ë¹„êµ!** â³
- ë¬¸ìì—´ ìœ ì‚¬ë„ë§Œìœ¼ë¡œëŠ” ë„ˆë¬´ ëŠë¦¼

### í•´ê²°ì±…
> ğŸ­ **ë¹„ìœ **: recordlinkageëŠ” **ê³µì¥ ìë™í™” ë¼ì¸**ì…ë‹ˆë‹¤.
>
> 1ë‹¨ê³„(Blocking): ê°™ì€ ìƒ‰ê¹”ë¼ë¦¬ë§Œ ë¹„êµ (í›„ë³´ ì¶•ì†Œ)
> 2ë‹¨ê³„(Comparison): ìœ ì‚¬ë„ ê³„ì‚° (í’ˆì§ˆ ê²€ì‚¬)
> 3ë‹¨ê³„(Classification): í•©ê²©/ë¶ˆí•©ê²© íŒì • (ìµœì¢… ì„ ë³„)

## í•™ìŠµ ëª©í‘œ
- recordlinkage ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•˜ê³  ì‚¬ìš©í•œë‹¤
- Blocking, Comparison, Classification íŒŒì´í”„ë¼ì¸ì„ êµ¬í˜„í•œë‹¤
- ì‹¤ì œ ë°ì´í„°ë¡œ ì¤‘ë³µ ë ˆì½”ë“œë¥¼ íƒì§€í•œë‹¤

## ì„¤ì¹˜

\`\`\`bash
pip install recordlinkage pandas
\`\`\`

## ê¸°ë³¸ ì‚¬ìš©ë²•

\`\`\`python
import recordlinkage
import pandas as pd

# ìƒ˜í”Œ ë°ì´í„°
df = pd.DataFrame({
    'id': [1, 2, 3, 4, 5],
    'name': ['ì‚¼ì„±ì „ì', 'Samsung Electronics', 'ì‚¼ì„±', 'LGì „ì', 'LG Electronics'],
    'city': ['ìˆ˜ì›', 'Suwon', 'ìˆ˜ì›', 'ì„œìš¸', 'Seoul'],
    'employees': [270000, 267000, 270000, 75000, 74000]
})

print(df)
\`\`\`

## Step 1: Indexing (Blocking)

\`\`\`python
# ì¸ë±ì„œ ìƒì„±
indexer = recordlinkage.Index()

# Blocking ì „ëµ ì„ íƒ
# 1. Full: ëª¨ë“  ìŒ ë¹„êµ (ì‘ì€ ë°ì´í„°ì…‹ìš©)
indexer.full()

# 2. Block: íŠ¹ì • ì—´ì´ ê°™ì€ ê²ƒë§Œ ë¹„êµ
# indexer.block('city')

# 3. Sorted Neighborhood: ì •ë ¬ í›„ ìœˆë„ìš° ë‚´ ë¹„êµ
# indexer.sortedneighbourhood('name', window=5)

# í›„ë³´ ìŒ ìƒì„±
candidate_pairs = indexer.index(df)
print(f"ë¹„êµí•  ìŒ ìˆ˜: {len(candidate_pairs)}")
# 5C2 = 10ìŒ
\`\`\`

## Step 2: Comparison

\`\`\`python
# ë¹„êµê¸° ìƒì„±
compare = recordlinkage.Compare()

# ê° ì†ì„±ë³„ ë¹„êµ ë°©ë²• ì„¤ì •
compare.string('name', 'name', method='jarowinkler', label='name_sim')
compare.string('city', 'city', method='levenshtein', label='city_sim')
compare.numeric('employees', 'employees', scale=10000, label='emp_sim')

# ë¹„êµ ì‹¤í–‰
features = compare.compute(candidate_pairs, df)
print(features)
\`\`\`

### ë¹„êµ ê²°ê³¼ ì˜ˆì‹œ

\`\`\`
         name_sim  city_sim  emp_sim
(0, 1)     0.78      0.60    0.997
(0, 2)     0.67      1.00    1.000
(0, 3)     0.44      0.50    0.195
...
\`\`\`

## Step 3: Classification

\`\`\`python
# ë°©ë²• 1: ì„ê³„ê°’ ê¸°ë°˜
matches = features[features.sum(axis=1) >= 2.0]
print(f"ë§¤ì¹­ëœ ìŒ: {len(matches)}")
print(matches)

# ë°©ë²• 2: ê°œë³„ ì†ì„± ì„ê³„ê°’
matches = features[
    (features['name_sim'] > 0.6) &
    (features['city_sim'] > 0.5)
]

# ë°©ë²• 3: ë¨¸ì‹ ëŸ¬ë‹ (ì§€ë„ í•™ìŠµ)
from recordlinkage.classifiers import LogisticRegression

# í•™ìŠµ ë°ì´í„° (ì •ë‹µ ë ˆì´ë¸” í•„ìš”)
true_matches = pd.MultiIndex.from_tuples([(0, 1), (0, 2), (3, 4)])
true_nonmatches = pd.MultiIndex.from_tuples([(0, 3), (1, 3)])

classifier = LogisticRegression()
classifier.fit(features, true_matches)

# ì˜ˆì¸¡
predictions = classifier.predict(features)
\`\`\`

## ì™„ì „í•œ ì˜ˆì œ: ê¸°ì—… ì¤‘ë³µ íƒì§€

\`\`\`python
import recordlinkage
import pandas as pd

# ğŸ“Œ Step 1: ê¸°ì—… ë°ì´í„° ì¤€ë¹„
companies = pd.DataFrame({
    'name': ['ì‚¼ì„±ì „ì', 'Samsung Electronics', 'ì‚¼ì„±ì „ìì£¼ì‹íšŒì‚¬',
             'LGì „ì', 'LG Electronics', 'SKí•˜ì´ë‹‰ìŠ¤'],
    'industry': ['ì „ì', 'Electronics', 'ë°˜ë„ì²´',
                 'ì „ì', 'Electronics', 'ë°˜ë„ì²´'],
    'employees': [270000, 267000, 270000, 75000, 74000, 30000]
})

# ğŸ“Œ Step 2: Blocking - í›„ë³´ ìŒ ìƒì„±
indexer = recordlinkage.Index()
indexer.full()  # ì‘ì€ ë°ì´í„°ì…‹ì´ë¯€ë¡œ ì „ì²´ ë¹„êµ
pairs = indexer.index(companies)
print(f"ë¹„êµí•  ìŒ: {len(pairs)}")  # 15ìŒ

# ğŸ“Œ Step 3: Comparison - ìœ ì‚¬ë„ ê³„ì‚°
compare = recordlinkage.Compare()
compare.string('name', 'name', method='jarowinkler', label='name')
compare.string('industry', 'industry', method='jarowinkler', label='industry')
compare.numeric('employees', 'employees', scale=10000, label='emp')

features = compare.compute(pairs, companies)

# ğŸ“Œ Step 4: Classification - ë§¤ì¹­ íŒì •
matches = features[features['name'] >= 0.7]

# ğŸ“Œ Step 5: ê²°ê³¼ ì¶œë ¥
print("\\n=== ì¤‘ë³µ í›„ë³´ ===")
for (i, j) in matches.index:
    print(f"{companies.loc[i, 'name']} â†” {companies.loc[j, 'name']}")
    print(f"  ìœ ì‚¬ë„: name={features.loc[(i,j)]['name']:.2f}")
\`\`\`

### ì¶œë ¥ ì˜ˆì‹œ

\`\`\`
=== ì¤‘ë³µ í›„ë³´ ===
ì‚¼ì„±ì „ì â†” Samsung Electronics
  ìœ ì‚¬ë„: {'name': 0.78, 'industry': 0.60, 'employees': 0.997}

ì‚¼ì„±ì „ì â†” ì‚¼ì„±ì „ìì£¼ì‹íšŒì‚¬
  ìœ ì‚¬ë„: {'name': 0.80, 'industry': 0.50, 'employees': 1.0}

LGì „ì â†” LG Electronics
  ìœ ì‚¬ë„: {'name': 0.72, 'industry': 0.60, 'employees': 0.99}
...
\`\`\`

## Blocking ì„±ëŠ¥ ë¹„êµ

\`\`\`python
import time

# ëŒ€ê·œëª¨ ë°ì´í„° ì‹œë®¬ë ˆì´ì…˜
large_df = pd.concat([companies] * 100, ignore_index=True)
print(f"ë ˆì½”ë“œ ìˆ˜: {len(large_df)}")

# Full indexing (ëª¨ë“  ìŒ)
indexer_full = recordlinkage.Index()
indexer_full.full()

start = time.time()
pairs_full = indexer_full.index(large_df)
print(f"Full: {len(pairs_full)} ìŒ, {time.time()-start:.2f}ì´ˆ")

# Sorted Neighborhood
indexer_sn = recordlinkage.Index()
indexer_sn.sortedneighbourhood('name', window=5)

start = time.time()
pairs_sn = indexer_sn.index(large_df)
print(f"SortedNeighbourhood: {len(pairs_sn)} ìŒ, {time.time()-start:.2f}ì´ˆ")
\`\`\`

## í•µì‹¬ í¬ì¸íŠ¸

1. **recordlinkage** = Python ER í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬
2. **3ë‹¨ê³„**: Indexing â†’ Comparison â†’ Classification
3. **Blocking**ìœ¼ë¡œ ë¹„êµ ëŒ€ìƒ ì¶•ì†Œ
4. **ì„ê³„ê°’ ë˜ëŠ” ML**ë¡œ ë§¤ì¹­ íŒì •
        `,
        keyPoints: [
          'ğŸ­ recordlinkageëŠ” Python Entity Resolution í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬',
          'ğŸ“Š Index(Blocking) â†’ Compare â†’ Classify 3ë‹¨ê³„ íŒŒì´í”„ë¼ì¸',
          'âš¡ Blockingìœ¼ë¡œ ë¹„êµ ëŒ€ìƒì„ ì¤„ì—¬ ì„±ëŠ¥ í™•ë³´',
          'ğŸ¯ ì„ê³„ê°’ ë˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹ìœ¼ë¡œ ë§¤ì¹­ íŒì •',
        ],
        practiceGoal: 'recordlinkageë¡œ ì¤‘ë³µ ë ˆì½”ë“œë¥¼ íƒì§€í•˜ëŠ” íŒŒì´í”„ë¼ì¸ì„ êµ¬í˜„í•  ìˆ˜ ìˆë‹¤',
      }
    ),

    // Task 4: Neo4jì—ì„œ Entity Resolution (35ë¶„)
    createCodeTask(
      'w4d1-neo4j-er',
      'Neo4jì—ì„œ Entity Resolution êµ¬í˜„',
      35,
      {
        introduction: `
# Neo4jì—ì„œ Entity Resolution

## ğŸ¯ ì™œ Neo4jì—ì„œ ERì„ í•˜ëŠ”ê°€?

### ë¬¸ì œ ìƒí™©
Pythonìœ¼ë¡œ ì¤‘ë³µì„ ì°¾ì•˜ëŠ”ë°, ì´ë¯¸ Neo4jì— ì €ì¥ëœ ë°ì´í„°ë„ ì¤‘ë³µì´ ìˆë‹¤ë©´?
- ì‚­ì œëœ ì¤„ ì•Œì•˜ëŠ”ë° ë‹¤ì‹œ ë‚˜íƒ€ë‚¨
- ê´€ê³„ê¹Œì§€ ì—°ê²°ë˜ì–´ ìˆì–´ì„œ ë³µì¡í•¨

### í•´ê²°ì±…
> ğŸ”— **ë¹„ìœ **: Neo4j ERì€ **ê±´ë¬¼ í†µí•© ê³µì‚¬**ì…ë‹ˆë‹¤.
>
> ë‘ ê±´ë¬¼(ë…¸ë“œ)ì„ í•©ì¹  ë•Œ ì „ê¸°ì¤„(ê´€ê³„)ë„ í•¨ê»˜ ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
> APOCì˜ mergeNodesëŠ” ë…¸ë“œ + ê´€ê³„ + ì†ì„±ì„ í•œ ë²ˆì— í†µí•©!

## í•™ìŠµ ëª©í‘œ
- Neo4jì—ì„œ ìœ ì‚¬ ë…¸ë“œë¥¼ íƒì§€í•œë‹¤
- APOCì„ í™œìš©í•œ ë¬¸ìì—´ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•œë‹¤
- ì¤‘ë³µ ë…¸ë“œë¥¼ ë³‘í•©í•œë‹¤

## APOC ë¬¸ìì—´ ìœ ì‚¬ë„ í•¨ìˆ˜

\`\`\`cypher
// ì„¤ì¹˜ í™•ì¸
RETURN apoc.text.jaroWinklerDistance("ì‚¼ì„±ì „ì", "ì‚¼ì„±") AS similarity
// 0.867

// ë‹¤ì–‘í•œ ìœ ì‚¬ë„ í•¨ìˆ˜
RETURN
  apoc.text.jaroWinklerDistance("Samsung", "Samsng") AS jaroWinkler,
  apoc.text.levenshteinDistance("Samsung", "Samsng") AS levenshtein,
  apoc.text.sorensenDiceSimilarity("Samsung Electronics", "Samsung") AS dice,
  apoc.text.fuzzyMatch("Samsung", "Samsng") AS fuzzy
\`\`\`

## ìœ ì‚¬ ë…¸ë“œ íƒì§€

\`\`\`cypher
// ì´ë¦„ì´ ìœ ì‚¬í•œ íšŒì‚¬ ìŒ ì°¾ê¸°
MATCH (a:Company), (b:Company)
WHERE a.id < b.id  // ì¤‘ë³µ ìŒ ë°©ì§€
  AND apoc.text.jaroWinklerDistance(a.name, b.name) > 0.8
RETURN
  a.name AS company1,
  b.name AS company2,
  apoc.text.jaroWinklerDistance(a.name, b.name) AS similarity
ORDER BY similarity DESC
LIMIT 20
\`\`\`

## Blockingìœ¼ë¡œ ì„±ëŠ¥ ìµœì í™”

\`\`\`cypher
// ê°™ì€ ì‚°ì—…êµ° ë‚´ì—ì„œë§Œ ë¹„êµ (Blocking)
MATCH (a:Company), (b:Company)
WHERE a.id < b.id
  AND a.industry = b.industry  // Blocking ì¡°ê±´
  AND apoc.text.jaroWinklerDistance(a.name, b.name) > 0.8
RETURN a.name, b.name,
       apoc.text.jaroWinklerDistance(a.name, b.name) AS similarity
\`\`\`

## ë…¸ë“œ ë³‘í•©

### ë°©ë²• 1: MERGE ì‚¬ìš©

\`\`\`cypher
// ê¸°ì¡´ ë…¸ë“œì˜ ê´€ê³„ë¥¼ ìƒˆ ë…¸ë“œë¡œ ì´ì „
MATCH (old:Company {name: "Samsung Electronics"})
MATCH (new:Company {name: "ì‚¼ì„±ì „ì"})

// ê´€ê³„ ë³µì‚¬
MATCH (old)-[r:SUPPLIES_TO]->(target)
CREATE (new)-[:SUPPLIES_TO]->(target)

// ì†ì„± ë³‘í•©
SET new.aliases = coalesce(new.aliases, []) + old.name
SET new.employees = CASE
  WHEN new.employees IS NULL THEN old.employees
  ELSE new.employees
END

// ì˜¤ë˜ëœ ë…¸ë“œ ì‚­ì œ
DETACH DELETE old
\`\`\`

### ë°©ë²• 2: APOC mergeNodes ì‚¬ìš©

\`\`\`cypher
// APOCìœ¼ë¡œ ë…¸ë“œ ë³‘í•©
MATCH (a:Company {name: "ì‚¼ì„±ì „ì"})
MATCH (b:Company {name: "Samsung Electronics"})
CALL apoc.refactor.mergeNodes([a, b], {
  properties: 'combine',
  mergeRels: true
})
YIELD node
RETURN node
\`\`\`

### ì†ì„± ë³‘í•© ì „ëµ

\`\`\`cypher
// properties ì˜µì…˜:
// 'overwrite' - ë§ˆì§€ë§‰ ë…¸ë“œì˜ ê°’ ì‚¬ìš©
// 'discard' - ì²« ë…¸ë“œì˜ ê°’ ìœ ì§€
// 'combine' - ë°°ì—´ë¡œ ê²°í•©

CALL apoc.refactor.mergeNodes([a, b], {
  properties: {
    name: 'discard',          // ì²« ë²ˆì§¸ ì´ë¦„ ìœ ì§€
    aliases: 'combine',       // ë³„ì¹­ ë°°ì—´ë¡œ ê²°í•©
    employees: 'overwrite',   // ë§ˆì§€ë§‰ ê°’ ì‚¬ìš©
    '*': 'discard'            // ë‚˜ë¨¸ì§€ëŠ” ì²« ë²ˆì§¸ ê°’
  },
  mergeRels: true
})
\`\`\`

## ë°°ì¹˜ ì²˜ë¦¬

\`\`\`cypher
// ìœ ì‚¬ ë…¸ë“œ ìŒì„ POTENTIAL_DUPLICATE ê´€ê³„ë¡œ í‘œì‹œ
MATCH (a:Company), (b:Company)
WHERE a.id < b.id
  AND apoc.text.jaroWinklerDistance(a.name, b.name) > 0.85
CREATE (a)-[:POTENTIAL_DUPLICATE {
  similarity: apoc.text.jaroWinklerDistance(a.name, b.name),
  detected_at: datetime()
}]->(b)

// ê²€í†  í›„ ë³‘í•©
MATCH (a:Company)-[r:POTENTIAL_DUPLICATE]->(b:Company)
WHERE r.similarity > 0.9  // ìë™ ë³‘í•© ì„ê³„ê°’
CALL apoc.refactor.mergeNodes([a, b], {properties: 'combine'})
YIELD node
DELETE r
RETURN count(node) AS merged_count
\`\`\`

## ì „ì²´ íŒŒì´í”„ë¼ì¸ (5ë‹¨ê³„)

\`\`\`cypher
// ğŸ“Œ Step 1: ë°ì´í„° ë¡œë“œ
LOAD CSV WITH HEADERS FROM 'file:///companies.csv' AS row
CREATE (:Company {name: row.name, industry: row.industry})

// ğŸ“Œ Step 2: ì¸ë±ìŠ¤ ìƒì„± (ì„±ëŠ¥ í–¥ìƒ)
CREATE INDEX company_name IF NOT EXISTS FOR (c:Company) ON (c.name)

// ğŸ“Œ Step 3: ìœ ì‚¬ ë…¸ë“œ íƒì§€ (Jaro-Winkler > 0.8)
MATCH (a:Company), (b:Company)
WHERE a.id < b.id
  AND a.industry = b.industry  // Blocking
  AND apoc.text.jaroWinklerDistance(a.name, b.name) > 0.8
MERGE (a)-[:POTENTIAL_DUPLICATE {
  similarity: apoc.text.jaroWinklerDistance(a.name, b.name)
}]->(b)

// ğŸ“Œ Step 4: ìë™ ë³‘í•© (ì‹ ë¢°ë„ > 0.95)
MATCH (a)-[r:POTENTIAL_DUPLICATE]->(b)
WHERE r.similarity > 0.95
CALL apoc.refactor.mergeNodes([a, b], {properties: 'combine'})
YIELD node
DELETE r
RETURN count(node) AS merged

// ğŸ“Œ Step 5: ìˆ˜ë™ ê²€í†  ëª©ë¡ (0.8~0.95)
MATCH (a)-[r:POTENTIAL_DUPLICATE]->(b)
RETURN a.name, b.name, r.similarity
ORDER BY r.similarity DESC
\`\`\`

## í•µì‹¬ í¬ì¸íŠ¸

1. **APOC** = Neo4j ER ë„êµ¬ (jaroWinkler, mergeNodes)
2. **Blocking** = ê°™ì€ ì†ì„± ë‚´ì—ì„œë§Œ ë¹„êµ
3. **mergeNodes** = ë…¸ë“œ + ê´€ê³„ + ì†ì„± í†µí•©
4. **POTENTIAL_DUPLICATE** = ìˆ˜ë™ ê²€í† ìš© ê´€ê³„
        `,
        keyPoints: [
          'ğŸ”§ APOCì˜ text í•¨ìˆ˜ë¡œ ë¬¸ìì—´ ìœ ì‚¬ë„ ê³„ì‚°',
          'âš¡ Blockingìœ¼ë¡œ ë¹„êµ ë²”ìœ„ ì¶•ì†Œí•˜ì—¬ ì„±ëŠ¥ í™•ë³´',
          'ğŸ”— apoc.refactor.mergeNodesë¡œ ë…¸ë“œ ë³‘í•©',
          'ğŸš© POTENTIAL_DUPLICATE ê´€ê³„ë¡œ ìˆ˜ë™ ê²€í†  ì§€ì›',
        ],
        practiceGoal: 'Neo4jì—ì„œ ìœ ì‚¬ ë…¸ë“œë¥¼ íƒì§€í•˜ê³  ë³‘í•©í•˜ëŠ” íŒŒì´í”„ë¼ì¸ì„ êµ¬í˜„í•  ìˆ˜ ìˆë‹¤',
      }
    ),

    // Task 5: ë°ì´í„° í’ˆì§ˆ ê´€ë¦¬ (25ë¶„)
    createReadingTask(
      'w4d1-data-quality',
      'ë°ì´í„° í’ˆì§ˆ ê´€ë¦¬ì™€ ê²€ì¦',
      25,
      {
        introduction: `
# ë°ì´í„° í’ˆì§ˆ ê´€ë¦¬ì™€ ê²€ì¦

## í•™ìŠµ ëª©í‘œ
- Knowledge Graphì˜ ë°ì´í„° í’ˆì§ˆ ë¬¸ì œë¥¼ ì‹ë³„í•œë‹¤
- Neo4jì—ì„œ í’ˆì§ˆ ê²€ì¦ ì¿¼ë¦¬ë¥¼ ì‘ì„±í•œë‹¤
- ë°ì´í„° ì •ì œ ì „ëµì„ ìˆ˜ë¦½í•œë‹¤

## ë°ì´í„° í’ˆì§ˆ ì°¨ì›

| ì°¨ì› | ì„¤ëª… | ì˜ˆì‹œ |
|------|------|------|
| **ì™„ì „ì„±** | í•„ìˆ˜ ì†ì„± ì¡´ì¬ | ì´ë¦„ ì—†ëŠ” íšŒì‚¬ |
| **ì •í™•ì„±** | ì˜¬ë°”ë¥¸ ê°’ | ì§ì›ìˆ˜ê°€ ìŒìˆ˜ |
| **ì¼ê´€ì„±** | ë°ì´í„° ê°„ ëª¨ìˆœ ì—†ìŒ | ì„¤ë¦½ì¼ > íì—…ì¼ |
| **ìœ ì¼ì„±** | ì¤‘ë³µ ì—†ìŒ | ê°™ì€ íšŒì‚¬ 2ê°œ |
| **ì ì‹œì„±** | ìµœì‹  ë°ì´í„° | 5ë…„ ì „ ì§ì›ìˆ˜ |
| **ìœ íš¨ì„±** | í˜•ì‹ ì¤€ìˆ˜ | ì˜ëª»ëœ ì´ë©”ì¼ í˜•ì‹ |

## Neo4j í’ˆì§ˆ ê²€ì¦ ì¿¼ë¦¬

### 1. ì™„ì „ì„± ê²€ì‚¬

\`\`\`cypher
// í•„ìˆ˜ ì†ì„± ëˆ„ë½ ë…¸ë“œ
MATCH (c:Company)
WHERE c.name IS NULL OR c.name = ''
RETURN 'Missing name' AS issue, count(c) AS count

UNION

MATCH (c:Company)
WHERE NOT EXISTS((c)-[:LOCATED_IN]->(:City))
RETURN 'Missing location' AS issue, count(c) AS count

UNION

MATCH (c:Company)
WHERE c.employees IS NULL
RETURN 'Missing employees' AS issue, count(c) AS count
\`\`\`

### 2. ìœ íš¨ì„± ê²€ì‚¬

\`\`\`cypher
// ë¹„ì •ìƒ ê°’ íƒì§€
MATCH (c:Company)
WHERE c.employees <= 0
RETURN c.name, c.employees AS invalid_employees

// ë‚ ì§œ ìœ íš¨ì„±
MATCH (c:Company)
WHERE c.founded_date > date()
RETURN c.name, c.founded_date AS future_date
\`\`\`

### 3. ì¼ê´€ì„± ê²€ì‚¬

\`\`\`cypher
// ëª¨ìˆœëœ ê´€ê³„
MATCH (a:Company)-[:SUBSIDIARY_OF]->(b:Company)
MATCH (b)-[:SUBSIDIARY_OF]->(a)
RETURN a.name, b.name AS circular_reference

// ìê¸° ì°¸ì¡°
MATCH (c:Company)-[r]->(c)
RETURN c.name, type(r) AS self_reference
\`\`\`

### 4. ê³ ì•„ ë…¸ë“œ

\`\`\`cypher
// ê´€ê³„ ì—†ëŠ” ë…¸ë“œ
MATCH (n)
WHERE NOT (n)--()
RETURN labels(n) AS label, count(n) AS orphan_count
ORDER BY orphan_count DESC
\`\`\`

### 5. ì¤‘ë³µ ê´€ê³„

\`\`\`cypher
// ë™ì¼ íƒ€ì…ì˜ ì¤‘ë³µ ê´€ê³„
MATCH (a)-[r1]->(b), (a)-[r2]->(b)
WHERE id(r1) < id(r2) AND type(r1) = type(r2)
RETURN a.name, b.name, type(r1), count(*) AS duplicate_count
\`\`\`

## í’ˆì§ˆ ëŒ€ì‹œë³´ë“œ ì¿¼ë¦¬

\`\`\`cypher
// ì „ì²´ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
CALL {
  MATCH (c:Company) RETURN count(c) AS total
}
CALL {
  MATCH (c:Company) WHERE c.name IS NOT NULL
  RETURN count(c) AS with_name
}
CALL {
  MATCH (c:Company) WHERE c.employees > 0
  RETURN count(c) AS valid_employees
}
CALL {
  MATCH (c:Company)-[:LOCATED_IN]->()
  RETURN count(DISTINCT c) AS with_location
}

RETURN
  total,
  round(with_name * 100.0 / total, 2) AS name_completeness,
  round(valid_employees * 100.0 / total, 2) AS employee_validity,
  round(with_location * 100.0 / total, 2) AS location_completeness
\`\`\`

## ë°ì´í„° ì •ì œ ì „ëµ

### ìë™ ì •ì œ

\`\`\`cypher
// ê³µë°± ì œê±°
MATCH (c:Company)
WHERE c.name CONTAINS '  ' OR c.name STARTS WITH ' '
SET c.name = trim(replace(c.name, '  ', ' '))

// ê¸°ë³¸ê°’ ì„¤ì •
MATCH (c:Company)
WHERE c.employees IS NULL
SET c.employees = 0, c.employees_unknown = true
\`\`\`

### ì œì•½ ì¡°ê±´

\`\`\`cypher
// ìœ ì¼ì„± ì œì•½
CREATE CONSTRAINT company_name_unique IF NOT EXISTS
FOR (c:Company) REQUIRE c.name IS UNIQUE

// í•„ìˆ˜ ì†ì„± ì œì•½ (Neo4j 5.0+)
CREATE CONSTRAINT company_name_exists IF NOT EXISTS
FOR (c:Company) REQUIRE c.name IS NOT NULL
\`\`\`

## í•µì‹¬ í¬ì¸íŠ¸

1. **6ê°€ì§€ í’ˆì§ˆ ì°¨ì›**: ì™„ì „ì„±, ì •í™•ì„±, ì¼ê´€ì„±, ìœ ì¼ì„±, ì ì‹œì„±, ìœ íš¨ì„±
2. **ê²€ì¦ ì¿¼ë¦¬**ë¡œ ë¬¸ì œ íƒì§€
3. **ì œì•½ ì¡°ê±´**ìœ¼ë¡œ í’ˆì§ˆ ê°•ì œ
4. **ìë™ ì •ì œ + ìˆ˜ë™ ê²€í† ** ë³‘í–‰
        `,
        keyPoints: [
          'ë°ì´í„° í’ˆì§ˆì€ ì™„ì „ì„±, ì •í™•ì„±, ì¼ê´€ì„±, ìœ ì¼ì„±, ì ì‹œì„±, ìœ íš¨ì„± 6ê°€ì§€ ì°¨ì›',
          'Cypher ì¿¼ë¦¬ë¡œ í’ˆì§ˆ ë¬¸ì œë¥¼ íƒì§€í•˜ê³  ëŒ€ì‹œë³´ë“œ êµ¬ì¶•',
          'ì œì•½ ì¡°ê±´(CONSTRAINT)ìœ¼ë¡œ í’ˆì§ˆ ê·œì¹™ ê°•ì œ',
          'ìë™ ì •ì œì™€ ìˆ˜ë™ ê²€í† ë¥¼ ë³‘í–‰',
        ],
        practiceGoal: 'Knowledge Graphì˜ ë°ì´í„° í’ˆì§ˆì„ ê²€ì¦í•˜ê³  ê°œì„ í•˜ëŠ” ë°©ë²•ì„ ì´í•´í•œë‹¤',
      }
    ),

    // Task 6: ì‹¤ìŠµ - ê¸°ì—… ë°ì´í„° ER (30ë¶„)
    createCodeTask(
      'w4d1-er-practice',
      'ì‹¤ìŠµ: ê¸°ì—… ë°ì´í„° Entity Resolution',
      30,
      {
        introduction: `
# ì‹¤ìŠµ: ê¸°ì—… ë°ì´í„° Entity Resolution

## ğŸ¯ ì‹¤ìŠµ ëª©í‘œ

ì—¬ëŸ¬ ì†ŒìŠ¤ì˜ ê¸°ì—… ë°ì´í„°ë¥¼ í†µí•©í•˜ì—¬ ì¤‘ë³µì„ ì œê±°í•©ë‹ˆë‹¤.

> ğŸ’¡ **ì‹œë‚˜ë¦¬ì˜¤**: 3ê°œì˜ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ í†µí•©í•˜ëŠ” M&A í”„ë¡œì íŠ¸
>
> êµ­ë‚´ DB(í•œê¸€) + ê¸€ë¡œë²Œ DB(ì˜ë¬¸) + ë‰´ìŠ¤ í¬ë¡¤ë§(í˜¼í•©)
> â†’ í•˜ë‚˜ì˜ ê¹¨ë—í•œ ê¸°ì—… ë¦¬ìŠ¤íŠ¸ë¡œ í†µí•©

## ê³¼ì œ ê°œìš”

## ë°ì´í„° ì¤€ë¹„

\`\`\`python
import pandas as pd

# ì†ŒìŠ¤ 1: êµ­ë‚´ ê¸°ì—… DB
source1 = pd.DataFrame({
    'id': ['K001', 'K002', 'K003', 'K004'],
    'name': ['ì‚¼ì„±ì „ì', 'SKí•˜ì´ë‹‰ìŠ¤', 'LGì „ì', 'í˜„ëŒ€ìë™ì°¨'],
    'industry': ['ì „ì', 'ë°˜ë„ì²´', 'ì „ì', 'ìë™ì°¨'],
    'employees': [270000, 30000, 75000, 120000],
    'source': ['domestic']
})

# ì†ŒìŠ¤ 2: ê¸€ë¡œë²Œ ê¸°ì—… DB
source2 = pd.DataFrame({
    'id': ['G001', 'G002', 'G003', 'G004'],
    'name': ['Samsung Electronics', 'SK Hynix', 'LG Electronics', 'Hyundai Motor'],
    'industry': ['Electronics', 'Semiconductor', 'Electronics', 'Automotive'],
    'employees': [267000, 29000, 74000, 118000],
    'source': ['global']
})

# ì†ŒìŠ¤ 3: ë‰´ìŠ¤ ì¶”ì¶œ ë°ì´í„°
source3 = pd.DataFrame({
    'id': ['N001', 'N002', 'N003'],
    'name': ['ì‚¼ì„±ì „ìì£¼ì‹íšŒì‚¬', 'ì‚¼ì„±', 'í˜„ëŒ€ì°¨'],
    'industry': ['í…Œí¬', 'ì „ì', 'ìë™ì°¨'],
    'employees': [None, None, None],
    'source': ['news']
})

# í†µí•©
all_companies = pd.concat([source1, source2, source3], ignore_index=True)
print(f"ì´ ë ˆì½”ë“œ: {len(all_companies)}")
print(all_companies)
\`\`\`

## ìš”êµ¬ì‚¬í•­

### 1. Python recordlinkageë¡œ ì¤‘ë³µ íƒì§€

\`\`\`python
import recordlinkage

def detect_duplicates(df):
    # Indexing
    indexer = recordlinkage.Index()
    indexer.full()
    pairs = indexer.index(df)

    # Comparison
    compare = recordlinkage.Compare()
    compare.string('name', 'name', method='jarowinkler', label='name_sim')
    compare.string('industry', 'industry', method='jarowinkler', label='industry_sim')
    compare.numeric('employees', 'employees', scale=10000, label='emp_sim', missing_value=0.5)

    features = compare.compute(pairs, df)

    # Classification (ì„ê³„ê°’ ê¸°ë°˜)
    matches = features[
        (features['name_sim'] > 0.7) |
        (features.sum(axis=1) > 1.8)
    ]

    return matches, features

# ì‹¤í–‰
matches, features = detect_duplicates(all_companies)

# ê²°ê³¼ ì¶œë ¥
print("\\n=== ì¤‘ë³µ í›„ë³´ ===")
for (i, j), row in matches.iterrows():
    print(f"{all_companies.loc[i, 'name']} ({all_companies.loc[i, 'source']})")
    print(f"  â†” {all_companies.loc[j, 'name']} ({all_companies.loc[j, 'source']})")
    print(f"  ìœ ì‚¬ë„: name={row['name_sim']:.2f}, total={row.sum():.2f}")
    print()
\`\`\`

### 2. í´ëŸ¬ìŠ¤í„°ë§ìœ¼ë¡œ ê·¸ë£¹í™”

\`\`\`python
import networkx as nx

def cluster_matches(matches, df):
    """ë§¤ì¹­ ìŒì„ í´ëŸ¬ìŠ¤í„°ë¡œ ê·¸ë£¹í™”"""
    G = nx.Graph()

    # ë§¤ì¹­ ìŒì„ ì—£ì§€ë¡œ ì¶”ê°€
    for (i, j) in matches.index:
        G.add_edge(i, j)

    # Connected components = ê°™ì€ ì—”í‹°í‹° ê·¸ë£¹
    clusters = list(nx.connected_components(G))

    # í´ëŸ¬ìŠ¤í„°ë³„ ì •ë³´ ì¶œë ¥
    for cluster_id, cluster in enumerate(clusters):
        print(f"\\n=== í´ëŸ¬ìŠ¤í„° {cluster_id + 1} ===")
        for idx in cluster:
            row = df.loc[idx]
            print(f"  {row['name']} ({row['source']}, {row['employees']})")

    return clusters

clusters = cluster_matches(matches, all_companies)
\`\`\`

### 3. ëŒ€í‘œ ë ˆì½”ë“œ ì„ ì • ë° ë³‘í•©

\`\`\`python
def merge_cluster(cluster, df):
    """í´ëŸ¬ìŠ¤í„°ë¥¼ í•˜ë‚˜ì˜ ë ˆì½”ë“œë¡œ ë³‘í•©"""
    records = df.loc[list(cluster)]

    # ëŒ€í‘œ ì´ë¦„: ê°€ì¥ ì§§ì€ í•œê¸€ ì´ë¦„ ë˜ëŠ” ì²« ë²ˆì§¸
    korean_names = records[records['name'].str.contains('[ê°€-í£]', regex=True)]
    if len(korean_names) > 0:
        main_name = korean_names.sort_values('name', key=lambda x: x.str.len()).iloc[0]['name']
    else:
        main_name = records.iloc[0]['name']

    # ë³„ì¹­: ë‹¤ë¥¸ ëª¨ë“  ì´ë¦„
    aliases = list(records['name'].unique())
    aliases.remove(main_name)

    # ì§ì›ìˆ˜: ìœ íš¨í•œ ê°’ ì¤‘ ìµœëŒ€
    valid_employees = records['employees'].dropna()
    employees = int(valid_employees.max()) if len(valid_employees) > 0 else None

    return {
        'name': main_name,
        'aliases': aliases,
        'industry': records['industry'].mode().iloc[0],
        'employees': employees,
        'sources': list(records['source'].unique())
    }

# ë³‘í•© ì‹¤í–‰
merged_records = []
for cluster in clusters:
    merged = merge_cluster(cluster, all_companies)
    merged_records.append(merged)
    print(f"\\në³‘í•© ê²°ê³¼: {merged['name']}")
    print(f"  ë³„ì¹­: {merged['aliases']}")
    print(f"  ì§ì›ìˆ˜: {merged['employees']}")

# ë‹¨ì¼ ë ˆì½”ë“œ (ë§¤ì¹­ ì—†ìŒ) ì¶”ê°€
matched_indices = set()
for cluster in clusters:
    matched_indices.update(cluster)

for idx in all_companies.index:
    if idx not in matched_indices:
        row = all_companies.loc[idx]
        merged_records.append({
            'name': row['name'],
            'aliases': [],
            'industry': row['industry'],
            'employees': row['employees'],
            'sources': [row['source']]
        })
\`\`\`

### 4. ê²°ê³¼ ê²€ì¦

\`\`\`python
# ìµœì¢… í†µí•© ë°ì´í„°
final_df = pd.DataFrame(merged_records)
print(f"\\n=== ìµœì¢… ê²°ê³¼ ===")
print(f"ì›ë³¸: {len(all_companies)} ë ˆì½”ë“œ")
print(f"í†µí•© í›„: {len(final_df)} ë ˆì½”ë“œ")
print(f"ì¤‘ë³µ ì œê±°: {len(all_companies) - len(final_df)}ê°œ")
print()
print(final_df)
\`\`\`

## í‰ê°€ ê¸°ì¤€

| í•­ëª© | ë°°ì  |
|------|------|
| ìœ ì‚¬ë„ ê³„ì‚° ì •í™•ì„± | 25% |
| ì¤‘ë³µ íƒì§€ ì™„ì „ì„± | 25% |
| í´ëŸ¬ìŠ¤í„°ë§ ì •í™•ì„± | 20% |
| ë³‘í•© ì „ëµ ì ì ˆì„± | 20% |
| ì½”ë“œ í’ˆì§ˆ | 10% |
        `,
        keyPoints: [
          'ğŸ” recordlinkageë¡œ ì¤‘ë³µ í›„ë³´ íƒì§€',
          'ğŸ•¸ï¸ NetworkXë¡œ ë§¤ì¹­ ìŒì„ í´ëŸ¬ìŠ¤í„°ë¡œ ê·¸ë£¹í™”',
          'â­ ëŒ€í‘œ ë ˆì½”ë“œ ì„ ì • ë° ì†ì„± ë³‘í•© ì „ëµ',
          'âœ… ì›ë³¸ ëŒ€ë¹„ í†µí•© ê²°ê³¼ ê²€ì¦',
        ],
        practiceGoal: 'ì—¬ëŸ¬ ì†ŒìŠ¤ì˜ ê¸°ì—… ë°ì´í„°ë¥¼ Entity Resolutionìœ¼ë¡œ í†µí•©í•  ìˆ˜ ìˆë‹¤',
      }
    ),

    // Task 7: Quiz (20ë¶„)
    createQuizTask(
      'w4d1-quiz',
      'Day 1 ë³µìŠµ í€´ì¦ˆ',
      20,
      {
        introduction: `
# Day 1 ë³µìŠµ í€´ì¦ˆ

Entity Resolutionì— ëŒ€í•´ í•™ìŠµí•œ ë‚´ìš©ì„ í™•ì¸í•©ë‹ˆë‹¤.
        `,
        questions: [
          {
            id: 'w4d1-q1',
            question: 'Entity Resolutionì˜ ì£¼ìš” ëª©ì ì€?',
            options: [
              'ë°ì´í„° ì•”í˜¸í™”',
              'ê°™ì€ ì—”í‹°í‹°ì˜ ë‹¤ë¥¸ í‘œí˜„ì„ ì‹ë³„í•˜ê³  í†µí•©',
              'ë°ì´í„° ì‹œê°í™”',
              'ì¿¼ë¦¬ ìµœì í™”',
            ],
            correctAnswer: 1,
            explanation: 'Entity Resolutionì€ ë‹¤ì–‘í•œ í‘œí˜„(ì‚¼ì„±ì „ì, Samsung Electronics ë“±)ì´ ê°™ì€ ì‹¤ì„¸ê³„ ì—”í‹°í‹°ë¥¼ ê°€ë¦¬í‚´ì„ ì‹ë³„í•˜ê³  í†µí•©í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤.',
          },
          {
            id: 'w4d1-q2',
            question: 'Blockingì˜ ëª©ì ì€?',
            options: [
              'ë³´ì•ˆ ê°•í™”',
              'ë°ì´í„° ì•”í˜¸í™”',
              'ë¹„êµ ëŒ€ìƒ ìŒì„ ì¤„ì—¬ ì„±ëŠ¥ í–¥ìƒ',
              'ì¤‘ë³µ ë°ì´í„° ì‚­ì œ',
            ],
            correctAnswer: 2,
            explanation: 'Blockingì€ ì „ì²´ ìŒ ë¹„êµ(nÂ²) ëŒ€ì‹  ìœ ì‚¬í•  ê°€ëŠ¥ì„±ì´ ìˆëŠ” ìŒë§Œ ë¹„êµí•˜ì—¬ ì„±ëŠ¥ì„ í¬ê²Œ í–¥ìƒì‹œí‚µë‹ˆë‹¤.',
          },
          {
            id: 'w4d1-q3',
            question: 'ì´ë¦„ ë§¤ì¹­ì— ê°€ì¥ ì í•©í•œ ìœ ì‚¬ë„ ë©”íŠ¸ë¦­ì€?',
            options: [
              'Jaccard',
              'Cosine',
              'Jaro-Winkler',
              'Euclidean',
            ],
            correctAnswer: 2,
            explanation: 'Jaro-WinklerëŠ” ë¬¸ì ìˆœì„œë¥¼ ê³ ë ¤í•˜ê³  ì ‘ë‘ì‚¬ì— ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•˜ì—¬ ì‚¬ëŒ/íšŒì‚¬ ì´ë¦„ ë§¤ì¹­ì— ê°€ì¥ ì í•©í•©ë‹ˆë‹¤.',
          },
          {
            id: 'w4d1-q4',
            question: 'recordlinkageì˜ 3ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ ìˆœì„œëŠ”?',
            options: [
              'Compare â†’ Index â†’ Classify',
              'Index â†’ Compare â†’ Classify',
              'Classify â†’ Compare â†’ Index',
              'Index â†’ Classify â†’ Compare',
            ],
            correctAnswer: 1,
            explanation: 'recordlinkageëŠ” Index(Blocking) â†’ Compare(ìœ ì‚¬ë„ ê³„ì‚°) â†’ Classify(ë§¤ì¹­ íŒì •) ìˆœì„œë¡œ ì§„í–‰ë©ë‹ˆë‹¤.',
          },
          {
            id: 'w4d1-q5',
            question: 'Neo4jì—ì„œ ë…¸ë“œë¥¼ ë³‘í•©í•  ë•Œ ì‚¬ìš©í•˜ëŠ” APOC í•¨ìˆ˜ëŠ”?',
            options: [
              'apoc.create.node',
              'apoc.refactor.mergeNodes',
              'apoc.algo.merge',
              'apoc.text.merge',
            ],
            correctAnswer: 1,
            explanation: 'apoc.refactor.mergeNodesëŠ” ì—¬ëŸ¬ ë…¸ë“œë¥¼ í•˜ë‚˜ë¡œ ë³‘í•©í•˜ê³  ê´€ê³„ì™€ ì†ì„±ì„ í†µí•©í•©ë‹ˆë‹¤.',
          },
        ],
        keyPoints: [
          'ERì€ ê°™ì€ ì—”í‹°í‹°ì˜ ë‹¤ë¥¸ í‘œí˜„ì„ í†µí•©',
          'Blockingìœ¼ë¡œ ë¹„êµ ëŒ€ìƒ ì¶•ì†Œ',
          'Jaro-WinklerëŠ” ì´ë¦„ ë§¤ì¹­ì— ìµœì ',
          'recordlinkage: Index â†’ Compare â†’ Classify',
        ],
        practiceGoal: 'Entity Resolutionì˜ í•µì‹¬ ê°œë…ì„ í™•ì¸í•œë‹¤',
      }
    ),
  ],

  // Day 1 Challenge
  challenge: createChallengeTask(
    'w4d1-challenge',
    'Challenge: ë©€í‹°ì†ŒìŠ¤ ê¸°ì—… ER íŒŒì´í”„ë¼ì¸',
    40,
    {
      introduction: `
# Challenge: ë©€í‹°ì†ŒìŠ¤ ê¸°ì—… ER íŒŒì´í”„ë¼ì¸

## ë„ì „ ê³¼ì œ

3ê°œ ì´ìƒì˜ ë°ì´í„° ì†ŒìŠ¤ì—ì„œ ê¸°ì—… ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ê³ , Entity Resolution íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•˜ì„¸ìš”.

### ìš”êµ¬ì‚¬í•­

1. **ë°ì´í„° ì¤€ë¹„** (3ê°œ ì†ŒìŠ¤)
   - êµ­ë‚´ ê¸°ì—… DB (í•œê¸€)
   - ê¸€ë¡œë²Œ ê¸°ì—… DB (ì˜ë¬¸)
   - ë‰´ìŠ¤/ì›¹ ì¶”ì¶œ ë°ì´í„° (í˜¼í•©)

2. **ER íŒŒì´í”„ë¼ì¸ êµ¬í˜„**
   - Blocking ì „ëµ ì„¤ê³„
   - ë‹¤ì¤‘ ì†ì„± ìœ ì‚¬ë„ ê³„ì‚°
   - ì„ê³„ê°’ íŠœë‹

3. **ê²°ê³¼ ê²€ì¦**
   - Precision / Recall ê³„ì‚° (ê°€ëŠ¥í•œ ê²½ìš°)
   - ì˜¤íƒì§€ ë¶„ì„

4. **Neo4j ì—°ë™**
   - í†µí•© ë°ì´í„° ë¡œë“œ
   - POTENTIAL_DUPLICATE ê´€ê³„ ìƒì„±
   - ë³‘í•© ì¿¼ë¦¬ ì‘ì„±

### í‰ê°€ ê¸°ì¤€

| í•­ëª© | ë°°ì  |
|------|------|
| ë°ì´í„° ì†ŒìŠ¤ ë‹¤ì–‘ì„± | 15% |
| Blocking ì „ëµ | 20% |
| ìœ ì‚¬ë„ ë©”íŠ¸ë¦­ ì„ íƒ | 20% |
| í´ëŸ¬ìŠ¤í„°ë§ ë° ë³‘í•© | 20% |
| Neo4j ì—°ë™ | 15% |
| ë¬¸ì„œí™” | 10% |
      `,
      keyPoints: [
        'ë‹¤ì¤‘ ì†ŒìŠ¤ ë°ì´í„° í†µí•©',
        'Blockingê³¼ ìœ ì‚¬ë„ ë©”íŠ¸ë¦­ ìµœì í™”',
        'í´ëŸ¬ìŠ¤í„°ë§ ë° ë³‘í•© ì „ëµ',
        'Neo4jë¡œ ê²°ê³¼ ì €ì¥ ë° ê²€ì¦',
      ],
      practiceGoal: 'ì‹¤ì œ ë©€í‹°ì†ŒìŠ¤ ë°ì´í„°ë¡œ ì™„ì „í•œ ER íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•œë‹¤',
    }
  ),
}
