// Week 6 Day 3: Microsoft GraphRAG

import type { Day } from './types'
import {
  createVideoTask,
  createReadingTask,
  createCodeTask,
  createQuizTask,
} from './types'

// Task 1: MS GraphRAG ì†Œê°œ
const task1 = createVideoTask(
  'w6d3-ms-graphrag-intro',
  'Microsoft GraphRAG ì•„í‚¤í…ì²˜',
  30,
  {
    introduction: `
## Microsoft GraphRAG

Microsoft Researchì—ì„œ ë°œí‘œí•œ GraphRAGëŠ” ëŒ€ê·œëª¨ ë¬¸ì„œì—ì„œ
ìë™ìœ¼ë¡œ Knowledge Graphë¥¼ êµ¬ì¶•í•˜ê³  ê²€ìƒ‰í•˜ëŠ” í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.

### í•µì‹¬ ì•„ì´ë””ì–´

ê¸°ì¡´ RAGì˜ **"ë‚˜ë¬´ë¥¼ ë³´ë˜ ìˆ²ì„ ëª» ë³´ëŠ”"** ë¬¸ì œ í•´ê²°:
- ê°œë³„ ì²­í¬ê°€ ì•„ë‹Œ ì „ì²´ ë¬¸ì„œ ì»¬ë ‰ì…˜ì˜ **ê¸€ë¡œë²Œ ì´í•´**
- **ì»¤ë®¤ë‹ˆí‹° ê¸°ë°˜** ê³„ì¸µì  ìš”ì•½
- **Local + Global** ê²€ìƒ‰ ì§€ì›

### íŒŒì´í”„ë¼ì¸ ê°œìš”

\`\`\`
Documents
    â†“
[1. Entity Extraction] â†’ ì—”í‹°í‹° + ê´€ê³„ ì¶”ì¶œ
    â†“
[2. Graph Construction] â†’ Knowledge Graph êµ¬ì¶•
    â†“
[3. Community Detection] â†’ ì»¤ë®¤ë‹ˆí‹° (ì£¼ì œ í´ëŸ¬ìŠ¤í„°) íƒì§€
    â†“
[4. Summary Generation] â†’ ì»¤ë®¤ë‹ˆí‹°ë³„ ìš”ì•½ ìƒì„±
    â†“
[Query Time]
    â”œâ†’ [Local Search] - íŠ¹ì • ì—”í‹°í‹° ê¸°ë°˜
    â””â†’ [Global Search] - ì»¤ë®¤ë‹ˆí‹° ìš”ì•½ ê¸°ë°˜
\`\`\`

### Local vs Global Search

| ê²€ìƒ‰ ìœ í˜• | ì í•©í•œ ì§ˆë¬¸ | ì˜ˆì‹œ |
|----------|------------|------|
| **Local** | íŠ¹ì • ì—”í‹°í‹° ê´€ë ¨ | "ì‚¼ì„±ì „ìì˜ CEOëŠ” ëˆ„êµ¬?" |
| **Global** | ì „ì²´ ì£¼ì œ ìš”ì•½ | "ë°˜ë„ì²´ ì‚°ì—…ì˜ ì£¼ìš” íŠ¸ë Œë“œëŠ”?" |

### ì¥ì 

1. **ê¸€ë¡œë²Œ ì§ˆë¬¸ ì²˜ë¦¬**: "ì „ì²´ ë°ì´í„°ì…‹ ìš”ì•½" ê°€ëŠ¥
2. **ê³„ì¸µì  ì´í•´**: ì„¸ë¶€ â†’ ì£¼ì œ â†’ ì „ì²´
3. **íš¨ìœ¨ì  ê²€ìƒ‰**: ì‚¬ì „ ê³„ì‚°ëœ ì»¤ë®¤ë‹ˆí‹° ìš”ì•½ í™œìš©
`,
    keyPoints: [
      'MS GraphRAG: ë¬¸ì„œì—ì„œ ìë™ KG êµ¬ì¶•',
      'Community Detectionìœ¼ë¡œ ì£¼ì œ í´ëŸ¬ìŠ¤í„°ë§',
      'Local Search: ì—”í‹°í‹° ê¸°ë°˜, Global Search: ì»¤ë®¤ë‹ˆí‹° ê¸°ë°˜',
      'ê¸€ë¡œë²Œ ì§ˆë¬¸ ("ì „ì²´ ìš”ì•½") ì²˜ë¦¬ ê°€ëŠ¥',
    ],
    practiceGoal: 'Microsoft GraphRAGì˜ í•µì‹¬ ê°œë…ê³¼ ì•„í‚¤í…ì²˜ ì´í•´',
  }
)

// Task 2: ì—”í‹°í‹° ì¶”ì¶œ íŒŒì´í”„ë¼ì¸
const task2 = createCodeTask(
  'w6d3-entity-extraction',
  'ì‹¤ìŠµ: LLM ê¸°ë°˜ ì—”í‹°í‹°/ê´€ê³„ ì¶”ì¶œ',
  50,
  {
    introduction: `
## ì™œ ë°°ìš°ëŠ”ê°€?

### ë¬¸ì œ ìƒí™©
ì¼ë°˜ RAGëŠ” ë¬¸ì„œë¥¼ í…ìŠ¤íŠ¸ ì²­í¬ë¡œë§Œ ì €ì¥í•©ë‹ˆë‹¤.
MS GraphRAGëŠ” ë¬¸ì„œì—ì„œ **ì—”í‹°í‹°ì™€ ê´€ê³„ë¥¼ ìë™ ì¶”ì¶œ**í•˜ì—¬ Knowledge Graphë¥¼ ë§Œë“­ë‹ˆë‹¤.

ë¬¸ì„œ â†’ ì²­í¬ (ì¼ë°˜ RAG)
ë¬¸ì„œ â†’ ì—”í‹°í‹° + ê´€ê³„ â†’ Graph (MS GraphRAG)

---

## ë¹„ìœ : ì‹ ë¬¸ ê¸°ì‚¬ ìš”ì•½

\`\`\`
ê¸°ì‚¬: "ì‚¼ì„±ì „ì ì´ì¬ìš© íšŒì¥ì´ NVIDIA ì  ìŠ¨ í™© CEOì™€ ë§Œë‚˜ AI ì¹© í˜‘ë ¥ì„ ë…¼ì˜í–ˆë‹¤."

ì¼ë°˜ ìš”ì•½:
  â†’ "ì‚¼ì„±ì „ìì™€ NVIDIAê°€ AI ì¹© í˜‘ë ¥"

GraphRAG ì¶”ì¶œ:
  ì—”í‹°í‹°: [ì‚¼ì„±ì „ì(Company), ì´ì¬ìš©(Person), NVIDIA(Company), ì  ìŠ¨ í™©(Person)]
  ê´€ê³„: [ì´ì¬ìš© -WORKS_ATâ†’ ì‚¼ì„±ì „ì, ì  ìŠ¨ í™© -WORKS_ATâ†’ NVIDIA, ì‚¼ì„±ì „ì -PARTNERS_WITHâ†’ NVIDIA]
\`\`\`

**êµ¬ì¡°í™”ëœ ì •ë³´ = ë‚˜ì¤‘ì— "ì´ì¬ìš©ì´ ëˆ„êµ¬ë‘ ë§Œë‚¬ë‚˜?" ì§ˆë¬¸ ê°€ëŠ¥**

---

## ì—”í‹°í‹°/ê´€ê³„ ì¶”ì¶œ íŒŒì´í”„ë¼ì¸

MS GraphRAGì˜ ì²« ë‹¨ê³„ëŠ” ë¬¸ì„œì—ì„œ ì—”í‹°í‹°ì™€ ê´€ê³„ë¥¼ ì¶”ì¶œí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

### ì¶”ì¶œ í”„ë¡¬í”„íŠ¸ ì„¤ê³„

\`\`\`python
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
import json

ENTITY_EXTRACTION_PROMPT = '''
ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ ì—”í‹°í‹°ì™€ ê´€ê³„ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

í…ìŠ¤íŠ¸:
{text}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{{
    "entities": [
        {{"name": "ì—”í‹°í‹°ëª…", "type": "ìœ í˜•", "description": "ì„¤ëª…"}}
    ],
    "relationships": [
        {{"source": "ì†ŒìŠ¤ ì—”í‹°í‹°", "target": "íƒ€ê²Ÿ ì—”í‹°í‹°", "type": "ê´€ê³„ìœ í˜•", "description": "ì„¤ëª…"}}
    ]
}}

ìœ í˜• ì˜ˆì‹œ:
- ì—”í‹°í‹°: Person, Organization, Location, Event, Technology, Product
- ê´€ê³„: WORKS_AT, COMPETES_WITH, LOCATED_IN, FOUNDED, ACQUIRED, PARTNERS_WITH
'''

def extract_entities_and_relations(text: str, llm) -> dict:
    prompt = ChatPromptTemplate.from_messages([
        ("system", ENTITY_EXTRACTION_PROMPT),
        ("human", "{text}")
    ])

    chain = prompt | llm

    result = chain.invoke({"text": text})
    return json.loads(result.content)

# ì‚¬ìš©
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
text = """
ì‚¼ì„±ì „ìì˜ ì´ì¬ìš© íšŒì¥ì€ NVIDIAì˜ ì  ìŠ¨ í™© CEOì™€
AI ë°˜ë„ì²´ í˜‘ë ¥ ë°©ì•ˆì„ ë…¼ì˜í–ˆë‹¤.
ë‘ íšŒì‚¬ëŠ” ì°¨ì„¸ëŒ€ AI ì¹© ê³µë™ ê°œë°œì— í•©ì˜í–ˆë‹¤.
"""

result = extract_entities_and_relations(text, llm)
print(json.dumps(result, indent=2, ensure_ascii=False))
\`\`\`

### ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬

\`\`\`python
from langchain.text_splitter import RecursiveCharacterTextSplitter

def process_documents(documents: list, llm) -> dict:
    """ë¬¸ì„œ ëª©ë¡ì—ì„œ ì—”í‹°í‹°/ê´€ê³„ ì¶”ì¶œ"""
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=2000,
        chunk_overlap=200
    )

    all_entities = []
    all_relations = []

    for doc in documents:
        chunks = splitter.split_text(doc)
        for chunk in chunks:
            result = extract_entities_and_relations(chunk, llm)
            all_entities.extend(result.get('entities', []))
            all_relations.extend(result.get('relationships', []))

    # ì¤‘ë³µ ì œê±°
    unique_entities = deduplicate_entities(all_entities)
    unique_relations = deduplicate_relations(all_relations)

    return {
        'entities': unique_entities,
        'relationships': unique_relations
    }
\`\`\`
`,
    keyPoints: [
      'ğŸ“Š LLM í”„ë¡¬í”„íŠ¸ë¡œ ì—”í‹°í‹°/ê´€ê³„ ì¶”ì¶œ',
      'ğŸ“‹ JSON êµ¬ì¡°í™” ì¶œë ¥ìœ¼ë¡œ íŒŒì‹± ìš©ì´',
      'ğŸ”„ ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬ í›„ ì¤‘ë³µ ì œê±°',
      'ğŸ¯ ì—”í‹°í‹° íƒ€ì…ê³¼ ê´€ê³„ íƒ€ì… ì •ì˜ ì¤‘ìš”',
    ],
    practiceGoal: 'ë¬¸ì„œì—ì„œ ì—”í‹°í‹°ì™€ ê´€ê³„ ìë™ ì¶”ì¶œ',
    codeExample: `from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
import json

# ğŸ“Œ Step 1: ì¶”ì¶œ í”„ë¡¬í”„íŠ¸ ì •ì˜
PROMPT = '''í…ìŠ¤íŠ¸ì—ì„œ ì—”í‹°í‹°ì™€ ê´€ê³„ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.
ì—”í‹°í‹° íƒ€ì…: Person, Company, Technology
ê´€ê³„ íƒ€ì…: COMPETES_WITH, PARTNERS_WITH, WORKS_AT
JSON: {{"entities": [{{"name": "...", "type": "..."}}],
       "relationships": [{{"source": "...", "relation": "...", "target": "..."}}]}}'''

llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

# ğŸ“Œ Step 2: í”„ë¡¬í”„íŠ¸ ì²´ì¸ ìƒì„±
prompt = ChatPromptTemplate.from_messages([
    ("system", PROMPT),
    ("human", "{text}")
])

# ğŸ“Œ Step 3: í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤í–‰
text = "ì‚¼ì„±ì „ìì™€ SKí•˜ì´ë‹‰ìŠ¤ëŠ” ë°˜ë„ì²´ ì‹œì¥ì—ì„œ ê²½ìŸí•œë‹¤."
result = (prompt | llm).invoke({"text": text})

# ğŸ“Œ Step 4: JSON íŒŒì‹±
data = json.loads(result.content)
print(json.dumps(data, indent=2, ensure_ascii=False))
# ì¶œë ¥:
# {"entities": [{"name": "ì‚¼ì„±ì „ì", "type": "Company"}, ...],
#  "relationships": [{"source": "ì‚¼ì„±ì „ì", "relation": "COMPETES_WITH", "target": "SKí•˜ì´ë‹‰ìŠ¤"}]}`,
  }
)

// Task 3: ì»¤ë®¤ë‹ˆí‹° íƒì§€
const task3 = createReadingTask(
  'w6d3-community-detection',
  'ì»¤ë®¤ë‹ˆí‹° íƒì§€ì™€ ê³„ì¸µì  ìš”ì•½',
  40,
  {
    introduction: `
## ì»¤ë®¤ë‹ˆí‹° íƒì§€ì™€ ê³„ì¸µì  ìš”ì•½

### ì»¤ë®¤ë‹ˆí‹° íƒì§€ë€?

ê·¸ë˜í”„ì—ì„œ ë°€ì ‘í•˜ê²Œ ì—°ê²°ëœ ë…¸ë“œ ê·¸ë£¹ì„ ì°¾ëŠ” ê²ƒì…ë‹ˆë‹¤.

\`\`\`
[ë°˜ë„ì²´ ì»¤ë®¤ë‹ˆí‹°]          [ì†Œí”„íŠ¸ì›¨ì–´ ì»¤ë®¤ë‹ˆí‹°]
  ì‚¼ì„± â”€â”€â”€ SK              Google â”€â”€â”€ Microsoft
    â”‚ â•² â•± â”‚                   â”‚         â”‚
  TSMC â”€â”€ Intel             Apple â”€â”€â”€ Amazon
\`\`\`

### Leiden ì•Œê³ ë¦¬ì¦˜

MS GraphRAGëŠ” **Leiden ì•Œê³ ë¦¬ì¦˜**ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
(Louvainì˜ ê°œì„  ë²„ì „)

\`\`\`python
import networkx as nx
from cdlib import algorithms

# NetworkX ê·¸ë˜í”„ ìƒì„±
G = nx.Graph()
G.add_edges_from([
    ('ì‚¼ì„±ì „ì', 'SKí•˜ì´ë‹‰ìŠ¤'),
    ('ì‚¼ì„±ì „ì', 'TSMC'),
    ('SKí•˜ì´ë‹‰ìŠ¤', 'TSMC'),
    ('Google', 'Microsoft'),
    ('Google', 'Amazon'),
])

# Leiden ì»¤ë®¤ë‹ˆí‹° íƒì§€
communities = algorithms.leiden(G)

for i, community in enumerate(communities.communities):
    print(f"Community {i}: {community}")
# Community 0: {'ì‚¼ì„±ì „ì', 'SKí•˜ì´ë‹‰ìŠ¤', 'TSMC'}
# Community 1: {'Google', 'Microsoft', 'Amazon'}
\`\`\`

### ê³„ì¸µì  ì»¤ë®¤ë‹ˆí‹°

MS GraphRAGëŠ” ì—¬ëŸ¬ ë ˆë²¨ì˜ ì»¤ë®¤ë‹ˆí‹°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤:

\`\`\`
Level 0 (ê°€ì¥ ì„¸ë¶„í™”):
  - Community 0.1: ì‚¼ì„±ì „ì, SKí•˜ì´ë‹‰ìŠ¤
  - Community 0.2: Intel, AMD
  - Community 0.3: TSMC, GlobalFoundries

Level 1 (ì¤‘ê°„):
  - Community 1.1: ë°˜ë„ì²´ ì œì¡°ì‚¬ (0.1 + 0.3)
  - Community 1.2: ë°˜ë„ì²´ ì„¤ê³„ì‚¬ (0.2)

Level 2 (ìµœìƒìœ„):
  - Community 2.1: ë°˜ë„ì²´ ì‚°ì—… ì „ì²´
\`\`\`

### ì»¤ë®¤ë‹ˆí‹° ìš”ì•½ ìƒì„±

ê° ì»¤ë®¤ë‹ˆí‹°ì— ëŒ€í•´ LLMìœ¼ë¡œ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤:

\`\`\`python
def summarize_community(entities: list, relations: list, llm) -> str:
    prompt = f"""
ë‹¤ìŒ ì—”í‹°í‹°ì™€ ê´€ê³„ë¡œ êµ¬ì„±ëœ ì»¤ë®¤ë‹ˆí‹°ë¥¼ ìš”ì•½í•˜ì„¸ìš”:

ì—”í‹°í‹°: {entities}
ê´€ê³„: {relations}

ìš”ì•½ (2-3ë¬¸ì¥):
"""
    return llm.invoke(prompt).content

# ê²°ê³¼ ì˜ˆì‹œ:
# "ì´ ì»¤ë®¤ë‹ˆí‹°ëŠ” ë°˜ë„ì²´ ì œì¡° ê¸°ì—…ë“¤ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.
#  ì‚¼ì„±ì „ìì™€ SKí•˜ì´ë‹‰ìŠ¤ëŠ” ë©”ëª¨ë¦¬ ë°˜ë„ì²´ ë¶„ì•¼ì—ì„œ ê²½ìŸí•˜ë©°,
#  TSMCëŠ” íŒŒìš´ë“œë¦¬ ì‹œì¥ì„ ì£¼ë„í•©ë‹ˆë‹¤."
\`\`\`
`,
    keyPoints: [
      'Leiden ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ì»¤ë®¤ë‹ˆí‹° íƒì§€',
      'ê³„ì¸µì  ì»¤ë®¤ë‹ˆí‹° (Level 0, 1, 2...)',
      'ê° ì»¤ë®¤ë‹ˆí‹°ë³„ LLM ìš”ì•½ ìƒì„±',
      'Global Searchì—ì„œ ì»¤ë®¤ë‹ˆí‹° ìš”ì•½ í™œìš©',
    ],
    practiceGoal: 'ì»¤ë®¤ë‹ˆí‹° íƒì§€ì™€ ìš”ì•½ ìƒì„± ì›ë¦¬ ì´í•´',
  }
)

// Task 4: Local Search êµ¬í˜„
const task4 = createCodeTask(
  'w6d3-local-search',
  'ì‹¤ìŠµ: Local Search êµ¬í˜„',
  45,
  {
    introduction: `
## Local Search

íŠ¹ì • ì—”í‹°í‹°ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.

### Local Search ì•Œê³ ë¦¬ì¦˜

\`\`\`
1. ì§ˆë¬¸ì—ì„œ ì—”í‹°í‹° ì¶”ì¶œ
2. í•´ë‹¹ ì—”í‹°í‹°ì˜ ì´ì›ƒ íƒìƒ‰ (1-2 hop)
3. ê´€ë ¨ í…ìŠ¤íŠ¸ ì²­í¬ ìˆ˜ì§‘
4. ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± â†’ LLM ì‘ë‹µ
\`\`\`

### êµ¬í˜„

\`\`\`python
class LocalSearch:
    def __init__(self, graph, vector_store, llm):
        self.graph = graph  # Neo4j ë˜ëŠ” NetworkX
        self.vector_store = vector_store
        self.llm = llm

    def extract_entities(self, question: str) -> list:
        """ì§ˆë¬¸ì—ì„œ ì—”í‹°í‹° ì¶”ì¶œ"""
        prompt = f"ë‹¤ìŒ ì§ˆë¬¸ì—ì„œ ê²€ìƒ‰í•  ì—”í‹°í‹°ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”: {question}"
        result = self.llm.invoke(prompt)
        return result.content.split(", ")

    def get_entity_context(self, entity: str) -> dict:
        """ì—”í‹°í‹° ì£¼ë³€ ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘"""
        # 1. ê·¸ë˜í”„ì—ì„œ ì´ì›ƒ íƒìƒ‰
        neighbors = self.graph.query(f'''
            MATCH (e {{name: "{entity}"}})-[r]-(n)
            RETURN e, type(r) as rel, n
            LIMIT 20
        ''')

        # 2. ê´€ë ¨ í…ìŠ¤íŠ¸ ì²­í¬ ê²€ìƒ‰
        chunks = self.vector_store.similarity_search(entity, k=3)

        return {
            'entity': entity,
            'neighbors': neighbors,
            'chunks': [c.page_content for c in chunks]
        }

    def search(self, question: str) -> str:
        """Local Search ì‹¤í–‰"""
        # 1. ì—”í‹°í‹° ì¶”ì¶œ
        entities = self.extract_entities(question)

        # 2. ê° ì—”í‹°í‹° ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘
        contexts = []
        for entity in entities:
            ctx = self.get_entity_context(entity)
            contexts.append(ctx)

        # 3. ì»¨í…ìŠ¤íŠ¸ í¬ë§·íŒ…
        context_text = self._format_context(contexts)

        # 4. LLM ì‘ë‹µ ìƒì„±
        prompt = f"""
ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”:

{context_text}

ì§ˆë¬¸: {question}
"""
        return self.llm.invoke(prompt).content

    def _format_context(self, contexts: list) -> str:
        parts = []
        for ctx in contexts:
            parts.append(f"## {ctx['entity']}")
            parts.append("ê´€ê³„:")
            for n in ctx['neighbors']:
                parts.append(f"  - {n}")
            parts.append("ê´€ë ¨ í…ìŠ¤íŠ¸:")
            for chunk in ctx['chunks']:
                parts.append(f"  {chunk[:200]}...")
        return "\\n".join(parts)
\`\`\`
`,
    keyPoints: [
      'Local Search: íŠ¹ì • ì—”í‹°í‹° ì¤‘ì‹¬ ê²€ìƒ‰',
      'ì—”í‹°í‹° ì¶”ì¶œ â†’ ì´ì›ƒ íƒìƒ‰ â†’ ì²­í¬ ê²€ìƒ‰ â†’ ì‘ë‹µ',
      'ê·¸ë˜í”„ + ë²¡í„° ê²€ìƒ‰ ê²°í•©',
      'ìƒì„¸í•˜ê³  êµ¬ì²´ì ì¸ ì§ˆë¬¸ì— ì í•©',
    ],
    practiceGoal: 'Local Search íŒŒì´í”„ë¼ì¸ êµ¬í˜„',
    codeExample: `# Local Search ì‚¬ìš© ì˜ˆì‹œ
local_search = LocalSearch(graph, vector_store, llm)

# íŠ¹ì • ì—”í‹°í‹° ê´€ë ¨ ì§ˆë¬¸
result = local_search.search("ì‚¼ì„±ì „ìì˜ ì£¼ìš” ê²½ìŸì‚¬ëŠ” ëˆ„êµ¬ì¸ê°€ìš”?")
print(result)

# ë™ì‘ íë¦„:
# 1. ì—”í‹°í‹° ì¶”ì¶œ: ["ì‚¼ì„±ì „ì"]
# 2. ê·¸ë˜í”„ íƒìƒ‰: ì‚¼ì„±ì „ìì˜ COMPETES_WITH ê´€ê³„
# 3. ë²¡í„° ê²€ìƒ‰: "ì‚¼ì„±ì „ì" ê´€ë ¨ ë¬¸ì„œ
# 4. í†µí•© ì‘ë‹µ ìƒì„±`,
  }
)

// Task 5: Global Search êµ¬í˜„
const task5 = createCodeTask(
  'w6d3-global-search',
  'ì‹¤ìŠµ: Global Search êµ¬í˜„',
  45,
  {
    introduction: `
## Global Search

ì»¤ë®¤ë‹ˆí‹° ìš”ì•½ì„ í™œìš©í•˜ì—¬ ì „ì²´ì ì¸ ì§ˆë¬¸ì— ë‹µí•©ë‹ˆë‹¤.

### Global Search ì•Œê³ ë¦¬ì¦˜

\`\`\`
1. ì»¤ë®¤ë‹ˆí‹° ìš”ì•½ ë¡œë“œ (ì‚¬ì „ ìƒì„±ë¨)
2. ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì»¤ë®¤ë‹ˆí‹° ì„ íƒ
3. ì„ íƒëœ ì»¤ë®¤ë‹ˆí‹° ìš”ì•½ìœ¼ë¡œ ë‹µë³€ ìƒì„±
4. (ì„ íƒ) Map-Reduceë¡œ ëŒ€ê·œëª¨ ì²˜ë¦¬
\`\`\`

### êµ¬í˜„

\`\`\`python
class GlobalSearch:
    def __init__(self, community_summaries: dict, llm):
        """
        community_summaries: {
            "community_0": {"summary": "...", "entities": [...]},
            "community_1": {"summary": "...", "entities": [...]},
        }
        """
        self.summaries = community_summaries
        self.llm = llm

    def select_relevant_communities(self, question: str, top_k: int = 5) -> list:
        """ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì»¤ë®¤ë‹ˆí‹° ì„ íƒ"""
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­ (ì‹¤ì œë¡œëŠ” ì„ë² ë”© ìœ ì‚¬ë„ ì‚¬ìš©)
        scores = {}
        question_lower = question.lower()

        for comm_id, data in self.summaries.items():
            # ì—”í‹°í‹° ë§¤ì¹­ ì ìˆ˜
            entity_score = sum(
                1 for e in data['entities']
                if e.lower() in question_lower
            )
            # ìš”ì•½ í‚¤ì›Œë“œ ë§¤ì¹­
            summary_score = sum(
                1 for word in question_lower.split()
                if word in data['summary'].lower()
            )
            scores[comm_id] = entity_score * 2 + summary_score

        # ìƒìœ„ kê°œ ì„ íƒ
        sorted_comms = sorted(scores.items(), key=lambda x: -x[1])
        return [c[0] for c in sorted_comms[:top_k]]

    def search(self, question: str) -> str:
        """Global Search ì‹¤í–‰"""
        # 1. ê´€ë ¨ ì»¤ë®¤ë‹ˆí‹° ì„ íƒ
        relevant_comms = self.select_relevant_communities(question)

        # 2. ì»¤ë®¤ë‹ˆí‹° ìš”ì•½ ìˆ˜ì§‘
        summaries = []
        for comm_id in relevant_comms:
            summaries.append(self.summaries[comm_id]['summary'])

        # 3. Map: ê° ìš”ì•½ìœ¼ë¡œ ë¶€ë¶„ ë‹µë³€ ìƒì„±
        partial_answers = []
        for summary in summaries:
            prompt = f"""
ì»¤ë®¤ë‹ˆí‹° ìš”ì•½:
{summary}

ì§ˆë¬¸: {question}

ì´ ì»¤ë®¤ë‹ˆí‹° ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš” (ê´€ë ¨ ì—†ìœ¼ë©´ "ê´€ë ¨ ì •ë³´ ì—†ìŒ"):
"""
            partial = self.llm.invoke(prompt).content
            if "ê´€ë ¨ ì •ë³´ ì—†ìŒ" not in partial:
                partial_answers.append(partial)

        # 4. Reduce: ë¶€ë¶„ ë‹µë³€ í†µí•©
        if not partial_answers:
            return "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        reduce_prompt = f"""
ë‹¤ìŒ ë¶€ë¶„ ë‹µë³€ë“¤ì„ ì¢…í•©í•˜ì—¬ ìµœì¢… ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”:

{chr(10).join(partial_answers)}

ì§ˆë¬¸: {question}

ì¢…í•© ë‹µë³€:
"""
        return self.llm.invoke(reduce_prompt).content
\`\`\`
`,
    keyPoints: [
      'Global Search: ì»¤ë®¤ë‹ˆí‹° ìš”ì•½ ê¸°ë°˜ ê²€ìƒ‰',
      'Map-Reduce íŒ¨í„´ìœ¼ë¡œ ëŒ€ê·œëª¨ ì²˜ë¦¬',
      'ì „ì²´ì ì¸ ì§ˆë¬¸ (íŠ¸ë Œë“œ, ìš”ì•½)ì— ì í•©',
      'ì‚¬ì „ ìƒì„±ëœ ìš”ì•½ìœ¼ë¡œ ë¹ ë¥¸ ì‘ë‹µ',
    ],
    practiceGoal: 'Global Search íŒŒì´í”„ë¼ì¸ êµ¬í˜„',
    codeExample: `# Global Search ì‚¬ìš© ì˜ˆì‹œ
community_summaries = {
    "comm_0": {
        "summary": "ë°˜ë„ì²´ ì œì¡° ê¸°ì—…ë“¤ì˜ ì»¤ë®¤ë‹ˆí‹°. ì‚¼ì„±, SK, TSMC ë“±ì´ í¬í•¨.",
        "entities": ["ì‚¼ì„±ì „ì", "SKí•˜ì´ë‹‰ìŠ¤", "TSMC"]
    },
    "comm_1": {
        "summary": "AI/í´ë¼ìš°ë“œ ê¸°ì—…ë“¤ì˜ ì»¤ë®¤ë‹ˆí‹°. NVIDIA, Google, Microsoft ë“±.",
        "entities": ["NVIDIA", "Google", "Microsoft"]
    }
}

global_search = GlobalSearch(community_summaries, llm)

# ì „ì²´ì ì¸ ì§ˆë¬¸
result = global_search.search("ë°˜ë„ì²´ ì‚°ì—…ì˜ ì£¼ìš” íŠ¸ë Œë“œëŠ” ë¬´ì—‡ì¸ê°€ìš”?")
print(result)`,
  }
)

// Task 6: í€´ì¦ˆ
const task6 = createQuizTask(
  'w6d3-quiz',
  'Day 3 ë³µìŠµ í€´ì¦ˆ',
  20,
  {
    questions: [
      {
        id: 'q1',
        question: 'MS GraphRAGì—ì„œ ì»¤ë®¤ë‹ˆí‹° íƒì§€ì— ì‚¬ìš©í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ì€?',
        options: [
          'K-means',
          'Leiden',
          'PageRank',
          'BFS',
        ],
        correctAnswer: 1,
        explanation: 'MS GraphRAGëŠ” Leiden ì•Œê³ ë¦¬ì¦˜ (Louvainì˜ ê°œì„  ë²„ì „)ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.',
      },
      {
        id: 'q2',
        question: '"ì „ì²´ ë°ì´í„°ì…‹ì˜ ì£¼ìš” íŠ¸ë Œë“œëŠ”?" ì§ˆë¬¸ì— ì í•©í•œ ê²€ìƒ‰ ë°©ì‹ì€?',
        options: [
          'Local Search',
          'Global Search',
          'Keyword Search',
          'Full-text Search',
        ],
        correctAnswer: 1,
        explanation: 'Global SearchëŠ” ì»¤ë®¤ë‹ˆí‹° ìš”ì•½ì„ í™œìš©í•˜ì—¬ ì „ì²´ì ì¸ ì§ˆë¬¸ì— ë‹µí•©ë‹ˆë‹¤.',
      },
      {
        id: 'q3',
        question: 'Global Searchì—ì„œ Map-Reduce íŒ¨í„´ì˜ ì—­í• ì€?',
        options: [
          'ë°ì´í„° ì••ì¶•',
          'ê° ì»¤ë®¤ë‹ˆí‹°ë³„ ë¶€ë¶„ ë‹µë³€ ìƒì„± í›„ í†µí•©',
          'ë³´ì•ˆ ì•”í˜¸í™”',
          'ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°',
        ],
        correctAnswer: 1,
        explanation: 'Map: ê° ì»¤ë®¤ë‹ˆí‹° ìš”ì•½ìœ¼ë¡œ ë¶€ë¶„ ë‹µë³€ ìƒì„±, Reduce: ë¶€ë¶„ ë‹µë³€ í†µí•©',
      },
      {
        id: 'q4',
        question: 'MS GraphRAGì˜ ê³„ì¸µì  ì»¤ë®¤ë‹ˆí‹° êµ¬ì¡°ì˜ ì¥ì ì€?',
        options: [
          'ì €ì¥ ê³µê°„ ì ˆì•½',
          'ì„¸ë¶€ ì •ë³´ë¶€í„° ì „ì²´ ìš”ì•½ê¹Œì§€ ë‹¤ì–‘í•œ ìˆ˜ì¤€ì˜ ì´í•´ ì œê³µ',
          'ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸',
          'ë‹¤êµ­ì–´ ì§€ì›',
        ],
        correctAnswer: 1,
        explanation: 'ê³„ì¸µì  êµ¬ì¡°ë¡œ ì„¸ë¶€ ì‚¬í•­(Level 0)ë¶€í„° ì „ì²´ ìš”ì•½(Level N)ê¹Œì§€ ì œê³µí•©ë‹ˆë‹¤.',
      },
    ],
    keyPoints: [
      'MS GraphRAG í•µì‹¬ ê°œë… ì´í•´',
      'Local vs Global Search êµ¬ë¶„',
      'Map-Reduce íŒ¨í„´ í™œìš©',
    ],
    practiceGoal: 'Day 3 í•™ìŠµ ë‚´ìš© ë³µìŠµ',
  }
)

// Day 3 Export
export const day3MsGraphrag: Day = {
  slug: 'ms-graphrag',
  title: 'Microsoft GraphRAG',
  totalDuration: 230,
  tasks: [task1, task2, task3, task4, task5, task6],
}
