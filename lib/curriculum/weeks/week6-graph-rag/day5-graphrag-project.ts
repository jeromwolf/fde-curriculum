// Week 6 Day 5: GraphRAG Q&A ì‹œìŠ¤í…œ í”„ë¡œì íŠ¸

import type { Day } from './types'
import {
  createVideoTask,
  createReadingTask,
  createCodeTask,
  createQuizTask,
  createChallengeTask,
} from './types'

// Task 1: í”„ë¡œì íŠ¸ ê°œìš”
const task1 = createVideoTask(
  'w6d5-project-intro',
  'GraphRAG Q&A ì‹œìŠ¤í…œ í”„ë¡œì íŠ¸ ê°€ì´ë“œ',
  20,
  {
    introduction: `
## GraphRAG Q&A ì‹œìŠ¤í…œ í”„ë¡œì íŠ¸

### í”„ë¡œì íŠ¸ ëª©í‘œ

Week 6ì—ì„œ ë°°ìš´ ëª¨ë“  ê¸°ìˆ ì„ í†µí•©í•˜ì—¬
**Knowledge Graph ê¸°ë°˜ Q&A ì‹œìŠ¤í…œ**ì„ êµ¬ì¶•í•©ë‹ˆë‹¤.

### ì‹œìŠ¤í…œ êµ¬ì„±ìš”ì†Œ

\`\`\`
[ë¬¸ì„œ ìˆ˜ì§‘] â†’ [KG êµ¬ì¶•] â†’ [ê²€ìƒ‰ ì—”ì§„] â†’ [Q&A ì¸í„°í˜ì´ìŠ¤]
\`\`\`

1. **ë¬¸ì„œ ìˆ˜ì§‘**: ë‰´ìŠ¤ ê¸°ì‚¬ ë˜ëŠ” ë¬¸ì„œ ìˆ˜ì§‘
2. **KG êµ¬ì¶•**: ì—”í‹°í‹°/ê´€ê³„ ì¶”ì¶œ â†’ Neo4j ì €ì¥
3. **ê²€ìƒ‰ ì—”ì§„**: Local + Global Search
4. **ì¸í„°í˜ì´ìŠ¤**: Streamlit ë˜ëŠ” FastAPI

### ê¸°ìˆ  ìŠ¤íƒ

| ì»´í¬ë„ŒíŠ¸ | ê¸°ìˆ  |
|---------|------|
| Knowledge Graph | Neo4j |
| Vector Store | Neo4j Vector / Chroma |
| LLM | OpenAI GPT-4o-mini |
| Framework | LangChain |
| UI | Streamlit |

### í‰ê°€ ê¸°ì¤€

- ê¸°ëŠ¥ ì™„ì„±ë„ (40%)
- ì½”ë“œ í’ˆì§ˆ (20%)
- GraphRAG ê¸°ë²• í™œìš© (30%)
- UI/UX (10%)
`,
    keyPoints: [
      'ë¬¸ì„œ â†’ KG êµ¬ì¶• â†’ ê²€ìƒ‰ â†’ Q&A ì „ì²´ íŒŒì´í”„ë¼ì¸',
      'Neo4j + LangChain + Streamlit í†µí•©',
      'Local/Global Search ëª¨ë‘ êµ¬í˜„',
      'ì‹¤ì œ ë™ì‘í•˜ëŠ” ì‹œìŠ¤í…œ ì™„ì„±',
    ],
    practiceGoal: 'í”„ë¡œì íŠ¸ êµ¬ì¡°ì™€ ìš”êµ¬ì‚¬í•­ ì´í•´',
  }
)

// Task 2: KG êµ¬ì¶• íŒŒì´í”„ë¼ì¸
const task2 = createCodeTask(
  'w6d5-kg-construction',
  'ì‹¤ìŠµ: Knowledge Graph êµ¬ì¶• íŒŒì´í”„ë¼ì¸',
  60,
  {
    introduction: `
## Knowledge Graph êµ¬ì¶•

### ì „ì²´ íŒŒì´í”„ë¼ì¸

\`\`\`python
from langchain_openai import ChatOpenAI
from langchain_community.graphs import Neo4jGraph
from langchain.text_splitter import RecursiveCharacterTextSplitter
import json

class KGConstructor:
    def __init__(self, neo4j_url, neo4j_user, neo4j_password):
        self.graph = Neo4jGraph(
            url=neo4j_url,
            username=neo4j_user,
            password=neo4j_password
        )
        self.llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
        self.splitter = RecursiveCharacterTextSplitter(
            chunk_size=2000,
            chunk_overlap=200
        )

    def extract_entities_relations(self, text: str) -> dict:
        """í…ìŠ¤íŠ¸ì—ì„œ ì—”í‹°í‹°/ê´€ê³„ ì¶”ì¶œ"""
        prompt = f'''
í…ìŠ¤íŠ¸ì—ì„œ ì—”í‹°í‹°ì™€ ê´€ê³„ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

í…ìŠ¤íŠ¸: {text}

JSON í˜•ì‹:
{{"entities": [{{"name": "...", "type": "...", "description": "..."}}],
 "relations": [{{"source": "...", "relation": "...", "target": "...", "description": "..."}}]}}
'''
        result = self.llm.invoke(prompt)
        return json.loads(result.content)

    def create_graph_elements(self, data: dict):
        """Neo4jì— ì—”í‹°í‹°/ê´€ê³„ ìƒì„±"""
        # ì—”í‹°í‹° ìƒì„±
        for entity in data.get('entities', []):
            query = '''
            MERGE (e:Entity {name: $name})
            SET e.type = $type, e.description = $description
            '''
            self.graph.query(query, {
                'name': entity['name'],
                'type': entity.get('type', 'Unknown'),
                'description': entity.get('description', '')
            })

        # ê´€ê³„ ìƒì„±
        for rel in data.get('relations', []):
            query = '''
            MATCH (s:Entity {name: $source})
            MATCH (t:Entity {name: $target})
            MERGE (s)-[r:RELATES_TO {type: $relation}]->(t)
            SET r.description = $description
            '''
            self.graph.query(query, {
                'source': rel['source'],
                'target': rel['target'],
                'relation': rel['relation'],
                'description': rel.get('description', '')
            })

    def process_documents(self, documents: list):
        """ë¬¸ì„œ ëª©ë¡ ì²˜ë¦¬"""
        for doc in documents:
            chunks = self.splitter.split_text(doc)
            for chunk in chunks:
                data = self.extract_entities_relations(chunk)
                self.create_graph_elements(data)
                print(f"Processed: {len(data.get('entities', []))} entities, "
                      f"{len(data.get('relations', []))} relations")

# ì‚¬ìš©
constructor = KGConstructor(
    "bolt://localhost:7687", "neo4j", "password"
)
constructor.process_documents(["ë¬¸ì„œ1 ë‚´ìš©...", "ë¬¸ì„œ2 ë‚´ìš©..."])
\`\`\`
`,
    keyPoints: [
      'LLMìœ¼ë¡œ ì—”í‹°í‹°/ê´€ê³„ ìë™ ì¶”ì¶œ',
      'MERGEë¡œ ì¤‘ë³µ ì—†ì´ Neo4jì— ì €ì¥',
      'ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬ë¡œ ê¸´ ë¬¸ì„œ ì§€ì›',
      'êµ¬ì¡°í™”ëœ JSON ì¶œë ¥ìœ¼ë¡œ íŒŒì‹± ìš©ì´',
    ],
    practiceGoal: 'ë¬¸ì„œë¡œë¶€í„° Knowledge Graph ìë™ êµ¬ì¶•',
    codeExample: `# KG êµ¬ì¶• ì‹¤í–‰ ì˜ˆì‹œ
documents = [
    """ì‚¼ì„±ì „ìëŠ” ì„¸ê³„ ìµœëŒ€ ë©”ëª¨ë¦¬ ë°˜ë„ì²´ ê¸°ì—…ì´ë‹¤.
    ì´ì¬ìš© íšŒì¥ì´ ê²½ì˜ì„ ë§¡ê³  ìˆìœ¼ë©°, SKí•˜ì´ë‹‰ìŠ¤ì™€ ê²½ìŸí•œë‹¤.
    ìµœê·¼ NVIDIAì™€ HBM ê³µê¸‰ ê³„ì•½ì„ ì²´ê²°í–ˆë‹¤.""",

    """NVIDIAëŠ” AI ì¹© ì‹œì¥ì„ ì„ ë„í•˜ëŠ” ê¸°ì—…ì´ë‹¤.
    ì  ìŠ¨ í™© CEOê°€ ì´ëŒê³  ìˆìœ¼ë©°, AMDì™€ ê²½ìŸí•œë‹¤."""
]

constructor = KGConstructor("bolt://localhost:7687", "neo4j", "password")
constructor.process_documents(documents)

# ê²°ê³¼ í™•ì¸
print(constructor.graph.query("MATCH (n) RETURN count(n) as count"))`,
  }
)

// Task 3: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ êµ¬í˜„
const task3 = createCodeTask(
  'w6d5-hybrid-search',
  'ì‹¤ìŠµ: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì—”ì§„ êµ¬í˜„',
  50,
  {
    introduction: `
## í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì—”ì§„

### í†µí•© ê²€ìƒ‰ í´ë˜ìŠ¤

\`\`\`python
from langchain_community.graphs import Neo4jGraph
from langchain_community.vectorstores import Neo4jVector
from langchain_openai import OpenAIEmbeddings, ChatOpenAI

class HybridSearchEngine:
    def __init__(self, neo4j_url, neo4j_user, neo4j_password):
        self.graph = Neo4jGraph(
            url=neo4j_url,
            username=neo4j_user,
            password=neo4j_password
        )
        self.vector_store = Neo4jVector.from_existing_index(
            embedding=OpenAIEmbeddings(),
            url=neo4j_url,
            username=neo4j_user,
            password=neo4j_password,
            index_name="document_index"
        )
        self.llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

    def route_query(self, question: str) -> str:
        """Local vs Global ë¼ìš°íŒ…"""
        prompt = f'''ì§ˆë¬¸ ìœ í˜•ì„ íŒë‹¨í•˜ì„¸ìš”.
ì§ˆë¬¸: {question}
LOCAL (íŠ¹ì • ì—”í‹°í‹°) ë˜ëŠ” GLOBAL (ì „ì²´ ìš”ì•½/íŠ¸ë Œë“œ)
ë‹µë³€ (í•œ ë‹¨ì–´):'''
        result = self.llm.invoke(prompt)
        return result.content.strip().upper()

    def extract_entities(self, question: str) -> list:
        """ì§ˆë¬¸ì—ì„œ ì—”í‹°í‹° ì¶”ì¶œ"""
        prompt = f"ì§ˆë¬¸ì—ì„œ ê²€ìƒ‰í•  ì—”í‹°í‹° ì´ë¦„ë§Œ ì¶”ì¶œ (ì‰¼í‘œ êµ¬ë¶„): {question}"
        result = self.llm.invoke(prompt)
        return [e.strip() for e in result.content.split(",") if e.strip()]

    def local_search(self, question: str) -> str:
        """Local Search: ì—”í‹°í‹° ê¸°ë°˜"""
        entities = self.extract_entities(question)
        graph_context = []

        for entity in entities:
            results = self.graph.query('''
                MATCH (e:Entity {name: $name})-[r]-(n)
                RETURN e.name, type(r), r.type, n.name, n.type
                LIMIT 15
            ''', {'name': entity})

            for r in results:
                graph_context.append(
                    f"{r['e.name']} -[{r['r.type']}]-> {r['n.name']}"
                )

        # ë²¡í„° ê²€ìƒ‰ ë³´ì™„
        vector_docs = self.vector_store.similarity_search(question, k=3)
        vector_context = "\\n".join([d.page_content for d in vector_docs])

        return f"=== ê·¸ë˜í”„ ê´€ê³„ ===\\n{chr(10).join(graph_context)}\\n\\n=== ê´€ë ¨ ë¬¸ì„œ ===\\n{vector_context}"

    def global_search(self, question: str) -> str:
        """Global Search: ì „ì²´ ìš”ì•½"""
        # ì£¼ìš” ì—”í‹°í‹° í†µê³„
        stats = self.graph.query('''
            MATCH (e:Entity)
            RETURN e.type as type, count(*) as count
            ORDER BY count DESC
            LIMIT 5
        ''')

        # ì£¼ìš” ê´€ê³„
        relations = self.graph.query('''
            MATCH (s)-[r]->(t)
            RETURN s.name, r.type, t.name
            LIMIT 20
        ''')

        context = "=== ì—”í‹°í‹° í†µê³„ ===\\n"
        for s in stats:
            context += f"- {s['type']}: {s['count']}ê°œ\\n"

        context += "\\n=== ì£¼ìš” ê´€ê³„ ===\\n"
        for r in relations:
            context += f"- {r['s.name']} â†’ {r['r.type']} â†’ {r['t.name']}\\n"

        return context

    def search(self, question: str) -> str:
        """í†µí•© ê²€ìƒ‰"""
        route = self.route_query(question)

        if route == "LOCAL":
            context = self.local_search(question)
        else:
            context = self.global_search(question)

        # LLM ì‘ë‹µ ìƒì„±
        prompt = f'''ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.

{context}

ì§ˆë¬¸: {question}
ë‹µë³€:'''
        return self.llm.invoke(prompt).content
\`\`\`
`,
    keyPoints: [
      'ì¿¼ë¦¬ ë¼ìš°íŒ…ìœ¼ë¡œ Local/Global ìë™ ì„ íƒ',
      'Local: ì—”í‹°í‹° ì¶”ì¶œ â†’ ê·¸ë˜í”„ + ë²¡í„° ê²€ìƒ‰',
      'Global: ì „ì²´ í†µê³„ ë° ì£¼ìš” ê´€ê³„ ìˆ˜ì§‘',
      'í†µí•© ì»¨í…ìŠ¤íŠ¸ë¡œ LLM ì‘ë‹µ ìƒì„±',
    ],
    practiceGoal: 'ë¼ìš°íŒ… ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì—”ì§„ êµ¬í˜„',
    codeExample: `# ê²€ìƒ‰ ì—”ì§„ ì‚¬ìš© ì˜ˆì‹œ
engine = HybridSearchEngine(
    "bolt://localhost:7687", "neo4j", "password"
)

# Local Search (íŠ¹ì • ì—”í‹°í‹°)
print(engine.search("ì‚¼ì„±ì „ìì˜ ê²½ìŸì‚¬ëŠ” ëˆ„êµ¬ì¸ê°€ìš”?"))

# Global Search (ì „ì²´ ìš”ì•½)
print(engine.search("ì´ ë°ì´í„°ì…‹ì˜ ì£¼ìš” ê¸°ì—…ë“¤ì€ ì–´ë–¤ ê´€ê³„ë¥¼ ê°€ì§€ê³  ìˆë‚˜ìš”?"))`,
  }
)

// Task 4: Streamlit UI êµ¬í˜„
const task4 = createCodeTask(
  'w6d5-streamlit-ui',
  'ì‹¤ìŠµ: Streamlit Q&A ì¸í„°í˜ì´ìŠ¤',
  50,
  {
    introduction: `
## Streamlit Q&A ì¸í„°í˜ì´ìŠ¤

### ê¸°ë³¸ UI êµ¬ì¡°

\`\`\`python
# app.py
import streamlit as st
from search_engine import HybridSearchEngine

st.set_page_config(page_title="GraphRAG Q&A", layout="wide")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []
if "engine" not in st.session_state:
    st.session_state.engine = HybridSearchEngine(
        st.secrets["NEO4J_URI"],
        st.secrets["NEO4J_USER"],
        st.secrets["NEO4J_PASSWORD"]
    )

# í—¤ë”
st.title("ğŸ” GraphRAG Q&A ì‹œìŠ¤í…œ")
st.markdown("Knowledge Graph ê¸°ë°˜ ì§ˆë¬¸ ë‹µë³€ ì‹œìŠ¤í…œ")

# ì‚¬ì´ë“œë°”: ì„¤ì •
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    search_mode = st.radio(
        "ê²€ìƒ‰ ëª¨ë“œ",
        ["ìë™ (ë¼ìš°íŒ…)", "Local Only", "Global Only"]
    )

    if st.button("ëŒ€í™” ì´ˆê¸°í™”"):
        st.session_state.messages = []
        st.rerun()

    # ê·¸ë˜í”„ í†µê³„
    st.header("ğŸ“Š ê·¸ë˜í”„ í†µê³„")
    stats = st.session_state.engine.graph.query(
        "MATCH (n) RETURN count(n) as nodes"
    )
    st.metric("ì´ ë…¸ë“œ ìˆ˜", stats[0]['nodes'])

# ì±„íŒ… ê¸°ë¡ í‘œì‹œ
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# ì‚¬ìš©ì ì…ë ¥
if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # ì‘ë‹µ ìƒì„±
    with st.chat_message("assistant"):
        with st.spinner("ê²€ìƒ‰ ì¤‘..."):
            response = st.session_state.engine.search(prompt)
        st.markdown(response)

    # ì‘ë‹µ ì €ì¥
    st.session_state.messages.append({"role": "assistant", "content": response})
\`\`\`

### ê·¸ë˜í”„ ì‹œê°í™” ì¶”ê°€

\`\`\`python
from pyvis.network import Network
import streamlit.components.v1 as components

def visualize_graph(engine, query: str):
    """ê²€ìƒ‰ ê²°ê³¼ ê·¸ë˜í”„ ì‹œê°í™”"""
    # ê´€ë ¨ ë…¸ë“œ/ì—£ì§€ ì¡°íšŒ
    results = engine.graph.query(f'''
        MATCH (s)-[r]->(t)
        WHERE s.name CONTAINS "{query}" OR t.name CONTAINS "{query}"
        RETURN s.name as source, type(r) as relation, t.name as target
        LIMIT 30
    ''')

    # PyVis ê·¸ë˜í”„ ìƒì„±
    net = Network(height="400px", width="100%")

    for r in results:
        net.add_node(r['source'], label=r['source'])
        net.add_node(r['target'], label=r['target'])
        net.add_edge(r['source'], r['target'], label=r['relation'])

    # HTML ì €ì¥ ë° í‘œì‹œ
    net.save_graph("graph.html")
    with open("graph.html", "r") as f:
        components.html(f.read(), height=420)
\`\`\`
`,
    keyPoints: [
      'Streamlit ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„',
      'ì„¸ì…˜ ìƒíƒœë¡œ ëŒ€í™” ê¸°ë¡ ìœ ì§€',
      'ì‚¬ì´ë“œë°”ì— ì„¤ì • ë° í†µê³„ í‘œì‹œ',
      'PyVisë¡œ ê´€ë ¨ ê·¸ë˜í”„ ì‹œê°í™”',
    ],
    practiceGoal: 'Streamlit ê¸°ë°˜ Q&A ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„',
    codeExample: `# secrets.toml ì„¤ì •
# [secrets]
# NEO4J_URI = "bolt://localhost:7687"
# NEO4J_USER = "neo4j"
# NEO4J_PASSWORD = "password"

# ì‹¤í–‰
# streamlit run app.py`,
  }
)

// Task 5: í…ŒìŠ¤íŠ¸ ë° ë°°í¬
const task5 = createReadingTask(
  'w6d5-deployment',
  'í…ŒìŠ¤íŠ¸ ë° ë°°í¬ ê°€ì´ë“œ',
  30,
  {
    introduction: `
## í…ŒìŠ¤íŠ¸ ë° ë°°í¬

### í…ŒìŠ¤íŠ¸ ì²´í¬ë¦¬ìŠ¤íŠ¸

**ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸**:
- [ ] KG êµ¬ì¶•: ë¬¸ì„œì—ì„œ ì—”í‹°í‹°/ê´€ê³„ ì¶”ì¶œ
- [ ] Local Search: íŠ¹ì • ì—”í‹°í‹° ì§ˆë¬¸ ì‘ë‹µ
- [ ] Global Search: ì „ì²´ ìš”ì•½ ì§ˆë¬¸ ì‘ë‹µ
- [ ] ì¿¼ë¦¬ ë¼ìš°íŒ…: ìë™ ëª¨ë“œ ì „í™˜
- [ ] ëŒ€í™” ê¸°ë¡: ë§¥ë½ ìœ ì§€

**í’ˆì§ˆ í…ŒìŠ¤íŠ¸**:
- [ ] ì—”í‹°í‹° ì¶”ì¶œ ì •í™•ë„
- [ ] ê´€ê³„ ì¶”ì¶œ ì •í™•ë„
- [ ] ì‘ë‹µ ê´€ë ¨ì„±
- [ ] ì‘ë‹µ ì‹œê°„ (< 5ì´ˆ)

### Streamlit Cloud ë°°í¬

\`\`\`yaml
# requirements.txt
langchain>=0.1.0
langchain-openai>=0.0.5
langchain-community>=0.0.10
neo4j>=5.0.0
streamlit>=1.30.0
pyvis>=0.3.0
\`\`\`

1. GitHubì— ì½”ë“œ í‘¸ì‹œ
2. streamlit.io ì ‘ì†
3. "New app" â†’ GitHub ì €ì¥ì†Œ ì—°ê²°
4. Secrets ì„¤ì • (NEO4J_URI ë“±)
5. ë°°í¬

### Docker ë°°í¬

\`\`\`dockerfile
FROM python:3.11-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

EXPOSE 8501
CMD ["streamlit", "run", "app.py", "--server.port=8501"]
\`\`\`

\`\`\`bash
docker build -t graphrag-qa .
docker run -p 8501:8501 graphrag-qa
\`\`\`

### ì„±ëŠ¥ ìµœì í™” íŒ

1. **Neo4j ì¸ë±ìŠ¤**: ìì£¼ ê²€ìƒ‰í•˜ëŠ” ì†ì„±ì— ì¸ë±ìŠ¤
2. **ê²°ê³¼ ìºì‹±**: ë™ì¼ ì§ˆë¬¸ ìºì‹œ
3. **ë¹„ë™ê¸° ì²˜ë¦¬**: ê·¸ë˜í”„/ë²¡í„° ê²€ìƒ‰ ë³‘ë ¬í™”
4. **ì²­í¬ í¬ê¸°**: 1000-2000 í† í° ê¶Œì¥
`,
    keyPoints: [
      'ê¸°ëŠ¥ ë° í’ˆì§ˆ í…ŒìŠ¤íŠ¸ ì²´í¬ë¦¬ìŠ¤íŠ¸',
      'Streamlit Cloudë¡œ ì‰¬ìš´ ë°°í¬',
      'Dockerë¡œ ì´ì‹ì„± ë†’ì€ ë°°í¬',
      'ì¸ë±ìŠ¤, ìºì‹±, ë³‘ë ¬í™”ë¡œ ì„±ëŠ¥ ìµœì í™”',
    ],
    practiceGoal: 'í…ŒìŠ¤íŠ¸ ë° ë°°í¬ ë°©ë²• ì´í•´',
  }
)

// Task 6: ë„ì „ ê³¼ì œ
const task6 = createChallengeTask(
  'w6d5-challenge',
  'ë„ì „ ê³¼ì œ: ê³ ê¸‰ ê¸°ëŠ¥ ì¶”ê°€',
  60,
  {
    introduction: `
## ë„ì „ ê³¼ì œ

ê¸°ë³¸ GraphRAG Q&A ì‹œìŠ¤í…œì— ê³ ê¸‰ ê¸°ëŠ¥ì„ ì¶”ê°€í•˜ì„¸ìš”.

### ì„ íƒ ê³¼ì œ (2ê°œ ì´ìƒ êµ¬í˜„)

**1. Re-ranking ì¶”ê°€**
- Cross-Encoderë¡œ ê²€ìƒ‰ ê²°ê³¼ ì¬ì •ë ¬
- Cohere Rerank API ì—°ë™

**2. ëŒ€í™”í˜• ê¸°ëŠ¥**
- ì§ˆë¬¸ ì¬êµ¬ì„± (ëŒ€ëª…ì‚¬ í•´ê²°)
- ëŒ€í™” ê¸°ë¡ Neo4j ì €ì¥

**3. ì†ŒìŠ¤ ì¸ìš©**
- ë‹µë³€ì— ì¶œì²˜ í‘œì‹œ
- ê´€ë ¨ ê·¸ë˜í”„ ê²½ë¡œ í‘œì‹œ

**4. í”¼ë“œë°± ì‹œìŠ¤í…œ**
- ì¢‹ì•„ìš”/ì‹«ì–´ìš” ë²„íŠ¼
- í”¼ë“œë°± ê¸°ë°˜ ê°œì„ 

**5. ë©€í‹°ëª¨ë‹¬**
- ê·¸ë˜í”„ ì‹œê°í™” ê°œì„ 
- ì—”í‹°í‹° ì´ë¯¸ì§€ í‘œì‹œ

### ì œì¶œë¬¼

1. ì†ŒìŠ¤ ì½”ë“œ (GitHub)
2. README.md (ì„¤ì¹˜/ì‹¤í–‰ ë°©ë²•)
3. ë°ëª¨ ì˜ìƒ ë˜ëŠ” ë°°í¬ URL
4. êµ¬í˜„ ê¸°ëŠ¥ ì„¤ëª… ë¬¸ì„œ
`,
    keyPoints: [
      'Re-ranking, ëŒ€í™”í˜• ê¸°ëŠ¥ ë“± ê³ ê¸‰ ê¸°ëŠ¥',
      'ì‹¤ì œ ë™ì‘í•˜ëŠ” ì‹œìŠ¤í…œ ì™„ì„±',
      'GitHub + README ë¬¸ì„œí™”',
      'ë°ëª¨ ë˜ëŠ” ë°°í¬ URL ì œê³µ',
    ],
    practiceGoal: 'GraphRAG Q&A ì‹œìŠ¤í…œ ì™„ì„± ë° ê³ ê¸‰ ê¸°ëŠ¥ ì¶”ê°€',
  }
)

// Day 5 Export
export const day5GraphragProject: Day = {
  slug: 'graphrag-project',
  title: 'GraphRAG Q&A ì‹œìŠ¤í…œ í”„ë¡œì íŠ¸',
  totalDuration: 270,
  tasks: [task1, task2, task3, task4, task5],
  challenge: task6,
}
