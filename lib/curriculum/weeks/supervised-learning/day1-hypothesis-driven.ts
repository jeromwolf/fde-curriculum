// Week 13 Day 1: ê°€ì„¤ ê¸°ë°˜ ë¶„ì„
import type { Task } from '../../types'

export const day1Tasks: Task[] = [
  {
    id: 'p2w5d1t1',
    type: 'video',
    title: 'ê°€ì„¤ ê¸°ë°˜ ë¶„ì„ í”„ë¡œì„¸ìŠ¤',
    duration: 25,
    content: {
      videoUrl: 'https://www.youtube.com/watch?v=placeholder',
      transcript: `# ê°€ì„¤ ê¸°ë°˜ ë¶„ì„ (Hypothesis-Driven Analysis)

## ëª¨ë¸ë§ ì „ì— "ì™œ"ë¥¼ ëª…í™•íˆ

ëª¨ë¸ì„ ë§Œë“¤ê¸° ì „ì— ë°˜ë“œì‹œ ë¬¼ì–´ì•¼ í•  ì§ˆë¬¸:
- "ì™œ ì´ ëª¨ë¸ì„ ë§Œë“œëŠ”ê°€?"
- "ì´ ëª¨ë¸ì´ ë¹„ì¦ˆë‹ˆìŠ¤ì— ì–´ë–¤ ê°€ì¹˜ë¥¼ ì£¼ëŠ”ê°€?"

## ê°€ì„¤ ê¸°ë°˜ ë¶„ì„ í”„ë¡œì„¸ìŠ¤

\`\`\`
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  ê°€ì„¤ ê¸°ë°˜ ë¶„ì„ í”„ë¡œì„¸ìŠ¤                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. ë¬¸ì œ ì •ì˜                                                â”‚
â”‚     "ì¬êµ¬ë§¤ìœ¨ì´ 30% í•˜ë½í•œ ì´ìœ ëŠ”?"                          â”‚
â”‚              â”‚                                               â”‚
â”‚              â–¼                                               â”‚
â”‚  2. ê°€ì„¤ ìˆ˜ë¦½                                                â”‚
â”‚     H1: ë°°ì†¡ ì‹œê°„ ì¦ê°€ â†’ ë§Œì¡±ë„ í•˜ë½ â†’ ì¬êµ¬ë§¤ ê°ì†Œ          â”‚
â”‚     H2: ê²½ìŸì‚¬ í”„ë¡œëª¨ì…˜ â†’ ê³ ê° ì´íƒˆ                         â”‚
â”‚     H3: ì œí’ˆ í’ˆì§ˆ í•˜ë½ â†’ ë°˜í’ˆ ì¦ê°€ â†’ ì¬êµ¬ë§¤ ê°ì†Œ            â”‚
â”‚              â”‚                                               â”‚
â”‚              â–¼                                               â”‚
â”‚  3. ë°ì´í„° ë¶„ì„ (ê²€ì¦)                                       â”‚
â”‚     ê° ê°€ì„¤ì— ëŒ€í•œ ì¦ê±° ìˆ˜ì§‘                                 â”‚
â”‚              â”‚                                               â”‚
â”‚              â–¼                                               â”‚
â”‚  4. ê²°ë¡  ë„ì¶œ                                                â”‚
â”‚     "H1 ì§€ì§€: ë°°ì†¡ ì‹œê°„ 3ì¼â†’5ì¼, ì¬êµ¬ë§¤ìœ¨ -25%p ìƒê´€"       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\`\`\`

## ì¢‹ì€ ê°€ì„¤ì˜ ì¡°ê±´

\`\`\`python
# ì¢‹ì€ ê°€ì„¤ vs ë‚˜ìœ ê°€ì„¤

# âœ… ì¢‹ì€ ê°€ì„¤
hypothesis_good = {
    'statement': "ë°°ì†¡ 3ì¼ ì´ìƒì´ë©´ ì¬êµ¬ë§¤ìœ¨ 20% í•˜ë½",
    'specific': True,        # êµ¬ì²´ì 
    'measurable': True,      # ì¸¡ì • ê°€ëŠ¥ (ë°ì´í„°ë¡œ ê²€ì¦)
    'actionable': True       # í–‰ë™ ê°€ëŠ¥ (ë°°ì†¡ ê°œì„ )
}

# âŒ ë‚˜ìœ ê°€ì„¤
hypothesis_bad = {
    'statement': "ê³ ê°ì´ ë¶ˆë§Œì¡±í•´ì„œ ê·¸ë ‡ë‹¤",
    'specific': False,       # ë„ˆë¬´ ëª¨í˜¸
    'measurable': False,     # ì–´ë–»ê²Œ ì¸¡ì •?
    'actionable': False      # ì–´ë–¤ í–‰ë™?
}
\`\`\`

## ì‹¤ì „ ì˜ˆì œ: ê³ ê° ì´íƒˆ ë¶„ì„

\`\`\`python
# 1. ë¬¸ì œ ì •ì˜
problem = "ì›”ê°„ ê³ ê° ì´íƒˆë¥ ì´ 5%ì—ì„œ 8%ë¡œ ì¦ê°€"

# 2. ê°€ì„¤ ìˆ˜ë¦½
hypotheses = [
    {
        'id': 'H1',
        'statement': 'ê°€ê²© ì¸ìƒ í›„ ì´íƒˆ ì¦ê°€',
        'data_needed': ['price_change_date', 'churn_date'],
        'metric': 'ê°€ê²© ì¸ìƒ ì „í›„ ì´íƒˆë¥  ë¹„êµ'
    },
    {
        'id': 'H2',
        'statement': 'CS ì‘ë‹µ ì‹œê°„ ì¦ê°€ë¡œ ë¶ˆë§Œ â†’ ì´íƒˆ',
        'data_needed': ['cs_response_time', 'churn_flag'],
        'metric': 'CS ì‘ë‹µ ì‹œê°„ê³¼ ì´íƒˆë¥  ìƒê´€ê´€ê³„'
    },
    {
        'id': 'H3',
        'statement': 'ê²½ìŸì‚¬ í”„ë¡œëª¨ì…˜ ì‹œê¸°ì™€ ì´íƒˆ ì¦ê°€',
        'data_needed': ['competitor_promo_dates', 'churn_date'],
        'metric': 'í”„ë¡œëª¨ì…˜ ê¸°ê°„ ì´íƒˆë¥  ë¹„êµ'
    }
]

# 3. ê²€ì¦ ìš°ì„ ìˆœìœ„ (ì˜í–¥ë„ Ã— ê²€ì¦ ìš©ì´ì„±)
priority = ['H1', 'H2', 'H3']  # ë°ì´í„° ê°€ìš©ì„± ê¸°ì¤€
\`\`\`

## ê°€ì„¤ ê²€ì¦ í”„ë ˆì„ì›Œí¬

\`\`\`python
def validate_hypothesis(df, hypothesis):
    """ê°€ì„¤ ê²€ì¦ í”„ë ˆì„ì›Œí¬"""
    results = {
        'hypothesis': hypothesis['statement'],
        'supported': None,
        'evidence': [],
        'confidence': 0
    }

    # 1. ê¸°ìˆ  í†µê³„
    stats = df.groupby('segment').agg({
        'churn': 'mean',
        'satisfaction': 'mean'
    })

    # 2. ìƒê´€ê´€ê³„ ë¶„ì„
    correlation = df['delivery_days'].corr(df['churn'])

    # 3. í†µê³„ ê²€ì •
    from scipy.stats import ttest_ind
    group_a = df[df['delivery_days'] <= 3]['churn']
    group_b = df[df['delivery_days'] > 3]['churn']
    t_stat, p_value = ttest_ind(group_a, group_b)

    # 4. ê²°ë¡ 
    if p_value < 0.05 and correlation > 0.3:
        results['supported'] = True
        results['confidence'] = 0.9

    return results
\`\`\`
`,
      objectives: [
        'ê°€ì„¤ ê¸°ë°˜ ë¶„ì„ì˜ ì¤‘ìš”ì„±ì„ ì´í•´í•œë‹¤',
        'ì¢‹ì€ ê°€ì„¤ì˜ ì¡°ê±´ì„ íŒë‹¨í•  ìˆ˜ ìˆë‹¤',
        'ê°€ì„¤ ê²€ì¦ í”„ë¡œì„¸ìŠ¤ë¥¼ ì ìš©í•  ìˆ˜ ìˆë‹¤'
      ],
      keyPoints: [
        'ëª¨ë¸ë§ ì „ "ì™œ"ë¥¼ ëª…í™•íˆ',
        'ê°€ì„¤: êµ¬ì²´ì , ì¸¡ì • ê°€ëŠ¥, í–‰ë™ ê°€ëŠ¥',
        'ë°ì´í„°ë¡œ ê°€ì„¤ ê²€ì¦',
        'ê²°ë¡ ì€ ë¹„ì¦ˆë‹ˆìŠ¤ í–‰ë™ìœ¼ë¡œ ì—°ê²°'
      ]
    }
  },
  {
    id: 'p2w5d1t2',
    type: 'video',
    title: 'ìƒê´€ê´€ê³„ vs ì¸ê³¼ê´€ê³„',
    duration: 20,
    content: {
      videoUrl: 'https://www.youtube.com/watch?v=placeholder',
      transcript: `# ìƒê´€ê´€ê³„ vs ì¸ê³¼ê´€ê³„

## í•µì‹¬ ì›ì¹™

\`\`\`
ìƒê´€ê´€ê³„ â‰  ì¸ê³¼ê´€ê³„
Correlation â‰  Causation
\`\`\`

## ìœ ëª…í•œ ì˜ˆì‹œ

\`\`\`python
# ì•„ì´ìŠ¤í¬ë¦¼ íŒë§¤ëŸ‰ê³¼ ìµì‚¬ ì‚¬ê³ 
# ìƒê´€ê³„ìˆ˜: 0.95 (ë§¤ìš° ê°•í•œ ì–‘ì˜ ìƒê´€)

# í•˜ì§€ë§Œ ì¸ê³¼ê´€ê³„?
# ì•„ì´ìŠ¤í¬ë¦¼ â†’ ìµì‚¬? âŒ

# ì§„ì§œ ì›ì¸: ì—¬ë¦„ (êµë€ë³€ìˆ˜)
# ì—¬ë¦„ â†’ ìˆ˜ì˜ ì¦ê°€ â†’ ìµì‚¬ ì¦ê°€
# ì—¬ë¦„ â†’ ë”ìœ„ â†’ ì•„ì´ìŠ¤í¬ë¦¼ ì†Œë¹„ ì¦ê°€

confounding_variable = "ì—¬ë¦„/ë”ìš´ ë‚ ì”¨"
\`\`\`

## ì¸ê³¼ê´€ê³„ íŒë‹¨ ê¸°ì¤€

\`\`\`python
# Bradford Hill Criteria (ê°„ëµí™”)

causation_criteria = {
    '1_temporality': 'ì›ì¸ì´ ê²°ê³¼ë³´ë‹¤ ë¨¼ì € ë°œìƒ',
    '2_strength': 'ê°•í•œ ì—°ê´€ì„± (ìƒê´€ê´€ê³„)',
    '3_consistency': 'ì—¬ëŸ¬ ìƒí™©ì—ì„œ ë°˜ë³µ',
    '4_plausibility': 'ìƒë¬¼í•™ì /ë…¼ë¦¬ì  íƒ€ë‹¹ì„±',
    '5_experiment': 'ì‹¤í—˜ìœ¼ë¡œ ê²€ì¦ (Gold Standard)'
}

# ì‹¤ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸
def check_causation(data, cause, effect):
    checks = {
        'temporal': False,    # ì‹œê°„ì  ì„ í›„ê´€ê³„
        'correlation': False, # í†µê³„ì  ì—°ê´€ì„±
        'no_confound': False, # êµë€ë³€ìˆ˜ ë°°ì œ
        'experiment': False   # ì‹¤í—˜ì  ê²€ì¦
    }

    # 1. ì‹œê°„ì  ì„ í›„ê´€ê³„
    if data[cause].first_valid_index() < data[effect].first_valid_index():
        checks['temporal'] = True

    # 2. ìƒê´€ê´€ê³„
    corr = data[cause].corr(data[effect])
    if abs(corr) > 0.3:
        checks['correlation'] = True

    # 3. êµë€ë³€ìˆ˜ (íšŒê·€ ë¶„ì„ìœ¼ë¡œ í†µì œ)
    # ... ë‹¤ë³€ëŸ‰ ë¶„ì„ í•„ìš”

    return checks
\`\`\`

## ì¸ê³¼ê´€ê³„ ê²€ì¦ ë°©ë²•

\`\`\`python
# 1. A/B í…ŒìŠ¤íŠ¸ (ì‹¤í—˜)
# Gold Standard - ë¬´ì‘ìœ„ ë°°ì •ìœ¼ë¡œ êµë€ë³€ìˆ˜ í†µì œ

# 2. íšŒê·€ ë¶„ì„ (í†µì œ)
import statsmodels.api as sm

# êµë€ë³€ìˆ˜ í†µì œ
X = df[['delivery_days', 'age', 'income', 'region']]  # í†µì œ ë³€ìˆ˜ í¬í•¨
y = df['churn']
X = sm.add_constant(X)
model = sm.OLS(y, X).fit()
print(model.summary())

# 3. ì„±í–¥ ì ìˆ˜ ë§¤ì¹­ (Propensity Score Matching)
# ê´€ì°° ë°ì´í„°ì—ì„œ ì¸ê³¼ ì¶”ë¡ 

# 4. ë„êµ¬ ë³€ìˆ˜ (Instrumental Variable)
# êµë€ë³€ìˆ˜ì™€ ë¬´ê´€í•œ ë³€ìˆ˜ í™œìš©
\`\`\`

## ì‹¤ë¬´ì—ì„œì˜ ì£¼ì˜ì‚¬í•­

\`\`\`
âŒ í”í•œ ì‹¤ìˆ˜:
"ê´‘ê³ ë¹„ì™€ ë§¤ì¶œì˜ ìƒê´€ê´€ê³„ê°€ 0.8ì´ë¯€ë¡œ
ê´‘ê³ ë¹„ë¥¼ ëŠ˜ë¦¬ë©´ ë§¤ì¶œì´ ëŠ˜ì–´ë‚  ê²ƒì´ë‹¤"

ğŸ¤” ê³ ë ¤í•´ì•¼ í•  ì :
- ì—­ì¸ê³¼: ë§¤ì¶œ ì¢‹ì„ ë•Œ ê´‘ê³ ë¹„ ì¦ê°€?
- êµë€ë³€ìˆ˜: ê³„ì ˆì„±, í”„ë¡œëª¨ì…˜, ê²½ìŸì‚¬?
- ì‹¤í—˜ í•„ìš”: A/B í…ŒìŠ¤íŠ¸ë¡œ ê²€ì¦

âœ… ì˜¬ë°”ë¥¸ ì ‘ê·¼:
"ê´‘ê³ ë¹„ì™€ ë§¤ì¶œì˜ ìƒê´€ê´€ê³„ 0.8 ê´€ì°°.
ê³„ì ˆì„± í†µì œ í›„ì—ë„ ìœ ì˜ë¯¸.
A/B í…ŒìŠ¤íŠ¸ì—ì„œ ê´‘ê³  ê·¸ë£¹ ë§¤ì¶œ 15% ì¦ê°€.
â†’ ì¸ê³¼ê´€ê³„ ì§€ì§€ë¨"
\`\`\`
`,
      objectives: [
        'ìƒê´€ê´€ê³„ì™€ ì¸ê³¼ê´€ê³„ë¥¼ êµ¬ë¶„í•  ìˆ˜ ìˆë‹¤',
        'êµë€ë³€ìˆ˜ì˜ ì˜í–¥ì„ ì´í•´í•œë‹¤',
        'ì¸ê³¼ê´€ê³„ ê²€ì¦ ë°©ë²•ì„ ì•Œ ìˆ˜ ìˆë‹¤'
      ],
      keyPoints: [
        'ìƒê´€ê´€ê³„ â‰  ì¸ê³¼ê´€ê³„',
        'êµë€ë³€ìˆ˜ í•­ìƒ ê³ ë ¤',
        'A/B í…ŒìŠ¤íŠ¸ = ì¸ê³¼ê´€ê³„ ê²€ì¦ì˜ Gold Standard',
        'ê´€ì°° ë°ì´í„°ì—ì„œëŠ” íšŒê·€/PSMìœ¼ë¡œ í†µì œ'
      ]
    }
  },
  {
    id: 'p2w5d1t3',
    type: 'code',
    title: 'ì‹¤ìŠµ: ê°€ì„¤ ìˆ˜ë¦½ ë° ê²€ì¦',
    duration: 40,
    content: {
      instructions: `# ê°€ì„¤ ê¸°ë°˜ ë¶„ì„ ì‹¤ìŠµ

## ëª©í‘œ
ê³ ê° ì´íƒˆ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°€ì„¤ì„ ìˆ˜ë¦½í•˜ê³  ê²€ì¦í•˜ì„¸ìš”.

## ìš”êµ¬ì‚¬í•­
1. ë¬¸ì œ ì •ì˜: ì´íƒˆë¥  ì¦ê°€ ì›ì¸ íŒŒì•…
2. ê°€ì„¤ 3ê°œ ìˆ˜ë¦½ (êµ¬ì²´ì , ì¸¡ì • ê°€ëŠ¥)
3. ê° ê°€ì„¤ì— ëŒ€í•œ ë°ì´í„° ë¶„ì„
4. í†µê³„ì  ê²€ì¦ (t-test, ìƒê´€ê´€ê³„)
5. ê²°ë¡  ë° ë¹„ì¦ˆë‹ˆìŠ¤ ì•¡ì…˜ ì œì•ˆ
`,
      starterCode: `import pandas as pd
import numpy as np
from scipy import stats
import matplotlib.pyplot as plt
import seaborn as sns

# ìƒ˜í”Œ ë°ì´í„° ìƒì„±
np.random.seed(42)
n = 1000

df = pd.DataFrame({
    'customer_id': range(n),
    'tenure_months': np.random.randint(1, 60, n),
    'monthly_charges': np.random.normal(70, 20, n),
    'support_calls': np.random.poisson(2, n),
    'contract_type': np.random.choice(['Month-to-month', '1 year', '2 year'], n, p=[0.5, 0.3, 0.2]),
    'churn': np.random.binomial(1, 0.2, n)
})

# ì´íƒˆê³¼ ê´€ë ¨ëœ íŒ¨í„´ ì¶”ê°€
df.loc[df['tenure_months'] < 12, 'churn'] = np.random.binomial(1, 0.35, sum(df['tenure_months'] < 12))
df.loc[df['support_calls'] > 4, 'churn'] = np.random.binomial(1, 0.4, sum(df['support_calls'] > 4))

print("=== ë°ì´í„° ê¸°ë³¸ ì •ë³´ ===")
print(f"ì´ ê³ ê° ìˆ˜: {len(df)}")
print(f"ì „ì²´ ì´íƒˆë¥ : {df['churn'].mean():.1%}")

# TODO: ê°€ì„¤ ìˆ˜ë¦½ ë° ê²€ì¦
`,
      solutionCode: `import pandas as pd
import numpy as np
from scipy import stats
import matplotlib.pyplot as plt
import seaborn as sns

np.random.seed(42)
n = 1000

df = pd.DataFrame({
    'customer_id': range(n),
    'tenure_months': np.random.randint(1, 60, n),
    'monthly_charges': np.random.normal(70, 20, n),
    'support_calls': np.random.poisson(2, n),
    'contract_type': np.random.choice(['Month-to-month', '1 year', '2 year'], n, p=[0.5, 0.3, 0.2]),
    'churn': np.random.binomial(1, 0.2, n)
})

df.loc[df['tenure_months'] < 12, 'churn'] = np.random.binomial(1, 0.35, sum(df['tenure_months'] < 12))
df.loc[df['support_calls'] > 4, 'churn'] = np.random.binomial(1, 0.4, sum(df['support_calls'] > 4))

print("=== 1. ë¬¸ì œ ì •ì˜ ===")
print(f"ì „ì²´ ì´íƒˆë¥ : {df['churn'].mean():.1%}")
print("ë¬¸ì œ: ì´íƒˆë¥ ì´ ì˜ˆìƒ(15%)ë³´ë‹¤ ë†’ìŒ. ì›ì¸ íŒŒì•… í•„ìš”")

print("\\n=== 2. ê°€ì„¤ ìˆ˜ë¦½ ===")
hypotheses = [
    {
        'id': 'H1',
        'statement': 'ì‹ ê·œ ê³ ê°(12ê°œì›” ë¯¸ë§Œ)ì˜ ì´íƒˆë¥ ì´ ê¸°ì¡´ ê³ ê°ë³´ë‹¤ ë†’ë‹¤',
        'metric': 'ê·¸ë£¹ë³„ ì´íƒˆë¥  ë¹„êµ'
    },
    {
        'id': 'H2',
        'statement': 'ê³ ê° ì§€ì› ë¬¸ì˜ê°€ ë§ì„ìˆ˜ë¡ ì´íƒˆë¥ ì´ ë†’ë‹¤',
        'metric': 'support_callsì™€ churn ìƒê´€ê´€ê³„'
    },
    {
        'id': 'H3',
        'statement': 'ì›” ë‹¨ìœ„ ê³„ì•½ ê³ ê°ì´ ì¥ê¸° ê³„ì•½ë³´ë‹¤ ì´íƒˆë¥ ì´ ë†’ë‹¤',
        'metric': 'ê³„ì•½ ìœ í˜•ë³„ ì´íƒˆë¥ '
    }
]

for h in hypotheses:
    print(f"[{h['id']}] {h['statement']}")

print("\\n=== 3. ê°€ì„¤ ê²€ì¦ ===")

# H1 ê²€ì¦: ì‹ ê·œ vs ê¸°ì¡´ ê³ ê°
print("\\n--- H1: ì‹ ê·œ ê³ ê° ì´íƒˆë¥  ---")
df['is_new'] = df['tenure_months'] < 12
new_churn = df[df['is_new']]['churn'].mean()
old_churn = df[~df['is_new']]['churn'].mean()
print(f"ì‹ ê·œ ê³ ê° ì´íƒˆë¥ : {new_churn:.1%}")
print(f"ê¸°ì¡´ ê³ ê° ì´íƒˆë¥ : {old_churn:.1%}")

t_stat, p_value = stats.ttest_ind(
    df[df['is_new']]['churn'],
    df[~df['is_new']]['churn']
)
print(f"T-test p-value: {p_value:.4f}")
print(f"â†’ H1 {'ì§€ì§€ë¨' if p_value < 0.05 else 'ê¸°ê°'} (p < 0.05)")

# H2 ê²€ì¦: ê³ ê° ì§€ì› ë¬¸ì˜ì™€ ì´íƒˆ
print("\\n--- H2: ê³ ê° ì§€ì› ë¬¸ì˜ì™€ ì´íƒˆ ---")
correlation = df['support_calls'].corr(df['churn'])
print(f"ìƒê´€ê³„ìˆ˜: {correlation:.3f}")

high_support = df[df['support_calls'] > 4]['churn'].mean()
low_support = df[df['support_calls'] <= 4]['churn'].mean()
print(f"ê³ ë¬¸ì˜(>4) ì´íƒˆë¥ : {high_support:.1%}")
print(f"ì €ë¬¸ì˜(â‰¤4) ì´íƒˆë¥ : {low_support:.1%}")
print(f"â†’ H2 {'ì§€ì§€ë¨' if correlation > 0.1 else 'ê¸°ê°'}")

# H3 ê²€ì¦: ê³„ì•½ ìœ í˜•ë³„ ì´íƒˆë¥ 
print("\\n--- H3: ê³„ì•½ ìœ í˜•ë³„ ì´íƒˆë¥  ---")
contract_churn = df.groupby('contract_type')['churn'].mean()
print(contract_churn)

from scipy.stats import chi2_contingency
contingency = pd.crosstab(df['contract_type'], df['churn'])
chi2, p_value, dof, expected = chi2_contingency(contingency)
print(f"Chi-squared p-value: {p_value:.4f}")
print(f"â†’ H3 {'ì§€ì§€ë¨' if p_value < 0.05 else 'ê¸°ê°'}")

print("\\n=== 4. ê²°ë¡  ë° ì•¡ì…˜ ===")
print("""
ê²€ì¦ ê²°ê³¼:
- H1 ì§€ì§€: ì‹ ê·œ ê³ ê° ì´íƒˆë¥  35% vs ê¸°ì¡´ 20%
- H2 ì§€ì§€: ê³ ë¬¸ì˜ ê³ ê° ì´íƒˆë¥  40% vs ì¼ë°˜ 18%
- H3 ì§€ì§€: ì›” ê³„ì•½ ì´íƒˆë¥  > ì—°ê°„ ê³„ì•½

ë¹„ì¦ˆë‹ˆìŠ¤ ì•¡ì…˜:
1. ì‹ ê·œ ê³ ê° ì˜¨ë³´ë”© í”„ë¡œê·¸ë¨ ê°•í™” (ì²« 90ì¼ ì§‘ì¤‘ ì¼€ì–´)
2. ê³ ê° ì§€ì› í’ˆì§ˆ ê°œì„  (ì‘ë‹µ ì‹œê°„ ë‹¨ì¶•, í•´ê²°ë¥  í–¥ìƒ)
3. ì¥ê¸° ê³„ì•½ ì „í™˜ ì¸ì„¼í‹°ë¸Œ ì œê³µ
""")
`,
      hints: [
        'scipy.stats.ttest_ind()ë¡œ ë‘ ê·¸ë£¹ ë¹„êµ',
        'df.corr()ë¡œ ìƒê´€ê´€ê³„ í™•ì¸',
        'chi2_contingency()ë¡œ ë²”ì£¼í˜• ë³€ìˆ˜ ê´€ê³„ ê²€ì •',
        'p-value < 0.05ë©´ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸'
      ]
    }
  },
  {
    id: 'p2w5d1t4',
    type: 'quiz',
    title: 'Day 1 í€´ì¦ˆ: ê°€ì„¤ ê¸°ë°˜ ë¶„ì„',
    duration: 10,
    content: {
      questions: [
        {
          question: 'ì¢‹ì€ ê°€ì„¤ì˜ ì¡°ê±´ì´ ì•„ë‹Œ ê²ƒì€?',
          options: ['êµ¬ì²´ì ì´ë‹¤', 'ì¸¡ì • ê°€ëŠ¥í•˜ë‹¤', 'í–‰ë™ ê°€ëŠ¥í•˜ë‹¤', 'ë³µì¡í•˜ë‹¤'],
          answer: 3
        },
        {
          question: 'ìƒê´€ê´€ê³„ê°€ 0.9ì¼ ë•Œ ë°˜ë“œì‹œ ì„±ë¦½í•˜ëŠ” ê²ƒì€?',
          options: ['ì¸ê³¼ê´€ê³„ê°€ ìˆë‹¤', 'ë‘ ë³€ìˆ˜ê°€ í•¨ê»˜ ë³€í•œë‹¤', 'ì›ì¸ê³¼ ê²°ê³¼ê°€ ëª…í™•í•˜ë‹¤', 'A/B í…ŒìŠ¤íŠ¸ê°€ í•„ìš”ì—†ë‹¤'],
          answer: 1
        },
        {
          question: 'ì¸ê³¼ê´€ê³„ ê²€ì¦ì˜ Gold StandardëŠ”?',
          options: ['ìƒê´€ê´€ê³„ ë¶„ì„', 'íšŒê·€ ë¶„ì„', 'A/B í…ŒìŠ¤íŠ¸', 'ê¸°ìˆ  í†µê³„'],
          answer: 2
        },
        {
          question: 'êµë€ë³€ìˆ˜(Confounding Variable)ë€?',
          options: ['ì¢…ì† ë³€ìˆ˜', 'ì›ì¸ê³¼ ê²°ê³¼ ëª¨ë‘ì— ì˜í–¥ì„ ì£¼ëŠ” ì œ3ì˜ ë³€ìˆ˜', 'ì¸¡ì • ì˜¤ë¥˜', 'ì´ìƒì¹˜'],
          answer: 1
        }
      ]
    }
  }
]
