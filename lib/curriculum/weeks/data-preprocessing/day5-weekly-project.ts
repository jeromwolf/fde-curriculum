// Week 10 Day 5: Weekly Project - ë°ì´í„° ì •ì œ íŒŒì´í”„ë¼ì¸
import type { Task } from '../../types'

export const day5Tasks: Task[] = [
  {
    id: 'p2w2d5t1',
    type: 'reading',
    title: 'Weekly Project ê°€ì´ë“œ: ë°ì´í„° ì •ì œ íŒŒì´í”„ë¼ì¸',
    duration: 15,
    content: {
      markdown: `# Weekly Project: ë°ì´í„° ì •ì œ íŒŒì´í”„ë¼ì¸

## í”„ë¡œì íŠ¸ ê°œìš”

ì´ë²ˆ ì£¼ì— ë°°ìš´ ë°ì´í„° í’ˆì§ˆ, ê²°ì¸¡ì¹˜, ì´ìƒì¹˜, ë³€í™˜ ê¸°ë²•ì„ ì¢…í•©í•˜ì—¬
**ì¬ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„° ì •ì œ íŒŒì´í”„ë¼ì¸**ì„ êµ¬ì¶•í•©ë‹ˆë‹¤.

## í•™ìŠµ ëª©í‘œ

- ë°ì´í„° í’ˆì§ˆì„ ì²´ê³„ì ìœ¼ë¡œ í‰ê°€í•  ìˆ˜ ìˆë‹¤
- ê²°ì¸¡ì¹˜ì™€ ì´ìƒì¹˜ë¥¼ ì ì ˆíˆ ì²˜ë¦¬í•  ìˆ˜ ìˆë‹¤
- sklearn Pipelineìœ¼ë¡œ ì „ì²˜ë¦¬ë¥¼ ìë™í™”í•  ìˆ˜ ìˆë‹¤
- ì²˜ë¦¬ ê²°ì •ì˜ ê·¼ê±°ë¥¼ ë¬¸ì„œí™”í•  ìˆ˜ ìˆë‹¤

## ë°ì´í„°ì…‹ ì„ íƒ

ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì„¸ìš”:

### ì˜µì…˜ 1: Spaceship Titanic (Kaggle)
- URL: https://www.kaggle.com/competitions/spaceship-titanic
- íŠ¹ì§•: ë‹¤ì–‘í•œ ê²°ì¸¡ íŒ¨í„´, ë²”ì£¼í˜•/ìˆ˜ì¹˜í˜• í˜¼í•©

### ì˜µì…˜ 2: Housing Prices (Kaggle)
- URL: https://www.kaggle.com/c/house-prices-advanced-regression-techniques
- íŠ¹ì§•: ë§ì€ ê²°ì¸¡ì¹˜, ê³ ì¹´ë””ë„ë¦¬í‹° ë²”ì£¼í˜•

### ì˜µì…˜ 3: ìì²´ ë°ì´í„°
- ì‹¤ë¬´ ë°ì´í„° ë˜ëŠ” ìˆ˜ì§‘í•œ ë°ì´í„°
- ìµœì†Œ 1000í–‰, 10ê°œ ì´ìƒ ì»¬ëŸ¼ ê¶Œì¥

## ìš”êµ¬ì‚¬í•­

### 1. ë°ì´í„° í’ˆì§ˆ í‰ê°€ (20%)

\\\`\\\`\\\`python
# 6ì°¨ì› í’ˆì§ˆ í‰ê°€
1. ì™„ì „ì„±: ê° ì»¬ëŸ¼ë³„ ê²°ì¸¡ë¥ 
2. ì •í™•ì„±: ë²”ìœ„ ê²€ì¦, ë¹„í˜„ì‹¤ì  ê°’ ì‹ë³„
3. ì¼ê´€ì„±: ì»¬ëŸ¼ ê°„ ëª¨ìˆœ í™•ì¸
4. ìœ íš¨ì„±: í˜•ì‹ ê²€ì¦ (ì´ë©”ì¼, ë‚ ì§œ ë“±)
5. ìœ ì¼ì„±: ì¤‘ë³µ ë ˆì½”ë“œ íƒì§€
6. ì ì‹œì„±: ë°ì´í„° ì‹ ì„ ë„ (í•´ë‹¹ ì‹œ)
\\\`\\\`\\\`

### 2. ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (25%)

\\\`\\\`\\\`python
# ê²°ì¸¡ ë©”ì»¤ë‹ˆì¦˜ ì§„ë‹¨
- MCAR vs MAR íŒë‹¨
- ê° ì»¬ëŸ¼ë³„ ì²˜ë¦¬ ì „ëµ ì„ íƒ
- ì²˜ë¦¬ ê·¼ê±° ë¬¸ì„œí™”

# ì²˜ë¦¬ ë°©ë²• ì˜ˆì‹œ
- ìˆ˜ì¹˜í˜•: ì¤‘ì•™ê°’, KNN, ê·¸ë£¹ë³„ ëŒ€ì²´
- ë²”ì£¼í˜•: ìµœë¹ˆê°’, Unknown
- ë†’ì€ ê²°ì¸¡ë¥ : ì»¬ëŸ¼ ì‚­ì œ ê³ ë ¤
\\\`\\\`\\\`

### 3. ì´ìƒì¹˜ ì²˜ë¦¬ (20%)

\\\`\\\`\\\`python
# ì´ìƒì¹˜ íƒì§€
- IQR ë°©ë²•
- Z-score (í•´ë‹¹ ì‹œ)
- ì‹œê°í™”ë¡œ í™•ì¸

# ì²˜ë¦¬ ì „ëµ
- ëª…í™•í•œ ì˜¤ë¥˜: ì œê±° ë˜ëŠ” ëŒ€ì²´
- ê·¹ë‹¨ê°’: Winsorizing, í´ë¦¬í•‘, ë¡œê·¸ ë³€í™˜
- ì²˜ë¦¬ ê·¼ê±° ë¬¸ì„œí™”
\\\`\\\`\\\`

### 4. ë³€í™˜ & ì¸ì½”ë”© (20%)

\\\`\\\`\\\`python
# ìˆ˜ì¹˜í˜• ë³€í™˜
- ìŠ¤ì¼€ì¼ë§ ë°©ë²• ì„ íƒ ë° ì ìš©
- ë¶„í¬ ë³€í™˜ (í•„ìš”ì‹œ)

# ë²”ì£¼í˜• ì¸ì½”ë”©
- ì¹´ë””ë„ë¦¬í‹°ì— ë”°ë¥¸ ë°©ë²• ì„ íƒ
- One-Hot vs Target vs Binary
\\\`\\\`\\\`

### 5. Pipeline êµ¬ì¶• (15%)

\\\`\\\`\\\`python
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer

# ColumnTransformerë¡œ ìˆ˜ì¹˜í˜•/ë²”ì£¼í˜• ë¶„ë¦¬ ì²˜ë¦¬
# ì „ì²´ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•
# ìƒˆ ë°ì´í„°ì— ì ìš© ê°€ëŠ¥í•œ í˜•íƒœ
\\\`\\\`\\\`

## ì‚°ì¶œë¬¼

1. **Jupyter Notebook** (ë˜ëŠ” Python ìŠ¤í¬ë¦½íŠ¸)
   - ì½”ë“œ + ë§ˆí¬ë‹¤ìš´ ì„¤ëª…
   - ì‹œê°í™” í¬í•¨

2. **ì²˜ë¦¬ ì „í›„ ë¹„êµ**
   - ê²°ì¸¡ë¥  ë³€í™”
   - ë¶„í¬ ë³€í™”
   - ì´ìƒì¹˜ ìˆ˜ ë³€í™”

3. **ê²°ì • ê·¼ê±° ë¬¸ì„œ**
   - ê° ì²˜ë¦¬ ê²°ì •ì˜ ì´ìœ 
   - ê³ ë ¤í•œ ëŒ€ì•ˆê³¼ ì„ íƒ ì´ìœ 

## í‰ê°€ ê¸°ì¤€

| í•­ëª© | ë°°ì  | ì„¸ë¶€ ê¸°ì¤€ |
|------|------|----------|
| í’ˆì§ˆ í‰ê°€ | 20% | 6ì°¨ì› ëª¨ë‘ í‰ê°€, ì‹œê°í™” |
| ê²°ì¸¡ì¹˜ ì²˜ë¦¬ | 25% | ë©”ì»¤ë‹ˆì¦˜ ì§„ë‹¨, ì ì ˆí•œ ë°©ë²• |
| ì´ìƒì¹˜ ì²˜ë¦¬ | 20% | íƒì§€ + ì²˜ë¦¬ + ê·¼ê±° |
| ë³€í™˜/ì¸ì½”ë”© | 20% | ìƒí™©ì— ë§ëŠ” ì„ íƒ |
| Pipeline | 15% | ì¬ì‚¬ìš© ê°€ëŠ¥, ëˆ„ìˆ˜ ì—†ìŒ |

## ì¶”ì²œ êµ¬ì¡°

\\\`\\\`\\\`markdown
# ë°ì´í„° ì •ì œ íŒŒì´í”„ë¼ì¸ í”„ë¡œì íŠ¸

## 1. ë°ì´í„° ë¡œë“œ ë° íƒìƒ‰
- ê¸°ë³¸ ì •ë³´ (shape, dtypes)
- ìƒ˜í”Œ í™•ì¸

## 2. ë°ì´í„° í’ˆì§ˆ í‰ê°€
- 6ì°¨ì› í‰ê°€ ê²°ê³¼
- ì£¼ìš” ì´ìŠˆ ì‹ë³„

## 3. ê²°ì¸¡ì¹˜ ì²˜ë¦¬
- ê²°ì¸¡ íŒ¨í„´ ë¶„ì„
- ì²˜ë¦¬ ì „ëµ ë° ì ìš©
- ì²˜ë¦¬ ì „í›„ ë¹„êµ

## 4. ì´ìƒì¹˜ ì²˜ë¦¬
- íƒì§€ ê²°ê³¼
- ì²˜ë¦¬ ì „ëµ ë° ì ìš©
- ì²˜ë¦¬ ì „í›„ ë¹„êµ

## 5. ë³€í™˜ & ì¸ì½”ë”©
- ìˆ˜ì¹˜í˜• ìŠ¤ì¼€ì¼ë§
- ë²”ì£¼í˜• ì¸ì½”ë”©
- ìµœì¢… í”¼ì²˜ í™•ì¸

## 6. Pipeline êµ¬ì¶•
- sklearn Pipeline ì½”ë“œ
- ìƒˆ ë°ì´í„° ì ìš© ì˜ˆì‹œ

## 7. ê²°ë¡  ë° ê¶Œê³ ì‚¬í•­
- ì£¼ìš” ë°œê²¬
- í–¥í›„ ê°œì„ ì 
\\\`\\\`\\\`
`,
      externalLinks: [
        { title: 'Spaceship Titanic (Kaggle)', url: 'https://www.kaggle.com/competitions/spaceship-titanic' },
        { title: 'Housing Prices (Kaggle)', url: 'https://www.kaggle.com/c/house-prices-advanced-regression-techniques' },
        { title: 'sklearn Pipeline Guide', url: 'https://scikit-learn.org/stable/modules/compose.html' }
      ]
    }
  },
  {
    id: 'p2w2d5t2',
    type: 'code',
    title: 'í”„ë¡œì íŠ¸ í…œí”Œë¦¿',
    duration: 90,
    content: {
      instructions: `# ë°ì´í„° ì •ì œ íŒŒì´í”„ë¼ì¸ í”„ë¡œì íŠ¸

ì•„ë˜ í…œí”Œë¦¿ì„ ì™„ì„±í•˜ì—¬ ë°ì´í„° ì •ì œ íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•˜ì„¸ìš”.

## ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] ë°ì´í„° ë¡œë“œ ë° ê¸°ë³¸ íƒìƒ‰
- [ ] 6ì°¨ì› ë°ì´í„° í’ˆì§ˆ í‰ê°€
- [ ] ê²°ì¸¡ì¹˜ ë©”ì»¤ë‹ˆì¦˜ ì§„ë‹¨ ë° ì²˜ë¦¬
- [ ] ì´ìƒì¹˜ íƒì§€ ë° ì²˜ë¦¬
- [ ] ìˆ˜ì¹˜í˜• ìŠ¤ì¼€ì¼ë§
- [ ] ë²”ì£¼í˜• ì¸ì½”ë”©
- [ ] sklearn Pipeline êµ¬ì¶•
- [ ] ì²˜ë¦¬ ì „í›„ ë¹„êµ ì‹œê°í™”
- [ ] ê²°ì • ê·¼ê±° ë¬¸ì„œí™”
`,
      starterCode: `"""
ë°ì´í„° ì •ì œ íŒŒì´í”„ë¼ì¸ í”„ë¡œì íŠ¸
Week 10 Weekly Project
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, RobustScaler, OneHotEncoder
from sklearn.impute import SimpleImputer, KNNImputer
from sklearn.ensemble import RandomForestClassifier

# ì‹œê°í™” ì„¤ì •
plt.style.use('seaborn-v0_8-whitegrid')
plt.rcParams['figure.figsize'] = (12, 6)

# =============================================================================
# 1. ë°ì´í„° ë¡œë“œ ë° íƒìƒ‰
# =============================================================================
print("=" * 60)
print("1. ë°ì´í„° ë¡œë“œ ë° íƒìƒ‰")
print("=" * 60)

# TODO: ë°ì´í„° ë¡œë“œ
# df = pd.read_csv('your_data.csv')

# ìƒ˜í”Œ ë°ì´í„° ìƒì„± (ì‹¤ì œ ë°ì´í„°ë¡œ êµì²´)
np.random.seed(42)
n = 1000

df = pd.DataFrame({
    'PassengerId': range(1, n + 1),
    'Age': np.random.randint(1, 80, n).astype(float),
    'Fare': np.random.exponential(50, n),
    'Cabin': np.random.choice(['A', 'B', 'C', 'D', None], n, p=[0.1, 0.1, 0.1, 0.1, 0.6]),
    'Embarked': np.random.choice(['S', 'C', 'Q', None], n, p=[0.6, 0.2, 0.15, 0.05]),
    'Pclass': np.random.choice([1, 2, 3], n),
    'VIP': np.random.choice([True, False], n),
    'Survived': np.random.randint(0, 2, n)
})

# ì´ìƒì¹˜ ë° ê²°ì¸¡ì¹˜ ì¶”ê°€
df.loc[np.random.choice(n, 100, replace=False), 'Age'] = np.nan
df.loc[np.random.choice(n, 50, replace=False), 'Fare'] = np.nan
df.loc[10:15, 'Age'] = [-5, 150, 200, 0, 999, 180]
df.loc[20:25, 'Fare'] = [1000, 2000, 5000, -100, 3000, 10000]

print(f"Shape: {df.shape}")
print(f"\\nDtypes:\\n{df.dtypes}")
print(f"\\nì²˜ìŒ 5í–‰:\\n{df.head()}")

# =============================================================================
# 2. ë°ì´í„° í’ˆì§ˆ í‰ê°€ (6ì°¨ì›)
# =============================================================================
print("\\n" + "=" * 60)
print("2. ë°ì´í„° í’ˆì§ˆ í‰ê°€")
print("=" * 60)

def evaluate_data_quality(df):
    """6ì°¨ì› ë°ì´í„° í’ˆì§ˆ í‰ê°€"""
    print("\\n--- 2.1 ì™„ì „ì„± (Completeness) ---")
    missing = df.isnull().sum()
    missing_pct = (missing / len(df) * 100).round(2)
    print(pd.DataFrame({'missing': missing, 'pct': missing_pct}))

    print("\\n--- 2.2 ì •í™•ì„± (Accuracy) ---")
    # TODO: ë²”ìœ„ ê²€ì¦ êµ¬í˜„
    pass

    print("\\n--- 2.3 ìœ íš¨ì„± (Validity) ---")
    # TODO: í˜•ì‹ ê²€ì¦ êµ¬í˜„
    pass

    print("\\n--- 2.4 ìœ ì¼ì„± (Uniqueness) ---")
    duplicates = df.duplicated().sum()
    print(f"ì¤‘ë³µ í–‰: {duplicates}")

# TODO: í’ˆì§ˆ í‰ê°€ í•¨ìˆ˜ ì™„ì„± ë° ì‹¤í–‰
evaluate_data_quality(df)

# =============================================================================
# 3. ê²°ì¸¡ì¹˜ ì²˜ë¦¬
# =============================================================================
print("\\n" + "=" * 60)
print("3. ê²°ì¸¡ì¹˜ ì²˜ë¦¬")
print("=" * 60)

def handle_missing_values(df):
    """ê²°ì¸¡ì¹˜ ì²˜ë¦¬"""
    df_clean = df.copy()

    # TODO: ê²°ì¸¡ ë©”ì»¤ë‹ˆì¦˜ ì§„ë‹¨

    # TODO: ê° ì»¬ëŸ¼ë³„ ì²˜ë¦¬ ì „ëµ ì ìš©

    return df_clean

# TODO: ê²°ì¸¡ì¹˜ ì²˜ë¦¬ í•¨ìˆ˜ ì™„ì„± ë° ì‹¤í–‰
# df_no_missing = handle_missing_values(df)

# =============================================================================
# 4. ì´ìƒì¹˜ ì²˜ë¦¬
# =============================================================================
print("\\n" + "=" * 60)
print("4. ì´ìƒì¹˜ ì²˜ë¦¬")
print("=" * 60)

def handle_outliers(df):
    """ì´ìƒì¹˜ ì²˜ë¦¬"""
    df_clean = df.copy()

    # TODO: IQR ê¸°ë°˜ ì´ìƒì¹˜ íƒì§€

    # TODO: ì²˜ë¦¬ ì „ëµ ì ìš©

    return df_clean

# TODO: ì´ìƒì¹˜ ì²˜ë¦¬ í•¨ìˆ˜ ì™„ì„± ë° ì‹¤í–‰
# df_no_outliers = handle_outliers(df_no_missing)

# =============================================================================
# 5. sklearn Pipeline êµ¬ì¶•
# =============================================================================
print("\\n" + "=" * 60)
print("5. sklearn Pipeline êµ¬ì¶•")
print("=" * 60)

# ì»¬ëŸ¼ ì •ì˜
numerical_cols = ['Age', 'Fare']
categorical_cols = ['Cabin', 'Embarked', 'Pclass']

# TODO: ìˆ˜ì¹˜í˜• íŒŒì´í”„ë¼ì¸

# TODO: ë²”ì£¼í˜• íŒŒì´í”„ë¼ì¸

# TODO: ColumnTransformer

# TODO: ì „ì²´ Pipeline (ì „ì²˜ë¦¬ + ëª¨ë¸)

# =============================================================================
# 6. ê²°ê³¼ ê²€ì¦
# =============================================================================
print("\\n" + "=" * 60)
print("6. ê²°ê³¼ ê²€ì¦")
print("=" * 60)

# TODO: ì²˜ë¦¬ ì „í›„ ë¹„êµ

# TODO: êµì°¨ ê²€ì¦

# =============================================================================
# 7. ê²°ë¡ 
# =============================================================================
print("\\n" + "=" * 60)
print("7. ê²°ë¡  ë° ê¶Œê³ ì‚¬í•­")
print("=" * 60)

# TODO: ì£¼ìš” ë°œê²¬ ë° ê¶Œê³ ì‚¬í•­ ì •ë¦¬
`,
      solutionCode: `"""
ë°ì´í„° ì •ì œ íŒŒì´í”„ë¼ì¸ í”„ë¡œì íŠ¸ - ì™„ì„±ë³¸
Week 10 Weekly Project
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from scipy.stats import mstats
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, RobustScaler, OneHotEncoder
from sklearn.impute import SimpleImputer, KNNImputer
from sklearn.ensemble import RandomForestClassifier

# ì‹œê°í™” ì„¤ì •
plt.style.use('seaborn-v0_8-whitegrid')
plt.rcParams['figure.figsize'] = (12, 6)

# =============================================================================
# 1. ë°ì´í„° ë¡œë“œ ë° íƒìƒ‰
# =============================================================================
print("=" * 60)
print("1. ë°ì´í„° ë¡œë“œ ë° íƒìƒ‰")
print("=" * 60)

np.random.seed(42)
n = 1000

df = pd.DataFrame({
    'PassengerId': range(1, n + 1),
    'Age': np.random.randint(1, 80, n).astype(float),
    'Fare': np.random.exponential(50, n),
    'Cabin': np.random.choice(['A', 'B', 'C', 'D', None], n, p=[0.1, 0.1, 0.1, 0.1, 0.6]),
    'Embarked': np.random.choice(['S', 'C', 'Q', None], n, p=[0.6, 0.2, 0.15, 0.05]),
    'Pclass': np.random.choice([1, 2, 3], n),
    'VIP': np.random.choice([True, False], n),
    'Survived': np.random.randint(0, 2, n)
})

df.loc[np.random.choice(n, 100, replace=False), 'Age'] = np.nan
df.loc[np.random.choice(n, 50, replace=False), 'Fare'] = np.nan
df.loc[10:15, 'Age'] = [-5, 150, 200, 0, 999, 180]
df.loc[20:25, 'Fare'] = [1000, 2000, 5000, -100, 3000, 10000]

print(f"Shape: {df.shape}")
print(f"\\nì›ë³¸ ë°ì´í„° í†µê³„:\\n{df.describe()}")

# =============================================================================
# 2. ë°ì´í„° í’ˆì§ˆ í‰ê°€ (6ì°¨ì›)
# =============================================================================
print("\\n" + "=" * 60)
print("2. ë°ì´í„° í’ˆì§ˆ í‰ê°€")
print("=" * 60)

def evaluate_data_quality(df):
    """6ì°¨ì› ë°ì´í„° í’ˆì§ˆ í‰ê°€"""
    scores = {}

    # 2.1 ì™„ì „ì„±
    print("\\n--- 2.1 ì™„ì „ì„± (Completeness) ---")
    missing = df.isnull().sum()
    missing_pct = (missing / len(df) * 100).round(2)
    completeness = 100 - missing_pct.mean()
    scores['completeness'] = completeness
    print(f"í‰ê·  ì™„ì „ì„± ì ìˆ˜: {completeness:.1f}%")
    print(f"ê²°ì¸¡ë¥  ë†’ì€ ì»¬ëŸ¼: {list(missing_pct[missing_pct > 10].index)}")

    # 2.2 ì •í™•ì„±
    print("\\n--- 2.2 ì •í™•ì„± (Accuracy) ---")
    issues = []
    if 'Age' in df.columns:
        invalid_age = df[(df['Age'] < 0) | (df['Age'] > 120)]['Age'].count()
        if invalid_age > 0:
            issues.append(f"Age: {invalid_age}ê°œ ìœ íš¨í•˜ì§€ ì•Šì€ ê°’")
    if 'Fare' in df.columns:
        negative_fare = (df['Fare'] < 0).sum()
        if negative_fare > 0:
            issues.append(f"Fare: {negative_fare}ê°œ ìŒìˆ˜ ê°’")
    accuracy = 100 if not issues else 90
    scores['accuracy'] = accuracy
    print(f"ì •í™•ì„± ì´ìŠˆ: {issues if issues else 'ì—†ìŒ'}")

    # 2.3 ìœ ì¼ì„±
    print("\\n--- 2.3 ìœ ì¼ì„± (Uniqueness) ---")
    duplicates = df.duplicated().sum()
    uniqueness = (1 - duplicates / len(df)) * 100
    scores['uniqueness'] = uniqueness
    print(f"ì¤‘ë³µ í–‰: {duplicates}ê°œ, ìœ ì¼ì„±: {uniqueness:.1f}%")

    # ì¢…í•© ì ìˆ˜
    overall = np.mean(list(scores.values()))
    print(f"\\n>>> ì¢…í•© í’ˆì§ˆ ì ìˆ˜: {overall:.1f}/100")

    return scores

quality_scores = evaluate_data_quality(df)

# =============================================================================
# 3. ê²°ì¸¡ì¹˜ ì²˜ë¦¬
# =============================================================================
print("\\n" + "=" * 60)
print("3. ê²°ì¸¡ì¹˜ ì²˜ë¦¬")
print("=" * 60)

def handle_missing_values(df):
    """ê²°ì¸¡ì¹˜ ì²˜ë¦¬"""
    df_clean = df.copy()

    print("\\nì²˜ë¦¬ ì „ ê²°ì¸¡ì¹˜:")
    print(df_clean.isnull().sum())

    # Age: ì¤‘ì•™ê°’ ëŒ€ì²´ (MCARë¡œ ê°€ì •)
    if 'Age' in df_clean.columns:
        median_age = df_clean['Age'].median()
        df_clean['Age'] = df_clean['Age'].fillna(median_age)
        print(f"\\n[Age] ì¤‘ì•™ê°’ {median_age:.1f}ìœ¼ë¡œ ëŒ€ì²´")

    # Fare: ê·¸ë£¹ë³„ ì¤‘ì•™ê°’ (Pclassì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
    if 'Fare' in df_clean.columns and 'Pclass' in df_clean.columns:
        df_clean['Fare'] = df_clean.groupby('Pclass')['Fare'].transform(
            lambda x: x.fillna(x.median())
        )
        print("[Fare] Pclassë³„ ì¤‘ì•™ê°’ìœ¼ë¡œ ëŒ€ì²´")

    # Cabin: 'Unknown'ìœ¼ë¡œ ëŒ€ì²´ (ë†’ì€ ê²°ì¸¡ë¥ )
    if 'Cabin' in df_clean.columns:
        df_clean['Cabin'] = df_clean['Cabin'].fillna('Unknown')
        print("[Cabin] 'Unknown'ìœ¼ë¡œ ëŒ€ì²´")

    # Embarked: ìµœë¹ˆê°’ ëŒ€ì²´
    if 'Embarked' in df_clean.columns:
        mode_embarked = df_clean['Embarked'].mode()[0]
        df_clean['Embarked'] = df_clean['Embarked'].fillna(mode_embarked)
        print(f"[Embarked] ìµœë¹ˆê°’ '{mode_embarked}'ìœ¼ë¡œ ëŒ€ì²´")

    print("\\nì²˜ë¦¬ í›„ ê²°ì¸¡ì¹˜:")
    print(df_clean.isnull().sum())

    return df_clean

df_no_missing = handle_missing_values(df)

# =============================================================================
# 4. ì´ìƒì¹˜ ì²˜ë¦¬
# =============================================================================
print("\\n" + "=" * 60)
print("4. ì´ìƒì¹˜ ì²˜ë¦¬")
print("=" * 60)

def handle_outliers(df):
    """ì´ìƒì¹˜ ì²˜ë¦¬"""
    df_clean = df.copy()

    # Age: ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜ í´ë¦¬í•‘ (0-100)
    if 'Age' in df_clean.columns:
        before = len(df_clean[(df_clean['Age'] < 0) | (df_clean['Age'] > 100)])
        df_clean['Age'] = df_clean['Age'].clip(0, 100)
        print(f"[Age] {before}ê°œ ì´ìƒì¹˜ í´ë¦¬í•‘ (0-100)")

    # Fare: Winsorizing (ìƒí•˜ìœ„ 1%)
    if 'Fare' in df_clean.columns:
        Q1, Q3 = df_clean['Fare'].quantile([0.25, 0.75])
        IQR = Q3 - Q1
        before = len(df_clean[(df_clean['Fare'] < Q1 - 1.5*IQR) |
                              (df_clean['Fare'] > Q3 + 1.5*IQR)])
        df_clean['Fare'] = mstats.winsorize(df_clean['Fare'], limits=[0.01, 0.01])
        print(f"[Fare] {before}ê°œ ì´ìƒì¹˜ Winsorizing ì²˜ë¦¬")

    return df_clean

df_clean = handle_outliers(df_no_missing)

# =============================================================================
# 5. sklearn Pipeline êµ¬ì¶•
# =============================================================================
print("\\n" + "=" * 60)
print("5. sklearn Pipeline êµ¬ì¶•")
print("=" * 60)

# í”¼ì²˜ì™€ íƒ€ê²Ÿ ë¶„ë¦¬
X = df_clean.drop(['PassengerId', 'Survived'], axis=1)
y = df_clean['Survived']

# ì»¬ëŸ¼ ì •ì˜
numerical_cols = ['Age', 'Fare']
categorical_cols = ['Cabin', 'Embarked', 'Pclass', 'VIP']

# ìˆ˜ì¹˜í˜• íŒŒì´í”„ë¼ì¸
numerical_pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', RobustScaler())
])

# ë²”ì£¼í˜• íŒŒì´í”„ë¼ì¸
categorical_pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))
])

# ColumnTransformer
preprocessor = ColumnTransformer([
    ('numerical', numerical_pipeline, numerical_cols),
    ('categorical', categorical_pipeline, categorical_cols)
])

# ì „ì²´ Pipeline
full_pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))
])

print("Pipeline êµ¬ì¡°:")
print(full_pipeline)

# =============================================================================
# 6. ê²°ê³¼ ê²€ì¦
# =============================================================================
print("\\n" + "=" * 60)
print("6. ê²°ê³¼ ê²€ì¦")
print("=" * 60)

# ì²˜ë¦¬ ì „í›„ ë¹„êµ
print("\\n--- ì²˜ë¦¬ ì „í›„ ë¹„êµ ---")
print(f"\\n[Age]")
print(f"  ì›ë³¸ - Mean: {df['Age'].mean():.2f}, Std: {df['Age'].std():.2f}")
print(f"  ì²˜ë¦¬ - Mean: {df_clean['Age'].mean():.2f}, Std: {df_clean['Age'].std():.2f}")

print(f"\\n[Fare]")
print(f"  ì›ë³¸ - Mean: {df['Fare'].mean():.2f}, Std: {df['Fare'].std():.2f}")
print(f"  ì²˜ë¦¬ - Mean: {df_clean['Fare'].mean():.2f}, Std: {df_clean['Fare'].std():.2f}")

# êµì°¨ ê²€ì¦
print("\\n--- êµì°¨ ê²€ì¦ ---")
cv_scores = cross_val_score(full_pipeline, X, y, cv=5, scoring='accuracy')
print(f"CV Accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})")

# =============================================================================
# 7. ê²°ë¡ 
# =============================================================================
print("\\n" + "=" * 60)
print("7. ê²°ë¡  ë° ê¶Œê³ ì‚¬í•­")
print("=" * 60)

print("""
## ì£¼ìš” ë°œê²¬

1. **ê²°ì¸¡ì¹˜**
   - Cabin: 60% ê²°ì¸¡ â†’ 'Unknown' ë²”ì£¼ë¡œ ì²˜ë¦¬
   - Age, Fare: 10% ë¯¸ë§Œ â†’ ì¤‘ì•™ê°’/ê·¸ë£¹ë³„ ëŒ€ì²´

2. **ì´ìƒì¹˜**
   - Age: ë¹„í˜„ì‹¤ì  ê°’ (ìŒìˆ˜, 120+ ì„¸) â†’ í´ë¦¬í•‘
   - Fare: ê·¹ë‹¨ì  ê³ ì•¡ ìš”ê¸ˆ â†’ Winsorizing

3. **ì¸ì½”ë”©**
   - Pclass: ìˆœì„œí˜•ì´ì§€ë§Œ One-Hotìœ¼ë¡œ ì²˜ë¦¬ (í´ë˜ìŠ¤ ê°„ ë™ë“± ì·¨ê¸‰)
   - Cabin: ê³ ì¹´ë””ë„ë¦¬í‹°ì§€ë§Œ Unknown ì²˜ë¦¬ë¡œ ë‹¨ìˆœí™”

## ê¶Œê³ ì‚¬í•­

1. ë” ì •êµí•œ Cabin ì²˜ë¦¬ (ì²« ê¸€ìë§Œ ì¶”ì¶œ ë“±)
2. Age ê²°ì¸¡ ì²˜ë¦¬ ì‹œ ì„±ë³„/í´ë˜ìŠ¤ë³„ ê·¸ë£¹ ëŒ€ì²´ ê³ ë ¤
3. Feature Engineering ì¶”ê°€ (ê°€ì¡± í¬ê¸°, ìš”ê¸ˆ/ì¸ ë“±)
""")

print("\\ní”„ë¡œì íŠ¸ ì™„ë£Œ!")
`,
      hints: [
        'ë°ì´í„° í’ˆì§ˆ í‰ê°€ëŠ” ì²˜ë¦¬ ì „ì— ìˆ˜í–‰í•˜ê³  ë¬¸ì„œí™”í•©ë‹ˆë‹¤',
        'ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì „ì— ë©”ì»¤ë‹ˆì¦˜(MCAR/MAR/MNAR)ì„ ì§„ë‹¨í•©ë‹ˆë‹¤',
        'sklearn Pipelineì„ ì‚¬ìš©í•˜ë©´ ì „ì²˜ë¦¬ì™€ ëª¨ë¸ë§ì„ í•œ ë²ˆì— ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤',
        'ì²˜ë¦¬ ì „í›„ ë¶„í¬ ë¹„êµë¡œ í¸í–¥ ì—¬ë¶€ë¥¼ í™•ì¸í•©ë‹ˆë‹¤'
      ]
    }
  },
  {
    id: 'p2w2d5t3',
    type: 'quiz',
    title: 'Week 10 ì¢…í•© í€´ì¦ˆ',
    duration: 20,
    content: {
      questions: [
        {
          question: 'ë°ì´í„° í’ˆì§ˆ 6ì°¨ì›ì— í¬í•¨ë˜ì§€ ì•ŠëŠ” ê²ƒì€?',
          options: ['ì™„ì „ì„± (Completeness)', 'ì •í™•ì„± (Accuracy)', 'ë³µì¡ì„± (Complexity)', 'ì¼ê´€ì„± (Consistency)'],
          answer: 2,
          explanation: 'ë°ì´í„° í’ˆì§ˆ 6ì°¨ì›ì€ ì™„ì „ì„±, ì •í™•ì„±, ì¼ê´€ì„±, ì ì‹œì„±, ìœ íš¨ì„±, ìœ ì¼ì„±ì…ë‹ˆë‹¤. ë³µì¡ì„±ì€ í’ˆì§ˆ ì°¨ì›ì´ ì•„ë‹ˆë¼ ë°ì´í„° êµ¬ì¡°ì˜ íŠ¹ì„±ì…ë‹ˆë‹¤.'
        },
        {
          question: 'ê²°ì¸¡ ë©”ì»¤ë‹ˆì¦˜ ì¤‘ "ê²°ì¸¡ì´ ë‹¤ë¥¸ ê´€ì¸¡ ë³€ìˆ˜ì™€ ê´€ë ¨"ì¸ ê²ƒì€?',
          options: ['MCAR', 'MAR', 'MNAR', 'Random'],
          answer: 1,
          explanation: 'MAR(Missing At Random)ì€ ê²°ì¸¡ì´ ë‹¤ë¥¸ ê´€ì¸¡ ë³€ìˆ˜ì™€ ê´€ë ¨ë©ë‹ˆë‹¤. ì˜ˆ: ë‚¨ì„±ì´ ì—¬ì„±ë³´ë‹¤ ì†Œë“ ë¯¸ì‘ë‹µ ë¹„ìœ¨ì´ ë†’ì€ ê²½ìš°. MCARì€ ì™„ì „ ë¬´ì‘ìœ„, MNARì€ ê²°ì¸¡ê°’ ìì²´ì™€ ê´€ë ¨ë©ë‹ˆë‹¤.'
        },
        {
          question: 'KNN Imputerì˜ íŠ¹ì§•ì´ ì•„ë‹Œ ê²ƒì€?',
          options: ['ìœ ì‚¬í•œ í–‰ì˜ ê°’ìœ¼ë¡œ ëŒ€ì²´', 'ë‹¤ë³€ëŸ‰ ê´€ê³„ ê³ ë ¤', 'ë²”ì£¼í˜• ë³€ìˆ˜ì— ì§ì ‘ ì ìš© ê°€ëŠ¥', 'ëŒ€ê·œëª¨ ë°ì´í„°ì—ì„œ ëŠë¦¼'],
          answer: 2,
          explanation: 'KNN ImputerëŠ” ìˆ˜ì¹˜í˜• ë³€ìˆ˜ì—ë§Œ ì§ì ‘ ì ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤. ë²”ì£¼í˜• ë³€ìˆ˜ëŠ” ë¨¼ì € ì¸ì½”ë”©í•´ì•¼ í•©ë‹ˆë‹¤. ìœ ì‚¬í•œ Kê°œ í–‰ì„ ì°¾ì•„ ëŒ€ì²´í•˜ë©°, ê±°ë¦¬ ê³„ì‚°ìœ¼ë¡œ ì¸í•´ ëŒ€ê·œëª¨ ë°ì´í„°ì—ì„œ ëŠë¦½ë‹ˆë‹¤.'
        },
        {
          question: 'ì´ìƒì¹˜ì— ê°•ê±´í•œ ìŠ¤ì¼€ì¼ëŸ¬ëŠ”?',
          options: ['StandardScaler', 'MinMaxScaler', 'RobustScaler', 'MaxAbsScaler'],
          answer: 2,
          explanation: 'RobustScalerëŠ” ì¤‘ì•™ê°’ê³¼ IQRì„ ì‚¬ìš©í•˜ì—¬ ì´ìƒì¹˜ì˜ ì˜í–¥ì„ ë°›ì§€ ì•ŠìŠµë‹ˆë‹¤. StandardScalerëŠ” í‰ê· /í‘œì¤€í¸ì°¨, MinMaxScalerì™€ MaxAbsScalerëŠ” ìµœì†Œ/ìµœëŒ€ê°’ì„ ì‚¬ìš©í•´ ì´ìƒì¹˜ì— ë¯¼ê°í•©ë‹ˆë‹¤.'
        },
        {
          question: 'One-Hot Encodingì˜ ë‹¨ì ì€?',
          options: ['ìˆœì„œ ì •ë³´ ì†ì‹¤', 'ê³ ì¹´ë””ë„ë¦¬í‹°ì—ì„œ ì°¨ì› í­ë°œ', 'ë²”ì£¼ ì •ë³´ ì†ì‹¤', 'í•´ì„ ì–´ë ¤ì›€'],
          answer: 1,
          explanation: 'One-Hot Encodingì€ ì¹´í…Œê³ ë¦¬ ìˆ˜ë§Œí¼ ì»¬ëŸ¼ì´ ìƒì„±ë˜ì–´, ê³ ì¹´ë””ë„ë¦¬í‹°(ë§ì€ ê³ ìœ ê°’)ì—ì„œ ì°¨ì›ì´ í­ë°œì ìœ¼ë¡œ ì¦ê°€í•©ë‹ˆë‹¤. 1000ê°œ ì¹´í…Œê³ ë¦¬ = 1000ê°œ ì»¬ëŸ¼ì´ ìƒì„±ë©ë‹ˆë‹¤.'
        },
        {
          question: 'Target Encoding ì‹œ ê³¼ì í•©ì„ ë°©ì§€í•˜ëŠ” ë°©ë²•ì€?',
          options: ['ë” ë§ì€ ì¹´í…Œê³ ë¦¬ ì‚¬ìš©', 'CV ë°©ì‹ ì ìš©', 'Standardization', 'Drop First'],
          answer: 1,
          explanation: 'Target Encodingì€ íƒ€ê²Ÿ ì •ë³´ë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ë¯€ë¡œ ê³¼ì í•© ìœ„í—˜ì´ ìˆìŠµë‹ˆë‹¤. K-Fold CV ë°©ì‹ìœ¼ë¡œ ê° foldì—ì„œ ë‹¤ë¥¸ foldì˜ íƒ€ê²Ÿ í‰ê· ì„ ì‚¬ìš©í•˜ë©´ ê³¼ì í•©ì„ íš¨ê³¼ì ìœ¼ë¡œ ë°©ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.'
        },
        {
          question: 'sklearn ColumnTransformerì˜ ìš©ë„ëŠ”?',
          options: ['ëª¨ë¸ í•™ìŠµ', 'ì»¬ëŸ¼ ìœ í˜•ë³„ ë‹¤ë¥¸ ì „ì²˜ë¦¬ ì ìš©', 'ë°ì´í„° ë¡œë“œ', 'ì„±ëŠ¥ í‰ê°€'],
          answer: 1,
          explanation: 'ColumnTransformerëŠ” ìˆ˜ì¹˜í˜•ê³¼ ë²”ì£¼í˜• ë“± ì»¬ëŸ¼ ìœ í˜•ë³„ë¡œ ë‹¤ë¥¸ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ì„ ì ìš©í•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤. ì˜ˆ: ìˆ˜ì¹˜í˜•ì€ StandardScaler, ë²”ì£¼í˜•ì€ OneHotEncoder.'
        },
        {
          question: 'ë°ì´í„° ëˆ„ìˆ˜ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ ìŠ¤ì¼€ì¼ëŸ¬ëŠ” ì–´ë””ì—ì„œ fití•´ì•¼ í•˜ëŠ”ê°€?',
          options: ['ì „ì²´ ë°ì´í„°', 'í•™ìŠµ ë°ì´í„°ë§Œ', 'í…ŒìŠ¤íŠ¸ ë°ì´í„°ë§Œ', 'ê²€ì¦ ë°ì´í„°'],
          answer: 1,
          explanation: 'ìŠ¤ì¼€ì¼ëŸ¬ëŠ” í•™ìŠµ ë°ì´í„°ì—ì„œë§Œ fití•´ì•¼ í•©ë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ í†µê³„ì¹˜ê°€ ëª¨ë¸ í•™ìŠµì— ì‚¬ìš©ë˜ë©´ ë°ì´í„° ëˆ„ìˆ˜ê°€ ë°œìƒí•˜ë©°, ì‹¤ì œ ì˜ˆì¸¡ ìƒí™©ì„ ë°˜ì˜í•˜ì§€ ëª»í•©ë‹ˆë‹¤.'
        },
        {
          question: 'Winsorizingì˜ íš¨ê³¼ëŠ”?',
          options: ['ê²°ì¸¡ì¹˜ ëŒ€ì²´', 'ê·¹ë‹¨ê°’ì„ ê²½ê³„ê°’ìœ¼ë¡œ ëŒ€ì²´', 'ë¶„í¬ë¥¼ ì •ê·œí™”', 'ì°¨ì› ì¶•ì†Œ'],
          answer: 1,
          explanation: 'Winsorizingì€ ìƒí•˜ìœ„ íŠ¹ì • í¼ì„¼íƒ€ì¼(ì˜ˆ: 1%, 99%)ì˜ ê·¹ë‹¨ê°’ì„ í•´ë‹¹ ê²½ê³„ê°’ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤. ë°ì´í„° ê°œìˆ˜ë¥¼ ìœ ì§€í•˜ë©´ì„œ ê·¹ë‹¨ê°’ì˜ ì˜í–¥ì„ ì¤„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.'
        },
        {
          question: 'IQR ë°©ë²•ì—ì„œ ì´ìƒì¹˜ íŒë‹¨ ê¸°ì¤€ì€?',
          options: ['í‰ê·  Â± 3 í‘œì¤€í¸ì°¨', 'Q1-1.5*IQR ~ Q3+1.5*IQR ë²”ìœ„ ë°–', 'ìƒí•˜ìœ„ 1%', 'Z-score > 2'],
          answer: 1,
          explanation: 'IQR ë°©ë²•ì€ Q1 - 1.5Ã—IQRë³´ë‹¤ ì‘ê±°ë‚˜ Q3 + 1.5Ã—IQRë³´ë‹¤ í° ê°’ì„ ì´ìƒì¹˜ë¡œ íŒë‹¨í•©ë‹ˆë‹¤. ë¶„í¬ ê°€ì • ì—†ì´ ì‚¬ìš©í•  ìˆ˜ ìˆì–´ ê°€ì¥ ë„ë¦¬ ì“°ì´ëŠ” ì´ìƒì¹˜ íƒì§€ ë°©ë²•ì…ë‹ˆë‹¤.'
        }
      ]
    }
  },
  {
    id: 'p2w2d5t4',
    type: 'challenge',
    title: 'ì£¼ê°„ ë„ì „ê³¼ì œ: ì‹¤ì „ ë°ì´í„° ì •ì œ ê²½ìŸ',
    duration: 60,
    content: {
      instructions: `# ì£¼ê°„ ë„ì „ê³¼ì œ: ì‹¤ì „ ë°ì´í„° ì •ì œ ê²½ìŸ

## ëª©í‘œ
ì‹¤ì œ Kaggle ë°ì´í„°ì…‹ì„ ì„ íƒí•˜ì—¬ **ë°ì´í„° ì •ì œ íŒŒì´í”„ë¼ì¸**ì„ êµ¬ì¶•í•˜ê³ , ì •ì œ í’ˆì§ˆì„ ì •ëŸ‰ì ìœ¼ë¡œ ì¸¡ì •í•˜ì„¸ìš”.

## ì¶”ì²œ ë°ì´í„°ì…‹

| ë°ì´í„°ì…‹ | ë‚œì´ë„ | íŠ¹ì§• |
|---------|--------|------|
| [Spaceship Titanic](https://www.kaggle.com/competitions/spaceship-titanic) | ì¤‘ | ë‹¤ì–‘í•œ ê²°ì¸¡ íŒ¨í„´, ë³µí•© ì»¬ëŸ¼ íŒŒì‹± í•„ìš” |
| [House Prices](https://www.kaggle.com/c/house-prices-advanced-regression-techniques) | ìƒ | 79ê°œ í”¼ì²˜, ê³ ì¹´ë””ë„ë¦¬í‹°, ë‹¤ì–‘í•œ ê²°ì¸¡ |
| [Playground S4E1](https://www.kaggle.com/competitions/playground-series-s4e1) | ì¤‘ | ì€í–‰ ì´íƒˆ ì˜ˆì¸¡, ë²”ì£¼í˜•/ìˆ˜ì¹˜í˜• í˜¼í•© |

## ìš”êµ¬ì‚¬í•­

### 1. ë°ì´í„° í’ˆì§ˆ ë¦¬í¬íŠ¸ (20ì )
- 6ì°¨ì› í’ˆì§ˆ í‰ê°€ ìˆ˜í–‰
- ê° ì°¨ì›ë³„ ì ìˆ˜ ì‚°ì¶œ (0-100)
- ì£¼ìš” í’ˆì§ˆ ì´ìŠˆ 3ê°œ ì´ìƒ ì‹ë³„

### 2. ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì „ëµ (25ì )
- ê²°ì¸¡ ë©”ì»¤ë‹ˆì¦˜ ì§„ë‹¨ (MCAR/MAR/MNAR)
- ì»¬ëŸ¼ë³„ ì²˜ë¦¬ ë°©ë²• ì„ íƒ ë° ê·¼ê±°
- ì²˜ë¦¬ ì „í›„ í†µê³„ëŸ‰ ë¹„êµ

### 3. ì´ìƒì¹˜ ì²˜ë¦¬ ì „ëµ (20ì )
- 2ê°€ì§€ ì´ìƒ íƒì§€ ë°©ë²• ì ìš© (IQR, Z-score ë“±)
- ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜ ì´ìƒì¹˜ íŒë‹¨
- ì²˜ë¦¬ ë°©ë²• ì„ íƒ (ì œê±°/ë³€í™˜/ìœ ì§€) ë° ê·¼ê±°

### 4. sklearn Pipeline êµ¬ì¶• (25ì )
- ColumnTransformerë¡œ ìˆ˜ì¹˜í˜•/ë²”ì£¼í˜• ë¶„ë¦¬ ì²˜ë¦¬
- ì „ì²˜ë¦¬ + ëª¨ë¸ í†µí•© íŒŒì´í”„ë¼ì¸
- 5-Fold CV ì„±ëŠ¥ ì¸¡ì •

### 5. ëª¨ë¸ ì„±ëŠ¥ ê°œì„  ì¸¡ì • (10ì )
- ì›ë³¸ ë°ì´í„° vs ì •ì œ ë°ì´í„° ì„±ëŠ¥ ë¹„êµ
- ê°œì„ ìœ¨ ê³„ì‚° ë° í•´ì„

## í‰ê°€ ê¸°ì¤€

| í•­ëª© | ë°°ì  | ì„¸ë¶€ ê¸°ì¤€ |
|------|------|----------|
| í’ˆì§ˆ ë¦¬í¬íŠ¸ | 20ì  | 6ì°¨ì› í‰ê°€, ì‹œê°í™”, ì´ìŠˆ ì‹ë³„ |
| ê²°ì¸¡ì¹˜ ì²˜ë¦¬ | 25ì  | ë©”ì»¤ë‹ˆì¦˜ ì§„ë‹¨, ì ì ˆí•œ ë°©ë²•, ë¬¸ì„œí™” |
| ì´ìƒì¹˜ ì²˜ë¦¬ | 20ì  | ë‹¤ì¤‘ ë°©ë²•, ë„ë©”ì¸ ì§€ì‹, ê·¼ê±° |
| Pipeline | 25ì  | ì¬ì‚¬ìš©ì„±, ëˆ„ìˆ˜ ë°©ì§€, CV ì„±ëŠ¥ |
| ì„±ëŠ¥ ê°œì„  | 10ì  | ì •ëŸ‰ì  ë¹„êµ, í•´ì„ |

## ë³´ë„ˆìŠ¤ í¬ì¸íŠ¸ (+10ì )

- Kaggle Notebookìœ¼ë¡œ ê³µê°œí•˜ì—¬ ì¢‹ì•„ìš” 1ê°œ ì´ìƒ íšë“
- Feature Engineering ì¶”ê°€ (ì˜ˆ: Cabin ì²« ê¸€ì ì¶”ì¶œ, ê°€ì¡± í¬ê¸°)
- 3ê°€ì§€ ì´ìƒ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ

## ì œì¶œ í˜•ì‹

\`\`\`
ğŸ“ week10-challenge/
â”œâ”€â”€ data_cleaning_pipeline.ipynb  # ë©”ì¸ ë…¸íŠ¸ë¶
â”œâ”€â”€ pipeline.pkl                   # ì €ì¥ëœ Pipeline
â””â”€â”€ quality_report.md             # í’ˆì§ˆ ë¦¬í¬íŠ¸ ìš”ì•½
\`\`\`

## íŒíŠ¸

- \`df.info()\`ì™€ \`df.describe()\`ë¡œ ë°ì´í„° ê°œìš” íŒŒì•…
- \`missingno\` ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ ê²°ì¸¡ íŒ¨í„´ ì‹œê°í™”
- \`scipy.stats.chi2_contingency\`ë¡œ MAR ì§„ë‹¨
- \`joblib.dump(pipeline, 'pipeline.pkl')\`ë¡œ íŒŒì´í”„ë¼ì¸ ì €ì¥
`,
      starterCode: `"""
Week 10 ë„ì „ê³¼ì œ: ì‹¤ì „ ë°ì´í„° ì •ì œ ê²½ìŸ
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, RobustScaler, OneHotEncoder
from sklearn.impute import SimpleImputer, KNNImputer
from sklearn.ensemble import RandomForestClassifier

# =============================================================================
# 1. ë°ì´í„° ë¡œë“œ
# =============================================================================
# TODO: Kaggle ë°ì´í„° ë¡œë“œ
# train = pd.read_csv('train.csv')

# ì˜ˆì‹œ ë°ì´í„° (ì‹¤ì œ Kaggle ë°ì´í„°ë¡œ êµì²´)
np.random.seed(42)
n = 2000
train = pd.DataFrame({
    'PassengerId': range(1, n + 1),
    'HomePlanet': np.random.choice(['Earth', 'Europa', 'Mars', None], n, p=[0.5, 0.2, 0.2, 0.1]),
    'CryoSleep': np.random.choice([True, False, None], n, p=[0.3, 0.6, 0.1]),
    'Cabin': [f"{np.random.choice(['A','B','C','D','E','F','G'])}/{np.random.randint(0, 2000)}/{np.random.choice(['P','S'])}"
              if np.random.random() > 0.3 else None for _ in range(n)],
    'Destination': np.random.choice(['TRAPPIST-1e', '55 Cancri e', 'PSO J318.5-22', None], n, p=[0.6, 0.2, 0.15, 0.05]),
    'Age': np.random.uniform(0, 80, n),
    'VIP': np.random.choice([True, False, None], n, p=[0.05, 0.9, 0.05]),
    'RoomService': np.random.exponential(200, n),
    'FoodCourt': np.random.exponential(300, n),
    'ShoppingMall': np.random.exponential(100, n),
    'Spa': np.random.exponential(250, n),
    'VRDeck': np.random.exponential(150, n),
    'Name': [f"Person_{i}" for i in range(n)],
    'Transported': np.random.choice([True, False], n)
})

# ê²°ì¸¡ì¹˜ ë° ì´ìƒì¹˜ ì¶”ê°€
train.loc[np.random.choice(n, 200, replace=False), 'Age'] = np.nan
train.loc[10:20, 'Age'] = [-5, 150, 200, 0, 999, -10, 180, 250, 1, 300, 500]
train.loc[np.random.choice(n, 100, replace=False), 'RoomService'] = np.nan
train.loc[50:55, 'RoomService'] = [50000, 100000, -100, 80000, 200000, 150000]

print("=== ë°ì´í„° ë¡œë“œ ì™„ë£Œ ===")
print(f"Shape: {train.shape}")
print(f"\\nì»¬ëŸ¼:\\n{train.columns.tolist()}")

# =============================================================================
# 2. ë°ì´í„° í’ˆì§ˆ í‰ê°€ (6ì°¨ì›)
# =============================================================================
def evaluate_quality_6d(df):
    """6ì°¨ì› ë°ì´í„° í’ˆì§ˆ í‰ê°€"""
    scores = {}

    # TODO: ì™„ì „ì„±, ì •í™•ì„±, ì¼ê´€ì„±, ì ì‹œì„±, ìœ íš¨ì„±, ìœ ì¼ì„± í‰ê°€

    return scores

# =============================================================================
# 3. ê²°ì¸¡ì¹˜ ë¶„ì„ ë° ì²˜ë¦¬
# =============================================================================
def analyze_and_impute(df):
    """ê²°ì¸¡ì¹˜ ë¶„ì„ ë° ì²˜ë¦¬"""
    df_clean = df.copy()

    # TODO: ê²°ì¸¡ ë©”ì»¤ë‹ˆì¦˜ ì§„ë‹¨
    # TODO: ì»¬ëŸ¼ë³„ ì²˜ë¦¬ ì „ëµ ì ìš©

    return df_clean

# =============================================================================
# 4. ì´ìƒì¹˜ íƒì§€ ë° ì²˜ë¦¬
# =============================================================================
def detect_and_handle_outliers(df):
    """ì´ìƒì¹˜ íƒì§€ ë° ì²˜ë¦¬"""
    df_clean = df.copy()

    # TODO: IQR ë° Z-score ì´ìƒì¹˜ íƒì§€
    # TODO: ì²˜ë¦¬ ì „ëµ ì ìš©

    return df_clean

# =============================================================================
# 5. sklearn Pipeline êµ¬ì¶•
# =============================================================================
def build_pipeline():
    """ì „ì²˜ë¦¬ + ëª¨ë¸ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•"""

    # TODO: ColumnTransformer ì •ì˜
    # TODO: Pipeline êµ¬ì¶•

    pass

# =============================================================================
# 6. ì„±ëŠ¥ ë¹„êµ
# =============================================================================
def compare_performance(df_original, df_cleaned, target_col):
    """ì›ë³¸ vs ì •ì œ ë°ì´í„° ì„±ëŠ¥ ë¹„êµ"""

    # TODO: ì›ë³¸ ë°ì´í„°ë¡œ CV ì„±ëŠ¥
    # TODO: ì •ì œ ë°ì´í„°ë¡œ CV ì„±ëŠ¥
    # TODO: ê°œì„ ìœ¨ ê³„ì‚°

    pass

# =============================================================================
# ì‹¤í–‰
# =============================================================================
print("\\në„ì „ê³¼ì œë¥¼ ì™„ì„±í•˜ì„¸ìš”!")
`,
      hints: [
        'í’ˆì§ˆ í‰ê°€: df.isnull().mean(), df.duplicated().sum() í™œìš©',
        'ê²°ì¸¡ ë©”ì»¤ë‹ˆì¦˜: chi2_contingencyë¡œ ê·¸ë£¹ë³„ ê²°ì¸¡ë¥  ì°¨ì´ ê²€ì •',
        'Cabin íŒŒì‹±: deck/num/side = cabin.str.split("/", expand=True)',
        'Pipeline ì €ì¥: joblib.dump(pipeline, "pipeline.pkl")'
      ]
    }
  }
]
