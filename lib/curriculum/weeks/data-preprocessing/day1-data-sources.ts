// Week 10 Day 1: ë°ì´í„° ì†ŒìŠ¤ ë§¤í•‘ & ì´í•´
import type { Task } from '../../types'

export const day1Tasks: Task[] = [
  {
    id: 'p2w2d1t1',
    type: 'video',
    title: 'ì¡°ì§ ë‚´ ë°ì´í„° ì†ŒìŠ¤ ì´í•´',
    duration: 20,
    content: {
      videoUrl: 'https://www.youtube.com/watch?v=placeholder',
      transcript: `# ì¡°ì§ ë‚´ ë°ì´í„° ì†ŒìŠ¤ ì´í•´

## ì™œ ë°ì´í„° ì†ŒìŠ¤ ë§¤í•‘ì´ ì¤‘ìš”í•œê°€?

FDEëŠ” ë¶„ì„ì„ ì‹œì‘í•˜ê¸° ì „ì— "ì–´ë–¤ ë°ì´í„°ê°€ ì–´ë””ì— ìˆëŠ”ì§€"ë¥¼ íŒŒì•…í•´ì•¼ í•©ë‹ˆë‹¤.

\\\`\\\`\\\`
ì˜ëª»ëœ ì ‘ê·¼:
"ë¶„ì„ ìš”ì²­ ë°›ìŒ â†’ ë°”ë¡œ ì½”ë”© ì‹œì‘ â†’ ë°ì´í„° ì–´ë””ìˆì§€?"

ì˜¬ë°”ë¥¸ ì ‘ê·¼:
"ë¶„ì„ ìš”ì²­ ë°›ìŒ â†’ í•„ìš”í•œ ë°ì´í„° ì •ì˜ â†’ ì†ŒìŠ¤ íŒŒì•… â†’ ì ‘ê·¼ ê¶Œí•œ í™•ì¸ â†’ ë¶„ì„"
\\\`\\\`\\\`

## ì¼ë°˜ì ì¸ ì¡°ì§ì˜ ë°ì´í„° êµ¬ì¡°

### 1. ìš´ì˜ ì‹œìŠ¤í…œ (Operational Systems)

| ì‹œìŠ¤í…œ | ë°ì´í„° ìœ í˜• | ì˜ˆì‹œ |
|--------|------------|------|
| ERP (SAP, Oracle) | ì¬ë¬´, ì¬ê³ , êµ¬ë§¤ | ë§¤ì¶œ, ì›ê°€, ì¬ê³ ëŸ‰ |
| CRM (Salesforce) | ê³ ê°, ì˜ì—… | ê³ ê° ì •ë³´, ê±°ë˜ ë‚´ì—­ |
| WMS (ì°½ê³ ê´€ë¦¬) | ë¬¼ë¥˜, ë°°ì†¡ | ì¶œê³ ëŸ‰, ë°°ì†¡ ì‹œê°„ |
| POS | ê±°ë˜, ê²°ì œ | ì‹¤ì‹œê°„ íŒë§¤ |

### 2. ì›¹/ì•± ë°ì´í„°

| ì†ŒìŠ¤ | ë°ì´í„° ìœ í˜• | í™œìš© |
|------|------------|------|
| Google Analytics | ì›¹ í–‰ë™ | ì „í™˜ í¼ë„, ì´íƒˆë¥  |
| Amplitude | ì•± ì´ë²¤íŠ¸ | ì‚¬ìš© íŒ¨í„´, ë¦¬í…ì…˜ |
| A/B í…ŒìŠ¤íŠ¸ | ì‹¤í—˜ ê²°ê³¼ | ê¸°ëŠ¥ íš¨ê³¼ ê²€ì¦ |

### 3. ë°ì´í„° ì €ì¥ì†Œ

\\\`\\\`\\\`
Raw Data (S3, GCS)
    â†“ ETL
Data Lake (Delta Lake, Iceberg)
    â†“ Transform
Data Warehouse (Snowflake, BigQuery)
    â†“ Aggregate
Data Mart (ë¶€ì„œë³„)
\\\`\\\`\\\`

## ë°ì´í„° ì¹´íƒˆë¡œê·¸ì˜ ì¤‘ìš”ì„±

### ì™œ ë°ì´í„° ì¹´íƒˆë¡œê·¸ê°€ í•„ìš”í•œê°€?

\\\`\\\`\\\`
ë¬¸ì œ ìƒí™©:
- "ì´ í…Œì´ë¸” ëˆ„ê°€ ê´€ë¦¬í•´ìš”?"
- "ì´ ì»¬ëŸ¼ ì˜ë¯¸ê°€ ë­ì˜ˆìš”?"
- "ìµœì‹  ë°ì´í„°ê°€ ì–¸ì œê¹Œì§€ì˜ˆìš”?"
- "ì´ ë°ì´í„° ì¨ë„ ë˜ë‚˜ìš”?"

í•´ê²°ì±…: ë°ì´í„° ì¹´íƒˆë¡œê·¸
- ë©”íƒ€ë°ì´í„° ê´€ë¦¬
- ë°ì´í„° ì†Œìœ ì ëª…ì‹œ
- ë°ì´í„° í’ˆì§ˆ ì§€í‘œ
- ì ‘ê·¼ ê¶Œí•œ ê´€ë¦¬
\\\`\\\`\\\`

### ì£¼ìš” ë°ì´í„° ì¹´íƒˆë¡œê·¸ ë„êµ¬

| ë„êµ¬ | íŠ¹ì§• | ê°€ê²© |
|------|------|------|
| DataHub (LinkedIn) | ì˜¤í”ˆì†ŒìŠ¤, í™•ì¥ì„± | ë¬´ë£Œ |
| Atlan | í˜‘ì—… ì¤‘ì‹¬, ì§ê´€ì  | ìœ ë£Œ |
| Alation | ì—”í„°í”„ë¼ì´ì¦ˆ | ìœ ë£Œ |
| dbt Cloud | dbt ì—°ë™, ë¬¸ì„œí™” | ë¬´ë£Œ/ìœ ë£Œ |

## FDEì˜ ë°ì´í„° ì†ŒìŠ¤ ì ‘ê·¼ë²•

### 1. ë°ì´í„° ìš”êµ¬ì‚¬í•­ ì •ì˜

\\\`\\\`\\\`python
# ë¶„ì„ ëª©í‘œ: ê³ ê° ì´íƒˆ ì˜ˆì¸¡

í•„ìš”í•œ ë°ì´í„°:
1. ê³ ê° ê¸°ë³¸ ì •ë³´ (CRM)
   - ê°€ì…ì¼, ì—°ë ¹, ì§€ì—­

2. ê±°ë˜ ë‚´ì—­ (ERP)
   - êµ¬ë§¤ ê¸ˆì•¡, ë¹ˆë„, ìµœê·¼ êµ¬ë§¤ì¼

3. ì„œë¹„ìŠ¤ ì´ìš© (ì›¹ ë¡œê·¸)
   - ë¡œê·¸ì¸ ë¹ˆë„, í˜ì´ì§€ ì²´ë¥˜ ì‹œê°„

4. CS ìƒë‹´ (CRM)
   - ë¬¸ì˜ íšŸìˆ˜, ë¶ˆë§Œ ìœ í˜•
\\\`\\\`\\\`

### 2. ë°ì´í„° ì†ŒìŠ¤ ë§¤í•‘

\\\`\\\`\\\`sql
-- ì†ŒìŠ¤ë³„ í…Œì´ë¸” ì‹ë³„
SELECT
    source_system,
    table_name,
    column_name,
    data_type,
    last_updated
FROM data_catalog
WHERE business_domain = 'ê³ ê°'
\\\`\\\`\\\`

### 3. ë°ì´í„° ì¡°ì¸ ì „ëµ

\\\`\\\`\\\`
ê³ ê° IDë¡œ ì—°ê²°:
CRM.customer_id
    â†” ERP.customer_id
    â†” WebLog.user_id (ë§¤í•‘ í…Œì´ë¸” í•„ìš”)
    â†” CS.customer_id
\\\`\\\`\\\`
`,
      objectives: [
        'ì¡°ì§ ë‚´ ë°ì´í„° ì†ŒìŠ¤ ìœ í˜•ì„ ì´í•´í•œë‹¤',
        'ë°ì´í„° ì¹´íƒˆë¡œê·¸ì˜ í•„ìš”ì„±ì„ ì´í•´í•œë‹¤',
        'ë¶„ì„ì— í•„ìš”í•œ ë°ì´í„° ì†ŒìŠ¤ë¥¼ ì‹ë³„í•  ìˆ˜ ìˆë‹¤'
      ],
      keyPoints: [
        'ë¶„ì„ ì „ ë°ì´í„° ì†ŒìŠ¤ ë§¤í•‘ì´ í•„ìˆ˜',
        'ERP, CRM, ì›¹ ë¡œê·¸ ë“± ë‹¤ì–‘í•œ ì†ŒìŠ¤ ì¡´ì¬',
        'ë°ì´í„° ì¹´íƒˆë¡œê·¸ë¡œ ë©”íƒ€ë°ì´í„° ê´€ë¦¬',
        'ì¡°ì¸ í‚¤ ì‹ë³„ì´ ì¤‘ìš”'
      ]
    }
  },
  {
    id: 'p2w2d1t2',
    type: 'video',
    title: 'ë°ì´í„° í’ˆì§ˆ 6ì°¨ì›',
    duration: 25,
    content: {
      videoUrl: 'https://www.youtube.com/watch?v=placeholder',
      transcript: `# ë°ì´í„° í’ˆì§ˆ 6ì°¨ì›

## ë°ì´í„° í’ˆì§ˆì´ ì™œ ì¤‘ìš”í•œê°€?

\\\`\\\`\\\`
"Garbage In, Garbage Out"

ì•„ë¬´ë¦¬ ì¢‹ì€ ëª¨ë¸ë„ ë‚˜ìœ ë°ì´í„°ë¡œëŠ” ì¢‹ì€ ê²°ê³¼ë¥¼ ë‚¼ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤ í”„ë¡œì íŠ¸ì˜ 80%ëŠ” ë°ì´í„° í’ˆì§ˆ ë¬¸ì œë¡œ ì‹¤íŒ¨í•©ë‹ˆë‹¤.
\\\`\\\`\\\`

## 6ê°€ì§€ ë°ì´í„° í’ˆì§ˆ ì°¨ì›

### 1. ì™„ì „ì„± (Completeness)

**ì§ˆë¬¸**: í•„ìš”í•œ ë°ì´í„°ê°€ ë‹¤ ìˆëŠ”ê°€?

\\\`\\\`\\\`python
import pandas as pd

# ê²°ì¸¡ë¥  í™•ì¸
def check_completeness(df):
    missing = df.isnull().sum()
    missing_pct = (missing / len(df) * 100).round(2)

    report = pd.DataFrame({
        'missing_count': missing,
        'missing_pct': missing_pct
    })
    return report[report['missing_count'] > 0].sort_values('missing_pct', ascending=False)

# ê²°ê³¼ í•´ì„
# missing_pct > 50%: ì»¬ëŸ¼ ì‚­ì œ ê³ ë ¤
# missing_pct > 20%: ì›ì¸ íŒŒì•… í•„ìš”
# missing_pct < 5%: ëŒ€ì²´ ê°€ëŠ¥
\\\`\\\`\\\`

### 2. ì •í™•ì„± (Accuracy)

**ì§ˆë¬¸**: ë°ì´í„°ê°€ ì‹¤ì œì™€ ì¼ì¹˜í•˜ëŠ”ê°€?

\\\`\\\`\\\`python
# ë²”ìœ„ ê²€ì¦
def check_accuracy(df):
    issues = []

    # ë‚˜ì´ê°€ 0-120 ë²”ìœ„ì¸ì§€
    if 'age' in df.columns:
        invalid_age = df[(df['age'] < 0) | (df['age'] > 120)]
        if len(invalid_age) > 0:
            issues.append(f"Invalid age: {len(invalid_age)} rows")

    # ê°€ê²©ì´ ì–‘ìˆ˜ì¸ì§€
    if 'price' in df.columns:
        negative_price = df[df['price'] < 0]
        if len(negative_price) > 0:
            issues.append(f"Negative price: {len(negative_price)} rows")

    return issues

# ìƒ˜í”Œë§ ê²€ì¦ (ì‹¤ì œ ê°’ê³¼ ë¹„êµ)
# ë¬´ì‘ìœ„ë¡œ 100ê°œ ë ˆì½”ë“œ ì„ íƒ â†’ ì›ë³¸ ì‹œìŠ¤í…œê³¼ ë¹„êµ
\\\`\\\`\\\`

### 3. ì¼ê´€ì„± (Consistency)

**ì§ˆë¬¸**: ì‹œìŠ¤í…œ ê°„ ë°ì´í„°ê°€ ì¼ì¹˜í•˜ëŠ”ê°€?

\\\`\\\`\\\`python
# CRMê³¼ ERPì˜ ê³ ê° ìˆ˜ ë¹„êµ
crm_customers = crm_df['customer_id'].nunique()
erp_customers = erp_df['customer_id'].nunique()

print(f"CRM ê³ ê° ìˆ˜: {crm_customers}")
print(f"ERP ê³ ê° ìˆ˜: {erp_customers}")
print(f"ì°¨ì´: {abs(crm_customers - erp_customers)}")

# êµì§‘í•© í™•ì¸
common = set(crm_df['customer_id']) & set(erp_df['customer_id'])
only_crm = set(crm_df['customer_id']) - set(erp_df['customer_id'])
only_erp = set(erp_df['customer_id']) - set(crm_df['customer_id'])
\\\`\\\`\\\`

### 4. ì ì‹œì„± (Timeliness)

**ì§ˆë¬¸**: ë°ì´í„°ê°€ ìµœì‹ ì¸ê°€?

\\\`\\\`\\\`python
# ìµœì¢… ì—…ë°ì´íŠ¸ í™•ì¸
def check_timeliness(df, date_col):
    latest = df[date_col].max()
    today = pd.Timestamp.now()
    delay = (today - latest).days

    print(f"ìµœì‹  ë°ì´í„°: {latest}")
    print(f"í˜„ì¬: {today}")
    print(f"ì§€ì—°: {delay}ì¼")

    if delay > 7:
        print("âš ï¸ ê²½ê³ : 1ì£¼ì¼ ì´ìƒ ì§€ì—°")

    return delay
\\\`\\\`\\\`

### 5. ìœ íš¨ì„± (Validity)

**ì§ˆë¬¸**: ë°ì´í„° í˜•ì‹ì´ ì˜¬ë°”ë¥¸ê°€?

\\\`\\\`\\\`python
import re

def check_validity(df):
    issues = []

    # ì´ë©”ì¼ í˜•ì‹ ê²€ì¦
    if 'email' in df.columns:
        email_pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
        invalid_email = df[~df['email'].str.match(email_pattern, na=False)]
        if len(invalid_email) > 0:
            issues.append(f"Invalid email: {len(invalid_email)} rows")

    # ì „í™”ë²ˆí˜¸ í˜•ì‹
    if 'phone' in df.columns:
        phone_pattern = r'^01[0-9]-?[0-9]{3,4}-?[0-9]{4}$'
        invalid_phone = df[~df['phone'].str.match(phone_pattern, na=False)]
        if len(invalid_phone) > 0:
            issues.append(f"Invalid phone: {len(invalid_phone)} rows")

    return issues
\\\`\\\`\\\`

### 6. ìœ ì¼ì„± (Uniqueness)

**ì§ˆë¬¸**: ì¤‘ë³µì´ ì—†ëŠ”ê°€?

\\\`\\\`\\\`python
def check_uniqueness(df, key_cols):
    # ì „ì²´ ì¤‘ë³µ
    total_dups = df.duplicated().sum()
    print(f"ì „ì²´ ì¤‘ë³µ í–‰: {total_dups}")

    # í‚¤ ê¸°ì¤€ ì¤‘ë³µ
    key_dups = df.duplicated(subset=key_cols).sum()
    print(f"í‚¤({key_cols}) ì¤‘ë³µ: {key_dups}")

    # ì¤‘ë³µ ë ˆì½”ë“œ í™•ì¸
    if key_dups > 0:
        dup_records = df[df.duplicated(subset=key_cols, keep=False)]
        return dup_records.sort_values(key_cols)

    return None
\\\`\\\`\\\`

## ë°ì´í„° í’ˆì§ˆ ë¦¬í¬íŠ¸ ìë™í™”

\\\`\\\`\\\`python
def generate_quality_report(df):
    report = {
        'total_rows': len(df),
        'total_columns': len(df.columns),
        'completeness': {},
        'accuracy': [],
        'uniqueness': {}
    }

    # ì™„ì „ì„±
    for col in df.columns:
        missing_pct = df[col].isnull().mean() * 100
        report['completeness'][col] = round(missing_pct, 2)

    # ìœ ì¼ì„±
    report['uniqueness']['total_duplicates'] = df.duplicated().sum()

    return report
\\\`\\\`\\\`
`,
      objectives: [
        'ë°ì´í„° í’ˆì§ˆ 6ì°¨ì›ì„ ì´í•´í•œë‹¤',
        'ê° ì°¨ì›ë³„ ê²€ì¦ ë°©ë²•ì„ ì ìš©í•  ìˆ˜ ìˆë‹¤',
        'ë°ì´í„° í’ˆì§ˆ ë¦¬í¬íŠ¸ë¥¼ ìë™í™”í•  ìˆ˜ ìˆë‹¤'
      ],
      keyPoints: [
        'ì™„ì „ì„±: ê²°ì¸¡ë¥  í™•ì¸',
        'ì •í™•ì„±: ë²”ìœ„ ê²€ì¦, ìƒ˜í”Œ ê²€ì¦',
        'ì¼ê´€ì„±: ì‹œìŠ¤í…œ ê°„ ë¹„êµ',
        'ì ì‹œì„±: ìµœì‹  ë°ì´í„° í™•ì¸',
        'ìœ íš¨ì„±: í˜•ì‹ ê²€ì¦ (ì •ê·œì‹)',
        'ìœ ì¼ì„±: ì¤‘ë³µ íƒì§€'
      ]
    }
  },
  {
    id: 'p2w2d1t3',
    type: 'code',
    title: 'ì‹¤ìŠµ: ë°ì´í„° í’ˆì§ˆ í”„ë¡œíŒŒì¼ë§',
    duration: 45,
    content: {
      instructions: `# ë°ì´í„° í’ˆì§ˆ í”„ë¡œíŒŒì¼ë§ ì‹¤ìŠµ

## ëª©í‘œ
ì£¼ì–´ì§„ ë°ì´í„°ì…‹ì— ëŒ€í•´ 6ê°€ì§€ í’ˆì§ˆ ì°¨ì›ì„ í‰ê°€í•˜ëŠ” í”„ë¡œíŒŒì¼ë§ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”.

## ìš”êµ¬ì‚¬í•­

### 1. ë°ì´í„° ë¡œë“œ
- Kaggleì˜ "Spaceship Titanic" ë°ì´í„° ë˜ëŠ” ì œê³µëœ ìƒ˜í”Œ ë°ì´í„° ì‚¬ìš©
- ê¸°ë³¸ ì •ë³´ ì¶œë ¥ (shape, dtypes)

### 2. ì™„ì „ì„± (Completeness)
- ê° ì»¬ëŸ¼ë³„ ê²°ì¸¡ë¥  ê³„ì‚°
- ê²°ì¸¡ë¥  10% ì´ìƒì¸ ì»¬ëŸ¼ ì‹ë³„
- missingno ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ íŒ¨í„´ ì‹œê°í™”

### 3. ì •í™•ì„± (Accuracy)
- ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ë²”ìœ„ ê²€ì¦ (min, max)
- ì´ìƒê°’ íƒì§€ (IQR ë°©ë²•)

### 4. ìœ íš¨ì„± (Validity)
- ë²”ì£¼í˜• ì»¬ëŸ¼ì˜ ê³ ìœ ê°’ í™•ì¸
- ì˜ˆìƒì¹˜ ëª»í•œ ê°’ íƒì§€

### 5. ìœ ì¼ì„± (Uniqueness)
- ì „ì²´ ì¤‘ë³µ í–‰ ìˆ˜
- ID ì»¬ëŸ¼ ê¸°ì¤€ ì¤‘ë³µ í™•ì¸

### 6. ì¢…í•© ë¦¬í¬íŠ¸
- í’ˆì§ˆ ì ìˆ˜ (0-100) ê³„ì‚°
- ê°œì„  ê¶Œê³ ì‚¬í•­ ë„ì¶œ

## ì œì¶œë¬¼
- ì™„ì„±ëœ Python ì½”ë“œ
- í’ˆì§ˆ ë¦¬í¬íŠ¸ ì¶œë ¥
`,
      starterCode: `import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# ìƒ˜í”Œ ë°ì´í„° ìƒì„± (ë˜ëŠ” ì‹¤ì œ ë°ì´í„° ë¡œë“œ)
np.random.seed(42)
n = 1000

df = pd.DataFrame({
    'customer_id': range(1, n + 1),
    'age': np.random.randint(18, 80, n),
    'income': np.random.normal(50000, 15000, n),
    'email': ['user' + str(i) + '@email.com' for i in range(n)],
    'category': np.random.choice(['A', 'B', 'C', None], n, p=[0.3, 0.3, 0.3, 0.1]),
    'purchase_amount': np.random.exponential(100, n)
})

# ì˜ë„ì ìœ¼ë¡œ í’ˆì§ˆ ì´ìŠˆ ì¶”ê°€
df.loc[50:60, 'age'] = -5  # ì˜ëª»ëœ ë‚˜ì´
df.loc[100:150, 'income'] = np.nan  # ê²°ì¸¡ì¹˜
df.loc[200:210, 'email'] = 'invalid-email'  # ì˜ëª»ëœ ì´ë©”ì¼
df = pd.concat([df, df.iloc[:20]])  # ì¤‘ë³µ ì¶”ê°€

print("=== ë°ì´í„° ê¸°ë³¸ ì •ë³´ ===")
print(f"Shape: {df.shape}")
print(f"\\nDtypes:\\n{df.dtypes}")

# TODO: ì•„ë˜ì— í’ˆì§ˆ ê²€ì‚¬ ì½”ë“œ ì‘ì„±

# 1. ì™„ì „ì„± ê²€ì‚¬
def check_completeness(df):
    """ê° ì»¬ëŸ¼ë³„ ê²°ì¸¡ë¥ ì„ ê³„ì‚°í•©ë‹ˆë‹¤."""
    # ì—¬ê¸°ì— ì½”ë“œ ì‘ì„±
    pass

# 2. ì •í™•ì„± ê²€ì‚¬
def check_accuracy(df):
    """ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ì˜ ë²”ìœ„ì™€ ì´ìƒê°’ì„ ê²€ì‚¬í•©ë‹ˆë‹¤."""
    # ì—¬ê¸°ì— ì½”ë“œ ì‘ì„±
    pass

# 3. ìœ íš¨ì„± ê²€ì‚¬
def check_validity(df):
    """ë°ì´í„° í˜•ì‹ì´ ì˜¬ë°”ë¥¸ì§€ ê²€ì‚¬í•©ë‹ˆë‹¤."""
    # ì—¬ê¸°ì— ì½”ë“œ ì‘ì„±
    pass

# 4. ìœ ì¼ì„± ê²€ì‚¬
def check_uniqueness(df, key_col='customer_id'):
    """ì¤‘ë³µ ë ˆì½”ë“œë¥¼ íƒì§€í•©ë‹ˆë‹¤."""
    # ì—¬ê¸°ì— ì½”ë“œ ì‘ì„±
    pass

# 5. ì¢…í•© ë¦¬í¬íŠ¸
def generate_quality_report(df):
    """ì¢…í•© í’ˆì§ˆ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    # ì—¬ê¸°ì— ì½”ë“œ ì‘ì„±
    pass

# ì‹¤í–‰
print("\\n=== í’ˆì§ˆ ê²€ì‚¬ ê²°ê³¼ ===")
# ê° í•¨ìˆ˜ í˜¸ì¶œ
`,
      solutionCode: `import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import re

# ìƒ˜í”Œ ë°ì´í„° ìƒì„±
np.random.seed(42)
n = 1000

df = pd.DataFrame({
    'customer_id': range(1, n + 1),
    'age': np.random.randint(18, 80, n),
    'income': np.random.normal(50000, 15000, n),
    'email': ['user' + str(i) + '@email.com' for i in range(n)],
    'category': np.random.choice(['A', 'B', 'C', None], n, p=[0.3, 0.3, 0.3, 0.1]),
    'purchase_amount': np.random.exponential(100, n)
})

# í’ˆì§ˆ ì´ìŠˆ ì¶”ê°€
df.loc[50:60, 'age'] = -5
df.loc[100:150, 'income'] = np.nan
df.loc[200:210, 'email'] = 'invalid-email'
df = pd.concat([df, df.iloc[:20]]).reset_index(drop=True)

print("=== ë°ì´í„° ê¸°ë³¸ ì •ë³´ ===")
print(f"Shape: {df.shape}")
print(f"\\nDtypes:\\n{df.dtypes}")

# 1. ì™„ì „ì„± ê²€ì‚¬
def check_completeness(df):
    """ê° ì»¬ëŸ¼ë³„ ê²°ì¸¡ë¥ ì„ ê³„ì‚°í•©ë‹ˆë‹¤."""
    print("\\n--- 1. ì™„ì „ì„± (Completeness) ---")

    missing = df.isnull().sum()
    missing_pct = (missing / len(df) * 100).round(2)

    report = pd.DataFrame({
        'missing_count': missing,
        'missing_pct': missing_pct
    }).sort_values('missing_pct', ascending=False)

    print(report)

    # 10% ì´ìƒ ê²°ì¸¡ ì»¬ëŸ¼
    high_missing = report[report['missing_pct'] >= 10]
    if len(high_missing) > 0:
        print(f"\\nâš ï¸ ê²°ì¸¡ë¥  10% ì´ìƒ ì»¬ëŸ¼: {list(high_missing.index)}")

    return report

# 2. ì •í™•ì„± ê²€ì‚¬
def check_accuracy(df):
    """ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ì˜ ë²”ìœ„ì™€ ì´ìƒê°’ì„ ê²€ì‚¬í•©ë‹ˆë‹¤."""
    print("\\n--- 2. ì •í™•ì„± (Accuracy) ---")

    numerical_cols = df.select_dtypes(include=[np.number]).columns
    issues = []

    for col in numerical_cols:
        print(f"\\n[{col}]")
        print(f"  Min: {df[col].min():.2f}, Max: {df[col].max():.2f}")
        print(f"  Mean: {df[col].mean():.2f}, Std: {df[col].std():.2f}")

        # íŠ¹ì • ì»¬ëŸ¼ ë²”ìœ„ ê²€ì‚¬
        if col == 'age':
            invalid = df[(df[col] < 0) | (df[col] > 120)]
            if len(invalid) > 0:
                issues.append(f"age: {len(invalid)} invalid values (< 0 or > 120)")

        # IQR ì´ìƒì¹˜
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        outliers = df[(df[col] < Q1 - 1.5*IQR) | (df[col] > Q3 + 1.5*IQR)]
        if len(outliers) > 0:
            print(f"  IQR ì´ìƒì¹˜: {len(outliers)}ê°œ ({len(outliers)/len(df)*100:.1f}%)")

    if issues:
        print(f"\\nâš ï¸ ì •í™•ì„± ì´ìŠˆ:")
        for issue in issues:
            print(f"  - {issue}")

    return issues

# 3. ìœ íš¨ì„± ê²€ì‚¬
def check_validity(df):
    """ë°ì´í„° í˜•ì‹ì´ ì˜¬ë°”ë¥¸ì§€ ê²€ì‚¬í•©ë‹ˆë‹¤."""
    print("\\n--- 3. ìœ íš¨ì„± (Validity) ---")

    issues = []

    # ì´ë©”ì¼ ê²€ì¦
    if 'email' in df.columns:
        email_pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'
        invalid_email = df[~df['email'].astype(str).str.match(email_pattern)]
        print(f"\\n[email] ìœ íš¨í•˜ì§€ ì•Šì€ ì´ë©”ì¼: {len(invalid_email)}ê°œ")
        if len(invalid_email) > 0:
            issues.append(f"email: {len(invalid_email)} invalid format")
            print(f"  ì˜ˆì‹œ: {invalid_email['email'].head().tolist()}")

    # ë²”ì£¼í˜• ê³ ìœ ê°’
    categorical_cols = df.select_dtypes(include=['object', 'category']).columns
    for col in categorical_cols:
        if col != 'email':
            unique_vals = df[col].dropna().unique()
            print(f"\\n[{col}] ê³ ìœ ê°’: {unique_vals}")

    return issues

# 4. ìœ ì¼ì„± ê²€ì‚¬
def check_uniqueness(df, key_col='customer_id'):
    """ì¤‘ë³µ ë ˆì½”ë“œë¥¼ íƒì§€í•©ë‹ˆë‹¤."""
    print("\\n--- 4. ìœ ì¼ì„± (Uniqueness) ---")

    # ì „ì²´ ì¤‘ë³µ
    total_dups = df.duplicated().sum()
    print(f"ì „ì²´ ì¤‘ë³µ í–‰: {total_dups}ê°œ ({total_dups/len(df)*100:.1f}%)")

    # í‚¤ ê¸°ì¤€ ì¤‘ë³µ
    key_dups = df.duplicated(subset=[key_col]).sum()
    print(f"í‚¤({key_col}) ì¤‘ë³µ: {key_dups}ê°œ")

    if key_dups > 0:
        dup_ids = df[df.duplicated(subset=[key_col], keep=False)][key_col].unique()
        print(f"  ì¤‘ë³µëœ ID ì˜ˆì‹œ: {list(dup_ids[:5])}")

    return {'total_duplicates': total_dups, 'key_duplicates': key_dups}

# 5. ì¢…í•© ë¦¬í¬íŠ¸
def generate_quality_report(df):
    """ì¢…í•© í’ˆì§ˆ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    print("\\n" + "="*50)
    print("=== ì¢…í•© ë°ì´í„° í’ˆì§ˆ ë¦¬í¬íŠ¸ ===")
    print("="*50)

    scores = {}

    # ì™„ì „ì„± ì ìˆ˜ (ê²°ì¸¡ë¥  ê¸°ë°˜)
    completeness_score = (1 - df.isnull().mean().mean()) * 100
    scores['completeness'] = completeness_score

    # ìœ ì¼ì„± ì ìˆ˜ (ì¤‘ë³µë¥  ê¸°ë°˜)
    uniqueness_score = (1 - df.duplicated().mean()) * 100
    scores['uniqueness'] = uniqueness_score

    # ì¢…í•© ì ìˆ˜
    overall_score = np.mean(list(scores.values()))

    print(f"\\nğŸ“Š í’ˆì§ˆ ì ìˆ˜:")
    print(f"  - ì™„ì „ì„±: {scores['completeness']:.1f}/100")
    print(f"  - ìœ ì¼ì„±: {scores['uniqueness']:.1f}/100")
    print(f"  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    print(f"  - ì¢…í•©: {overall_score:.1f}/100")

    # ê¶Œê³ ì‚¬í•­
    print(f"\\nğŸ“‹ ê°œì„  ê¶Œê³ ì‚¬í•­:")
    if scores['completeness'] < 90:
        print("  1. [ì™„ì „ì„±] ê²°ì¸¡ì¹˜ ì²˜ë¦¬ í•„ìš” - KNN ë˜ëŠ” ì¤‘ì•™ê°’ ëŒ€ì²´ ê¶Œì¥")
    if scores['uniqueness'] < 95:
        print("  2. [ìœ ì¼ì„±] ì¤‘ë³µ ë ˆì½”ë“œ ì œê±° í•„ìš”")

    return scores

# ì‹¤í–‰
print("\\n=== í’ˆì§ˆ ê²€ì‚¬ ê²°ê³¼ ===")
completeness = check_completeness(df)
accuracy = check_accuracy(df)
validity = check_validity(df)
uniqueness = check_uniqueness(df)
scores = generate_quality_report(df)
`,
      hints: [
        'df.isnull().sum()ìœ¼ë¡œ ê²°ì¸¡ì¹˜ ìˆ˜ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤',
        'df.duplicated()ë¡œ ì¤‘ë³µ í–‰ì„ íƒì§€í•©ë‹ˆë‹¤',
        'str.match()ë¡œ ì •ê·œì‹ íŒ¨í„´ ê²€ì¦ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤',
        'IQR = Q3 - Q1, ì´ìƒì¹˜ëŠ” Q1 - 1.5*IQR ~ Q3 + 1.5*IQR ë²”ìœ„ ë°–'
      ]
    }
  },
  {
    id: 'p2w2d1t4',
    type: 'quiz',
    title: 'Day 1 í€´ì¦ˆ: ë°ì´í„° ì†ŒìŠ¤ & í’ˆì§ˆ',
    duration: 10,
    content: {
      questions: [
        {
          question: 'ë°ì´í„° í’ˆì§ˆ 6ì°¨ì› ì¤‘ "ë°ì´í„°ê°€ ì‹¤ì œì™€ ì¼ì¹˜í•˜ëŠ”ê°€?"ë¥¼ í‰ê°€í•˜ëŠ” ì°¨ì›ì€?',
          options: ['ì™„ì „ì„± (Completeness)', 'ì •í™•ì„± (Accuracy)', 'ì¼ê´€ì„± (Consistency)', 'ìœ íš¨ì„± (Validity)'],
          answer: 1,
          explanation: 'ì •í™•ì„±(Accuracy)ì€ ë°ì´í„°ê°€ ì‹¤ì œ ê°’ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ë¥¼ í‰ê°€í•©ë‹ˆë‹¤. ì™„ì „ì„±ì€ ê²°ì¸¡ì¹˜ ì—¬ë¶€, ì¼ê´€ì„±ì€ ì‹œìŠ¤í…œ ê°„ ë°ì´í„° ì¼ì¹˜, ìœ íš¨ì„±ì€ í˜•ì‹ì´ ì˜¬ë°”ë¥¸ì§€ë¥¼ í‰ê°€í•©ë‹ˆë‹¤.'
        },
        {
          question: 'ê²°ì¸¡ë¥ ì´ 50% ì´ìƒì¸ ì»¬ëŸ¼ì— ëŒ€í•œ ì¼ë°˜ì ì¸ ê¶Œì¥ ì²˜ë¦¬ ë°©ë²•ì€?',
          options: ['í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´', 'ì¤‘ì•™ê°’ìœ¼ë¡œ ëŒ€ì²´', 'KNN ëŒ€ì²´', 'ì»¬ëŸ¼ ì‚­ì œ ê³ ë ¤'],
          answer: 3,
          explanation: 'ê²°ì¸¡ë¥ ì´ 50% ì´ìƒì´ë©´ ëŒ€ì²´ ë°©ë²•ìœ¼ë¡œëŠ” ì‹ ë¢°í•  ìˆ˜ ì—†ëŠ” ê°’ì´ ìƒì„±ë  ìˆ˜ ìˆì–´, ì»¬ëŸ¼ ì‚­ì œë¥¼ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤. ë‹¨, í•´ë‹¹ ë³€ìˆ˜ì˜ ì¤‘ìš”ë„ì™€ ë¹„ì¦ˆë‹ˆìŠ¤ ë§¥ë½ì„ í•¨ê»˜ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤.'
        },
        {
          question: 'ë°ì´í„° ì¹´íƒˆë¡œê·¸ì˜ ì£¼ìš” ì—­í• ì´ ì•„ë‹Œ ê²ƒì€?',
          options: ['ë©”íƒ€ë°ì´í„° ê´€ë¦¬', 'ë°ì´í„° ì†Œìœ ì ëª…ì‹œ', 'ë°ì´í„° ë³€í™˜ ìˆ˜í–‰', 'ì ‘ê·¼ ê¶Œí•œ ê´€ë¦¬'],
          answer: 2,
          explanation: 'ë°ì´í„° ì¹´íƒˆë¡œê·¸ëŠ” ë©”íƒ€ë°ì´í„° ê´€ë¦¬, ë°ì´í„° ì†Œìœ ì ëª…ì‹œ, ì ‘ê·¼ ê¶Œí•œ ê´€ë¦¬ë¥¼ ë‹´ë‹¹í•©ë‹ˆë‹¤. ë°ì´í„° ë³€í™˜ì€ ETL íŒŒì´í”„ë¼ì¸ì´ë‚˜ ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ ë„êµ¬ì—ì„œ ìˆ˜í–‰í•©ë‹ˆë‹¤.'
        },
        {
          question: 'CRM ì‹œìŠ¤í…œì—ì„œ ì¼ë°˜ì ìœ¼ë¡œ ê´€ë¦¬í•˜ëŠ” ë°ì´í„° ìœ í˜•ì€?',
          options: ['ì¬ê³ , êµ¬ë§¤', 'ê³ ê°, ì˜ì—…', 'ë¬¼ë¥˜, ë°°ì†¡', 'ì¬ë¬´, ì›ê°€'],
          answer: 1,
          explanation: 'CRM(Customer Relationship Management)ì€ ê³ ê° ì •ë³´ì™€ ì˜ì—… ë°ì´í„°ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤. ì¬ê³ /êµ¬ë§¤ëŠ” ERP, ë¬¼ë¥˜/ë°°ì†¡ì€ WMS, ì¬ë¬´/ì›ê°€ë„ ERPì—ì„œ ì£¼ë¡œ ê´€ë¦¬í•©ë‹ˆë‹¤.'
        },
        {
          question: 'ì´ë©”ì¼ í˜•ì‹ ê²€ì¦ì— ì‚¬ìš©í•˜ëŠ” ê¸°ë²•ì€?',
          options: ['IQR ë°©ë²•', 'ì •ê·œì‹ (Regex)', 'Z-score', 'KNN'],
          answer: 1,
          explanation: 'ì •ê·œì‹(Regular Expression)ì€ ë¬¸ìì—´ íŒ¨í„´ì„ ì •ì˜í•˜ì—¬ ì´ë©”ì¼, ì „í™”ë²ˆí˜¸ ë“±ì˜ í˜•ì‹ì„ ê²€ì¦í•©ë‹ˆë‹¤. IQRê³¼ Z-scoreëŠ” ì´ìƒì¹˜ íƒì§€, KNNì€ ê²°ì¸¡ì¹˜ ëŒ€ì²´ì— ì‚¬ìš©ë©ë‹ˆë‹¤.'
        }
      ]
    }
  }
]
