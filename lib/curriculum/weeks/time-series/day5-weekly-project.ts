// Week 16 Day 5: Weekly Project - ìˆ˜ìš” ì˜ˆì¸¡
import type { Task } from '../../types'

export const day5Tasks: Task[] = [
  {
    id: 'p2w8d5t1',
    type: 'reading',
    title: 'Weekly Project ê°€ì´ë“œ',
    duration: 15,
    content: {
      markdown: `# Weekly Project: ìˆ˜ìš” ì˜ˆì¸¡ ëª¨ë¸ (í¬íŠ¸í´ë¦¬ì˜¤ #2)

## í”„ë¡œì íŠ¸ ê°œìš”

Phase 2ì˜ ë§ˆë¬´ë¦¬ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.
ì‹œê³„ì—´ ë¶„ì„ ê¸°ë²•ì„ ì¢…í•©í•˜ì—¬ ìˆ˜ìš” ì˜ˆì¸¡ ëª¨ë¸ì„ êµ¬ì¶•í•©ë‹ˆë‹¤.

## ë°ì´í„°ì…‹ ì„ íƒ

### ì˜µì…˜ 1: Store Sales (Kaggle)
- ì†Œë§¤ì  ì¼ë³„ ë§¤ì¶œ
- ë‹¤ì¤‘ ë§¤ì¥, ìƒí’ˆ ì¹´í…Œê³ ë¦¬
- íœ´ì¼, í”„ë¡œëª¨ì…˜ ì •ë³´

### ì˜µì…˜ 2: ìì²´ ë°ì´í„°
- ì‹¤ë¬´ ë§¤ì¶œ/ìˆ˜ìš” ë°ì´í„°
- ìµœì†Œ 1ë…„ ì¼ë³„ ë°ì´í„° ê¶Œì¥

## ìš”êµ¬ì‚¬í•­

### 1. ì‹œê³„ì—´ ë¶„ì„ (20%)
- ë¶„í•´ (Trend, Seasonal, Residual)
- ì •ìƒì„± ê²€ì • (ADF)
- ACF/PACF ë¶„ì„

### 2. Prophet ëª¨ë¸ (25%)
- ê¸°ë³¸ Prophet
- íœ´ì¼/ì´ë²¤íŠ¸ ì¶”ê°€
- ì„±ë¶„ ë¶„ì„

### 3. ML ëª¨ë¸ (25%)
- Lag/Rolling í”¼ì²˜
- LightGBM ë˜ëŠ” RandomForest
- TimeSeriesSplit CV

### 4. ëª¨ë¸ ë¹„êµ (15%)
- MAE, RMSE, MAPE
- ì˜ˆì¸¡ vs ì‹¤ì œ ì‹œê°í™”

### 5. ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ (15%)
- ì¬ê³  ê´€ë¦¬ ê´€ì  í•´ì„
- ì‹ ë¢° êµ¬ê°„ í™œìš© ë°©ì•ˆ

## í‰ê°€ ê¸°ì¤€

| í•­ëª© | ë°°ì  |
|------|------|
| ì‹œê³„ì—´ ë¶„ì„ | 20% |
| Prophet | 25% |
| ML ëª¨ë¸ | 25% |
| ëª¨ë¸ ë¹„êµ | 15% |
| ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ | 15% |

## ì‚°ì¶œë¬¼

- Jupyter Notebook
- ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ í‘œ
- ì˜ˆì¸¡ ì‹œê°í™”
- ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ë¬¸ì„œ
`,
      externalLinks: [
        { title: 'Store Sales Competition', url: 'https://www.kaggle.com/c/store-sales-time-series-forecasting' },
        { title: 'Prophet Documentation', url: 'https://facebook.github.io/prophet/' },
        { title: 'LightGBM Time Series', url: 'https://lightgbm.readthedocs.io/' }
      ]
    }
  },
  {
    id: 'p2w8d5t2',
    type: 'code',
    title: 'í”„ë¡œì íŠ¸ í…œí”Œë¦¿',
    duration: 90,
    content: {
      instructions: `# ìˆ˜ìš” ì˜ˆì¸¡ í”„ë¡œì íŠ¸

ì¢…í•© ì‹œê³„ì—´ ì˜ˆì¸¡ í”„ë¡œì íŠ¸ë¥¼ ì™„ì„±í•˜ì„¸ìš”.

## ì²´í¬ë¦¬ìŠ¤íŠ¸
- [ ] ì‹œê³„ì—´ ë¶„í•´
- [ ] ì •ìƒì„± ê²€ì •
- [ ] Prophet ëª¨ë¸
- [ ] ML ëª¨ë¸ (Lag í”¼ì²˜)
- [ ] ëª¨ë¸ ë¹„êµ
- [ ] ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸
`,
      starterCode: `"""
ìˆ˜ìš” ì˜ˆì¸¡ í”„ë¡œì íŠ¸
Week 16 Weekly Project (Phase 2 í¬íŠ¸í´ë¦¬ì˜¤ #2)
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import TimeSeriesSplit
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error
from statsmodels.tsa.seasonal import STL
from statsmodels.tsa.stattools import adfuller

# =============================================================================
# 1. ë°ì´í„° ë¡œë“œ
# =============================================================================
print("=== 1. ë°ì´í„° ë¡œë“œ ===")

np.random.seed(42)

# 2ë…„ ì¼ë³„ ë§¤ì¶œ ì‹œë®¬ë ˆì´ì…˜
dates = pd.date_range('2022-01-01', periods=730, freq='D')

# ë³µì¡í•œ íŒ¨í„´ ìƒì„±
trend = np.linspace(10000, 15000, 730)  # ìƒìŠ¹ ì¶”ì„¸
yearly = 2000 * np.sin(2 * np.pi * np.arange(730) / 365)  # ì—°ê°„ íŒ¨í„´
weekly = 500 * np.sin(2 * np.pi * np.arange(730) / 7)  # ì£¼ê°„ íŒ¨í„´
noise = np.random.normal(0, 500, 730)

# íŠ¹ë³„ ì´ë²¤íŠ¸ (ë¸”ë™í”„ë¼ì´ë°ì´, ì—°ë§)
event_boost = np.zeros(730)
for year in [0, 1]:
    black_friday = 325 + 365 * year  # 11ì›” ë§
    christmas = 359 + 365 * year     # 12ì›” ë§
    if black_friday < 730:
        event_boost[black_friday-3:black_friday+3] = 3000
    if christmas < 730:
        event_boost[christmas-5:christmas+2] = 4000

sales = trend + yearly + weekly + event_boost + noise
sales = np.maximum(sales, 0)  # ìŒìˆ˜ ë°©ì§€

df = pd.DataFrame({'date': dates, 'sales': sales})
df = df.set_index('date')

print(f"ê¸°ê°„: {df.index.min().date()} ~ {df.index.max().date()}")
print(f"í‰ê·  ë§¤ì¶œ: \${df['sales'].mean():,.0f}")
print(f"ì´ ë§¤ì¶œ: \${df['sales'].sum():,.0f}")

# =============================================================================
# 2. ì‹œê³„ì—´ ë¶„ì„
# =============================================================================
print("\\n=== 2. ì‹œê³„ì—´ ë¶„ì„ ===")

# TODO: ë¶„í•´, ì •ìƒì„± ê²€ì •

# =============================================================================
# 3. Prophet ëª¨ë¸
# =============================================================================
print("\\n=== 3. Prophet ëª¨ë¸ ===")

# TODO: Prophet í•™ìŠµ ë° ì˜ˆì¸¡

# =============================================================================
# 4. ML ëª¨ë¸
# =============================================================================
print("\\n=== 4. ML ëª¨ë¸ ===")

# TODO: Lag í”¼ì²˜, TimeSeriesSplit CV

# =============================================================================
# 5. ëª¨ë¸ ë¹„êµ
# =============================================================================
print("\\n=== 5. ëª¨ë¸ ë¹„êµ ===")

# TODO: MAE, RMSE, MAPE ë¹„êµ

# =============================================================================
# 6. ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸
# =============================================================================
print("\\n=== 6. ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ===")

# TODO: ì¬ê³  ê´€ë¦¬ ê´€ì  í•´ì„
`,
      solutionCode: `"""
ìˆ˜ìš” ì˜ˆì¸¡ í”„ë¡œì íŠ¸ - ì™„ì„±ë³¸
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import TimeSeriesSplit
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error
from statsmodels.tsa.seasonal import STL
from statsmodels.tsa.stattools import adfuller

# 1. ë°ì´í„° ë¡œë“œ
print("=== 1. ë°ì´í„° ë¡œë“œ ===")
np.random.seed(42)

dates = pd.date_range('2022-01-01', periods=730, freq='D')
trend = np.linspace(10000, 15000, 730)
yearly = 2000 * np.sin(2 * np.pi * np.arange(730) / 365)
weekly = 500 * np.sin(2 * np.pi * np.arange(730) / 7)
noise = np.random.normal(0, 500, 730)

event_boost = np.zeros(730)
for year in [0, 1]:
    bf = 325 + 365 * year
    xmas = 359 + 365 * year
    if bf < 730: event_boost[max(0,bf-3):min(730,bf+3)] = 3000
    if xmas < 730: event_boost[max(0,xmas-5):min(730,xmas+2)] = 4000

sales = np.maximum(trend + yearly + weekly + event_boost + noise, 0)
df = pd.DataFrame({'date': dates, 'sales': sales})
df = df.set_index('date')

print(f"ê¸°ê°„: {df.index.min().date()} ~ {df.index.max().date()}")
print(f"í‰ê· : \${df['sales'].mean():,.0f}, ë²”ìœ„: \${df['sales'].min():,.0f} ~ \${df['sales'].max():,.0f}")

# Train/Test ë¶„í•  (ë§ˆì§€ë§‰ 60ì¼ í…ŒìŠ¤íŠ¸)
train = df.iloc[:-60]
test = df.iloc[-60:]

# 2. ì‹œê³„ì—´ ë¶„ì„
print("\\n=== 2. ì‹œê³„ì—´ ë¶„ì„ ===")

# STL ë¶„í•´
stl = STL(train['sales'], period=7, robust=True)
result = stl.fit()
print(f"ì¶”ì„¸ ë³€í™”: {result.trend[-1] - result.trend[0]:,.0f}")
print(f"ê³„ì ˆì„± ë²”ìœ„: {result.seasonal.min():.0f} ~ {result.seasonal.max():.0f}")

# ADF ê²€ì •
adf_result = adfuller(train['sales'])
print(f"ADF p-value: {adf_result[1]:.4f}", end="")
print(" â†’ ë¹„ì •ìƒ" if adf_result[1] > 0.05 else " â†’ ì •ìƒ")

# 3. Prophet ìŠ¤íƒ€ì¼ ëª¨ë¸ (ëŒ€ì•ˆ êµ¬í˜„)
print("\\n=== 3. Prophet ìŠ¤íƒ€ì¼ ëª¨ë¸ ===")

# í”¼ì²˜ ìƒì„±
df_model = df.copy()
df_model['trend'] = np.arange(len(df_model))
df_model['yearly_sin'] = np.sin(2 * np.pi * df_model['trend'] / 365)
df_model['yearly_cos'] = np.cos(2 * np.pi * df_model['trend'] / 365)
df_model['weekly_sin'] = np.sin(2 * np.pi * df_model['trend'] / 7)
df_model['weekly_cos'] = np.cos(2 * np.pi * df_model['trend'] / 7)

prophet_features = ['trend', 'yearly_sin', 'yearly_cos', 'weekly_sin', 'weekly_cos']
X_train_p = df_model[prophet_features].iloc[:-60]
X_test_p = df_model[prophet_features].iloc[-60:]
y_train_p = df_model['sales'].iloc[:-60]
y_test_p = df_model['sales'].iloc[-60:]

prophet_model = LinearRegression()
prophet_model.fit(X_train_p, y_train_p)
prophet_pred = prophet_model.predict(X_test_p)

prophet_mae = mean_absolute_error(y_test_p, prophet_pred)
prophet_rmse = np.sqrt(mean_squared_error(y_test_p, prophet_pred))
prophet_mape = np.mean(np.abs((y_test_p - prophet_pred) / y_test_p)) * 100

print(f"MAE: \${prophet_mae:,.0f}")
print(f"MAPE: {prophet_mape:.2f}%")

# 4. ML ëª¨ë¸ (Lag í”¼ì²˜)
print("\\n=== 4. ML ëª¨ë¸ ===")

# Lag í”¼ì²˜
for lag in [1, 7, 14, 30]:
    df_model[f'lag_{lag}'] = df_model['sales'].shift(lag)

df_model['rolling_7_mean'] = df_model['sales'].shift(1).rolling(7).mean()
df_model['rolling_7_std'] = df_model['sales'].shift(1).rolling(7).std()

ml_features = ['lag_1', 'lag_7', 'lag_14', 'lag_30', 'rolling_7_mean', 'rolling_7_std',
               'trend', 'yearly_sin', 'yearly_cos', 'weekly_sin', 'weekly_cos']

df_clean = df_model.dropna()
X_ml = df_clean[ml_features]
y_ml = df_clean['sales']

# TimeSeriesSplit CV
tscv = TimeSeriesSplit(n_splits=5)
cv_scores = []

for train_idx, val_idx in tscv.split(X_ml):
    X_tr, X_val = X_ml.iloc[train_idx], X_ml.iloc[val_idx]
    y_tr, y_val = y_ml.iloc[train_idx], y_ml.iloc[val_idx]

    rf = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)
    rf.fit(X_tr, y_tr)
    pred = rf.predict(X_val)
    cv_scores.append(mean_absolute_error(y_val, pred))

print(f"CV MAE: \${np.mean(cv_scores):,.0f} (+/- \${np.std(cv_scores)*2:,.0f})")

# í…ŒìŠ¤íŠ¸ ì„±ëŠ¥
X_train_ml = X_ml.iloc[:-60]
X_test_ml = X_ml.iloc[-60:]
y_train_ml = y_ml.iloc[:-60]
y_test_ml = y_ml.iloc[-60:]

rf_model = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)
rf_model.fit(X_train_ml, y_train_ml)
ml_pred = rf_model.predict(X_test_ml)

ml_mae = mean_absolute_error(y_test_ml, ml_pred)
ml_rmse = np.sqrt(mean_squared_error(y_test_ml, ml_pred))
ml_mape = np.mean(np.abs((y_test_ml.values - ml_pred) / y_test_ml.values)) * 100

print(f"í…ŒìŠ¤íŠ¸ MAE: \${ml_mae:,.0f}")
print(f"í…ŒìŠ¤íŠ¸ MAPE: {ml_mape:.2f}%")

# 5. ëª¨ë¸ ë¹„êµ
print("\\n=== 5. ëª¨ë¸ ë¹„êµ ===")
comparison = pd.DataFrame({
    'Model': ['Prophet ìŠ¤íƒ€ì¼', 'ML (RandomForest)'],
    'MAE': [prophet_mae, ml_mae],
    'RMSE': [prophet_rmse, ml_rmse],
    'MAPE (%)': [prophet_mape, ml_mape]
})
print(comparison.to_string(index=False))

winner = 'ML' if ml_mae < prophet_mae else 'Prophet'
print(f"\\nâ†’ {winner} ëª¨ë¸ì´ ë” ì •í™•í•¨")

# Feature Importance
print("\\nì£¼ìš” í”¼ì²˜:")
importance = pd.DataFrame({
    'feature': ml_features,
    'importance': rf_model.feature_importances_
}).sort_values('importance', ascending=False)
for _, row in importance.head(5).iterrows():
    print(f"  {row['feature']}: {row['importance']:.3f}")

# 6. ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸
print("\\n=== 6. ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ===")
print("""
ğŸ“Š ìˆ˜ìš” ì˜ˆì¸¡ ê²°ê³¼ ìš”ì•½

1. íŒ¨í„´ ë¶„ì„:
   - ì—°ê°„ 5,000 ì¦ê°€ ì¶”ì„¸ (ì¼ í‰ê·  +13.7)
   - ì—°ë§ ì‹œì¦Œ (11-12ì›”) ë§¤ì¶œ ê¸‰ì¦ (+3,000~4,000)
   - ì£¼ê°„ íŒ¨í„´ ì¡´ì¬ (Â±500)

2. ëª¨ë¸ ì„±ëŠ¥:
   - MAPE 5% ì´í•˜ â†’ ë†’ì€ ì •í™•ë„
   - lag_1 (ì „ë‚  ë§¤ì¶œ)ì´ ê°€ì¥ ì¤‘ìš”í•œ ì˜ˆì¸¡ ë³€ìˆ˜

3. ì¬ê³  ê´€ë¦¬ ì œì•ˆ:
   - ì—°ë§ ì‹œì¦Œ 2ì£¼ ì „ ì¬ê³  30% í™•ëŒ€
   - ì£¼ë§ ì¬ê³  í‰ì¼ ëŒ€ë¹„ 10% ì¶”ê°€
   - ì•ˆì „ ì¬ê³  = ì˜ˆì¸¡ê°’ + 1.5 Ã— ì˜ˆì¸¡ í‘œì¤€í¸ì°¨

4. ì•¡ì…˜ í”Œëœ:
   - ì¼ë³„ ì˜ˆì¸¡ê°’ ê¸°ë°˜ ë°œì£¼ ì‹œìŠ¤í…œ êµ¬ì¶•
   - ì‹ ë¢°êµ¬ê°„ í™œìš©í•˜ì—¬ ìµœì†Œ/ìµœëŒ€ ì¬ê³  ìˆ˜ì¤€ ì„¤ì •
   - ì˜ˆì¸¡ ì˜¤ì°¨ ëª¨ë‹ˆí„°ë§ ë° ëª¨ë¸ ì •ê¸° ì—…ë°ì´íŠ¸
""")
`,
      hints: [
        'STLë¡œ ë¶„í•´, adfullerë¡œ ì •ìƒì„±',
        'sin/cosë¡œ ê³„ì ˆì„± ì¸ì½”ë”© (Prophet ëŒ€ì•ˆ)',
        'lag_1, lag_7ì´ ë³´í†µ ê°€ì¥ ì¤‘ìš”',
        'MAPE < 10%ë©´ ì¢‹ì€ ëª¨ë¸'
      ]
    }
  },
  {
    id: 'p2w8d5t3',
    type: 'quiz',
    title: 'Week 16 ì¢…í•© í€´ì¦ˆ',
    duration: 20,
    content: {
      questions: [
        {
          question: 'ì‹œê³„ì—´ì˜ 3ê°€ì§€ êµ¬ì„± ìš”ì†ŒëŠ”?',
          options: ['X, Y, Z', 'Trend, Seasonal, Residual', 'Mean, Median, Mode', 'Input, Hidden, Output'],
          answer: 1,
          explanation: 'ì‹œê³„ì—´ì€ Trend(ì¶”ì„¸), Seasonal(ê³„ì ˆì„±), Residual(ì”ì°¨)ì˜ ì„¸ êµ¬ì„± ìš”ì†Œë¡œ ë¶„í•´ë©ë‹ˆë‹¤. ì¶”ì„¸ëŠ” ì¥ê¸°ì  ì¦ê°, ê³„ì ˆì„±ì€ ì£¼ê¸°ì  íŒ¨í„´, ì”ì°¨ëŠ” ì„¤ëª…ë˜ì§€ ì•ŠëŠ” ë…¸ì´ì¦ˆì…ë‹ˆë‹¤. ì´ ë¶„í•´ë¥¼ í†µí•´ ê° ì„±ë¶„ì„ ë…ë¦½ì ìœ¼ë¡œ ë¶„ì„í•˜ê³  ì˜ˆì¸¡ ëª¨ë¸ì„ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.'
        },
        {
          question: 'ADF ê²€ì •ì—ì„œ p-value < 0.05ë©´?',
          options: ['ë¹„ì •ìƒ', 'ì •ìƒ', 'ê³„ì ˆì„± ìˆìŒ', 'ì¶”ì„¸ ìˆìŒ'],
          answer: 1,
          explanation: 'ADF(Augmented Dickey-Fuller) ê²€ì •ì˜ ê·€ë¬´ê°€ì„¤ì€ "ë¹„ì •ìƒ ì‹œê³„ì—´"ì…ë‹ˆë‹¤. p-value < 0.05ë©´ ê·€ë¬´ê°€ì„¤ì„ ê¸°ê°í•˜ì—¬ ì •ìƒ ì‹œê³„ì—´ì„ì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ARIMA ë“± ì „í†µ ëª¨ë¸ì€ ì •ìƒì„±ì„ ê°€ì •í•˜ë¯€ë¡œ, p > 0.05ë©´ ì°¨ë¶„ì„ í†µí•´ ì •ìƒí™”ê°€ í•„ìš”í•©ë‹ˆë‹¤.'
        },
        {
          question: 'Prophetì˜ í•„ìˆ˜ ì»¬ëŸ¼ì€?',
          options: ['date, value', 'ds, y', 'time, target', 'x, y'],
          answer: 1,
          explanation: 'Prophetì€ ds(datetime string)ì™€ y(ì˜ˆì¸¡ ëŒ€ìƒ ê°’) ë‘ ì»¬ëŸ¼ì„ í•„ìˆ˜ë¡œ ìš”êµ¬í•©ë‹ˆë‹¤. ê¸°ì¡´ ë°ì´í„°ë¥¼ rename(columns={"date": "ds", "sales": "y"})ë¡œ ë³€í™˜í•´ì•¼ í•©ë‹ˆë‹¤. ì˜ˆì¸¡ ê²°ê³¼ì—ëŠ” yhat(ì˜ˆì¸¡ê°’), yhat_lower/yhat_upper(ì‹ ë¢°êµ¬ê°„)ê°€ í¬í•¨ë©ë‹ˆë‹¤.'
        },
        {
          question: 'Lag í”¼ì²˜ì—ì„œ ë°ì´í„° ëˆ„ìˆ˜ë¥¼ ë°©ì§€í•˜ë ¤ë©´?',
          options: ['shift(0)', 'shift(-1)', 'shift(1)', 'í•„ìš” ì—†ìŒ'],
          answer: 2,
          explanation: 'shift(1)ì€ í˜„ì¬ í–‰ì— 1ì‹œì  ì´ì „(ê³¼ê±°)ì˜ ê°’ì„ ê°€ì ¸ì˜µë‹ˆë‹¤. ì˜ˆì¸¡ ì‹œì ì—ëŠ” í˜„ì¬ ì‹œì ì˜ ì‹¤ì œê°’ì„ ì•Œ ìˆ˜ ì—†ìœ¼ë¯€ë¡œ, shift(1) ì´ìƒì„ ì‚¬ìš©í•´ì•¼ ë°ì´í„° ëˆ„ìˆ˜ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤. shift(-1)ì€ ë¯¸ë˜ ê°’ì„ ê°€ì ¸ì˜¤ë¯€ë¡œ ì ˆëŒ€ ì‚¬ìš©í•˜ë©´ ì•ˆ ë©ë‹ˆë‹¤.'
        },
        {
          question: 'TimeSeriesSplitì˜ íŠ¹ì§•ì€?',
          options: ['ëœë¤ ì…”í”Œ', 'ì‹œê°„ ìˆœì„œ ë³´ì¡´', 'Stratified', 'ë™ì¼ í¬ê¸°'],
          answer: 1,
          explanation: 'TimeSeriesSplitì€ ì‹œê°„ ìˆœì„œë¥¼ ë³´ì¡´í•˜ëŠ” êµì°¨ ê²€ì¦ì…ë‹ˆë‹¤. ì¼ë°˜ KFoldëŠ” ëœë¤ ì…”í”Œë¡œ ë¯¸ë˜ ë°ì´í„°ê°€ í•™ìŠµì— í¬í•¨ë  ìˆ˜ ìˆì§€ë§Œ, TimeSeriesSplitì€ í•­ìƒ ê³¼ê±° ë°ì´í„°ë¡œ í•™ìŠµí•˜ê³  ë¯¸ë˜ ë°ì´í„°ë¡œ ê²€ì¦í•©ë‹ˆë‹¤. ì‹œê³„ì—´ì˜ ì‹œê°„ ì˜ì¡´ì„±ì„ ì˜¬ë°”ë¥´ê²Œ ë°˜ì˜í•©ë‹ˆë‹¤.'
        },
        {
          question: 'MAPE 5%ì˜ ì˜ë¯¸ëŠ”?',
          options: ['RÂ² = 0.05', 'í‰ê·  ì˜¤ì°¨ 5%', '5ì¼ í›„ ì˜ˆì¸¡', 'F1 = 0.05'],
          answer: 1,
          explanation: 'MAPE(Mean Absolute Percentage Error)ëŠ” ì˜ˆì¸¡ ì˜¤ì°¨ë¥¼ ë°±ë¶„ìœ¨ë¡œ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. MAPE 5%ëŠ” ì˜ˆì¸¡ê°’ì´ ì‹¤ì œê°’ ëŒ€ë¹„ í‰ê·  5% ì°¨ì´ê°€ ë‚œë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ MAPE < 10%ë©´ ì¢‹ì€ ëª¨ë¸, < 5%ë©´ ë§¤ìš° ì •í™•í•œ ëª¨ë¸ë¡œ í‰ê°€ë˜ë©°, ìˆ˜ìš” ì˜ˆì¸¡ì—ì„œ ë„ë¦¬ ì‚¬ìš©ë©ë‹ˆë‹¤.'
        }
      ]
    }
  },
  {
    id: 'p2w8d5t4',
    type: 'challenge',
    title: 'ì£¼ê°„ ë„ì „ê³¼ì œ: ì‹œê³„ì—´ ì˜ˆì¸¡ ëŒ€íšŒ',
    duration: 60,
    content: {
      instructions: `# ì£¼ê°„ ë„ì „ê³¼ì œ: ì‹œê³„ì—´ ì˜ˆì¸¡ ëŒ€íšŒ

## ëª©í‘œ
Kaggle Store Sales ë°ì´í„°ì…‹ìœ¼ë¡œ **ìµœê³  ì •í™•ë„ì˜ ìˆ˜ìš” ì˜ˆì¸¡ ëª¨ë¸**ì„ êµ¬ì¶•í•˜ì„¸ìš”.

## ë°ì´í„°ì…‹
**Store Sales - Time Series Forecasting** (Kaggle)
- https://www.kaggle.com/c/store-sales-time-series-forecasting
- 54ê°œ ë§¤ì¥, 33ê°œ ìƒí’ˆêµ°ì˜ ì¼ë³„ ë§¤ì¶œ
- 2013-2017ë…„ (ì•½ 170ë§Œ í–‰)
- íœ´ì¼, í”„ë¡œëª¨ì…˜, ìœ ê°€ ì •ë³´ í¬í•¨

## í‰ê°€ ê¸°ì¤€

### 1. ì‹œê³„ì—´ ë¶„ì„ (25ì )
| í•­ëª© | ì ìˆ˜ |
|------|------|
| STL ë¶„í•´ & ì‹œê°í™” | 10ì  |
| ADF ì •ìƒì„± ê²€ì • | 8ì  |
| ACF/PACF ë¶„ì„ | 7ì  |

### 2. ë‹¤ì¤‘ ëª¨ë¸ êµ¬í˜„ (35ì )
| ëª¨ë¸ | ì ìˆ˜ |
|------|------|
| Prophet (ë˜ëŠ” ëŒ€ì•ˆ êµ¬í˜„) | 15ì  |
| ML ëª¨ë¸ (Lag/Rolling í”¼ì²˜) | 15ì  |
| ì•™ìƒë¸” (ì„ íƒ) | 5ì  (ë³´ë„ˆìŠ¤) |

### 3. í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ (25ì )
| í”¼ì²˜ | ì ìˆ˜ |
|------|------|
| Lag í”¼ì²˜ (1, 7, 14, 30ì¼) | 8ì  |
| Rolling í†µê³„ (mean, std, min, max) | 8ì  |
| ì‹œê°„ í”¼ì²˜ (sin/cos ì¸ì½”ë”©) | 5ì  |
| ì™¸ë¶€ ë³€ìˆ˜ (íœ´ì¼, í”„ë¡œëª¨ì…˜) | 4ì  |

### 4. ì„±ëŠ¥ ë‹¬ì„± (15ì )
| ì§€í‘œ | ê¸°ì¤€ |
|------|------|
| MAPE < 15% | 5ì  |
| MAPE < 10% | 10ì  |
| MAPE < 5% | 15ì  |

## ì œì¶œë¬¼
1. \`sales_forecasting.ipynb\` (ì „ì²´ ì½”ë“œ)
2. ëª¨ë¸ ì„±ëŠ¥ ë¹„êµí‘œ (MAE, RMSE, MAPE)
3. Feature Importance ë¶„ì„
4. ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ (ì¬ê³  ê´€ë¦¬ ê´€ì )

## ë„ì „ íŒíŠ¸
- ë°ì´í„° ëˆ„ìˆ˜ ì£¼ì˜: Rolling í”¼ì²˜ì— shift(1) í•„ìˆ˜!
- ë§¤ì¥/ìƒí’ˆêµ°ë³„ë¡œ ê°œë³„ ëª¨ë¸ vs ì „ì²´ ëª¨ë¸ ë¹„êµ
- íœ´ì¼ ì „í›„ ë§¤ì¶œ ê¸‰ì¦ íŒ¨í„´ í™œìš©
- TimeSeriesSplitìœ¼ë¡œ ì‹œê°„ ìˆœì„œ ë³´ì¡´
`,
      starterCode: `"""
Week 16 ë„ì „ê³¼ì œ: ì‹œê³„ì—´ ì˜ˆì¸¡ ëŒ€íšŒ
Store Sales Forecasting
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import TimeSeriesSplit
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error
from statsmodels.tsa.seasonal import STL
from statsmodels.tsa.stattools import adfuller

# ============================================================
# 1. ë°ì´í„° ë¡œë“œ (Kaggleì—ì„œ ë‹¤ìš´ë¡œë“œ ë˜ëŠ” ìƒ˜í”Œ ì‚¬ìš©)
# ============================================================
print("=== 1. ë°ì´í„° ë¡œë“œ ===")

# ìƒ˜í”Œ ë°ì´í„° ìƒì„± (ì‹¤ì œëŠ” Kaggle ë°ì´í„° ì‚¬ìš©)
np.random.seed(42)
dates = pd.date_range('2022-01-01', periods=730, freq='D')

# ë³µì¡í•œ íŒ¨í„´
trend = np.linspace(10000, 15000, 730)
yearly = 2000 * np.sin(2 * np.pi * np.arange(730) / 365)
weekly = 500 * np.sin(2 * np.pi * np.arange(730) / 7)
noise = np.random.normal(0, 500, 730)

# íœ´ì¼ íš¨ê³¼
holiday_boost = np.zeros(730)
for year in [0, 1]:
    bf = 325 + 365 * year  # ë¸”ë™í”„ë¼ì´ë°ì´
    xmas = 359 + 365 * year  # í¬ë¦¬ìŠ¤ë§ˆìŠ¤
    if bf < 730: holiday_boost[max(0,bf-3):min(730,bf+3)] = 3000
    if xmas < 730: holiday_boost[max(0,xmas-5):min(730,xmas+2)] = 4000

sales = np.maximum(trend + yearly + weekly + holiday_boost + noise, 0)

df = pd.DataFrame({'date': dates, 'sales': sales})
df = df.set_index('date')

print(f"ê¸°ê°„: {df.index.min().date()} ~ {df.index.max().date()}")
print(f"í‰ê·  ë§¤ì¶œ: $" + f"{df['sales'].mean():,.0f}")

# ============================================================
# 2. ì‹œê³„ì—´ ë¶„ì„
# ============================================================
print("\\n=== 2. ì‹œê³„ì—´ ë¶„ì„ ===")

# TODO: STL ë¶„í•´, ADF ê²€ì •, ACF/PACF


# ============================================================
# 3. í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§
# ============================================================
print("\\n=== 3. í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ===")

# TODO: Lag, Rolling, ì‹œê°„ í”¼ì²˜ ìƒì„±


# ============================================================
# 4. Prophet ìŠ¤íƒ€ì¼ ëª¨ë¸
# ============================================================
print("\\n=== 4. Prophet ìŠ¤íƒ€ì¼ ëª¨ë¸ ===")

# TODO: sin/cos í”¼ì²˜ ê¸°ë°˜ ì„ í˜• ëª¨ë¸


# ============================================================
# 5. ML ëª¨ë¸ (RandomForest/LightGBM)
# ============================================================
print("\\n=== 5. ML ëª¨ë¸ ===")

# TODO: TimeSeriesSplit CV, Feature Importance


# ============================================================
# 6. ëª¨ë¸ ë¹„êµ & ì•™ìƒë¸”
# ============================================================
print("\\n=== 6. ëª¨ë¸ ë¹„êµ ===")

# TODO: MAE, RMSE, MAPE ë¹„êµ, ì•™ìƒë¸”


# ============================================================
# 7. ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸
# ============================================================
print("\\n=== 7. ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ===")

# TODO: ì¬ê³  ê´€ë¦¬ ê´€ì  í•´ì„
`,
      hints: [
        'STL(period=7, robust=True)ë¡œ ë¶„í•´',
        'shift(1).rolling()ìœ¼ë¡œ ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€',
        'TimeSeriesSplit(n_splits=5)ë¡œ ì‹œê°„ ìˆœì„œ ë³´ì¡´',
        'lag_1ì´ ë³´í†µ ê°€ì¥ ì¤‘ìš”í•œ í”¼ì²˜',
        'MAPE = mean(abs((y_true - y_pred) / y_true)) * 100',
        'íœ´ì¼ ì „í›„ íŒ¨í„´ì„ í”¼ì²˜ë¡œ ì¶”ê°€í•˜ë©´ ì„±ëŠ¥ í–¥ìƒ'
      ]
    }
  }
]
