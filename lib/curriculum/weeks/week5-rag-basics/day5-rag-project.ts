// Day 5: ë¬¸ì„œ Q&A RAG ì‹œìŠ¤í…œ ì‹¤ìŠµ

import type { Day } from '../../types'
import {
  createVideoTask,
  createReadingTask,
  createCodeTask,
  createQuizTask,
  createChallengeTask,
} from './types'

export const day5RagProject: Day = {
  slug: 'rag-project',
  title: 'ë¬¸ì„œ Q&A RAG ì‹œìŠ¤í…œ',
  totalDuration: 300,
  tasks: [
    createVideoTask('w5d5-project-overview', 'í”„ë¡œì íŠ¸ ê°œìš”', 20, {
      introduction: `
# í”„ë¡œì íŠ¸ ê°œìš”: ë¬¸ì„œ Q&A RAG ì‹œìŠ¤í…œ

## ëª©í‘œ

PDF ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ë©´ ì§ˆë¬¸ì— ë‹µí•˜ëŠ” **Q&A ì±—ë´‡**ì„ êµ¬ì¶•í•©ë‹ˆë‹¤.

## ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

\`\`\`
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ë¬¸ì„œ Q&A RAG ì‹œìŠ¤í…œ                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  [PDF ì—…ë¡œë“œ]                                                 â”‚
â”‚       â†“                                                      â”‚
â”‚  [í…ìŠ¤íŠ¸ ì¶”ì¶œ] â†’ [ì²­í‚¹] â†’ [ì„ë² ë”©] â†’ [Chroma ì €ì¥]             â”‚
â”‚                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  [ì‚¬ìš©ì ì§ˆë¬¸]                                                â”‚
â”‚       â†“                                                      â”‚
â”‚  [ì„ë² ë”©] â†’ [ìœ ì‚¬ë„ ê²€ìƒ‰] â†’ [Top-K ì²­í¬]                       â”‚
â”‚       â†“                                                      â”‚
â”‚  [í”„ë¡¬í”„íŠ¸ + ì»¨í…ìŠ¤íŠ¸] â†’ [GPT-4o-mini] â†’ [ë‹µë³€]               â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\`\`\`

## ê¸°ìˆ  ìŠ¤íƒ

| ì»´í¬ë„ŒíŠ¸ | ê¸°ìˆ  |
|----------|------|
| ë¬¸ì„œ ë¡œë”© | PyPDFLoader |
| ì²­í‚¹ | RecursiveCharacterTextSplitter |
| ì„ë² ë”© | OpenAI text-embedding-3-small |
| ë²¡í„° DB | Chroma |
| LLM | GPT-4o-mini |
| í”„ë ˆì„ì›Œí¬ | LangChain |
| UI | Streamlit |

## í•™ìŠµ ëª©í‘œ

1. PDF ë¬¸ì„œ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•
2. íš¨ê³¼ì ì¸ ì²­í‚¹ ì „ëµ ì ìš©
3. ë²¡í„° ì €ì¥ì†Œ êµ¬ì¶• ë° ê²€ìƒ‰
4. LangChain RAG ì²´ì¸ êµ¬ì„±
5. Streamlit UI ê°œë°œ
      `,
      keyPoints: ['PDF â†’ ì²­í‚¹ â†’ ì„ë² ë”© â†’ ë²¡í„° DB', 'LangChain + Chroma + OpenAI', 'Streamlitìœ¼ë¡œ ì›¹ UI'],
      practiceGoal: 'í”„ë¡œì íŠ¸ ì „ì²´ êµ¬ì¡°ë¥¼ ì´í•´í•œë‹¤',
    }),

    createCodeTask('w5d5-pdf-processing', 'PDF ë¬¸ì„œ ì²˜ë¦¬', 45, {
      introduction: `
# PDF ë¬¸ì„œ ì²˜ë¦¬

## ì„¤ì¹˜

\`\`\`bash
pip install langchain langchain-openai langchain-chroma chromadb pypdf
\`\`\`

## PDF ë¡œë”©

\`\`\`python
from langchain_community.document_loaders import PyPDFLoader

# ë‹¨ì¼ PDF ë¡œë“œ
loader = PyPDFLoader("document.pdf")
pages = loader.load()

print(f"ì´ {len(pages)} í˜ì´ì§€")
print(f"ì²« í˜ì´ì§€ ë‚´ìš©: {pages[0].page_content[:200]}...")
print(f"ë©”íƒ€ë°ì´í„°: {pages[0].metadata}")
# {'source': 'document.pdf', 'page': 0}
\`\`\`

## ì—¬ëŸ¬ PDF ë¡œë“œ

\`\`\`python
from langchain_community.document_loaders import DirectoryLoader

# í´ë” ë‚´ ëª¨ë“  PDF ë¡œë“œ
loader = DirectoryLoader(
    "./documents",
    glob="**/*.pdf",
    loader_cls=PyPDFLoader
)
all_docs = loader.load()
print(f"ì´ {len(all_docs)} í˜ì´ì§€ ë¡œë“œë¨")
\`\`\`

## í…ìŠ¤íŠ¸ ë¶„í• 

\`\`\`python
from langchain.text_splitter import RecursiveCharacterTextSplitter

splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,
    chunk_overlap=50,
    separators=["\\n\\n", "\\n", ". ", " ", ""]
)

chunks = splitter.split_documents(pages)
print(f"ì´ {len(chunks)} ì²­í¬ ìƒì„±")

# ì²­í¬ í™•ì¸
for i, chunk in enumerate(chunks[:3]):
    print(f"\\n--- ì²­í¬ {i+1} ---")
    print(f"ë‚´ìš©: {chunk.page_content[:100]}...")
    print(f"ë©”íƒ€ë°ì´í„°: {chunk.metadata}")
\`\`\`

## ë²¡í„° ì €ì¥ì†Œ ìƒì„±

\`\`\`python
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma

embeddings = OpenAIEmbeddings(model="text-embedding-3-small")

# Chroma ë²¡í„° ì €ì¥ì†Œ ìƒì„±
vectorstore = Chroma.from_documents(
    documents=chunks,
    embedding=embeddings,
    persist_directory="./chroma_db"
)

print(f"ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì™„ë£Œ: {len(chunks)} ì²­í¬")
\`\`\`

## ì „ì²´ íŒŒì´í”„ë¼ì¸

\`\`\`python
def process_pdf(pdf_path: str, persist_dir: str = "./chroma_db"):
    """PDFë¥¼ ì²˜ë¦¬í•˜ì—¬ ë²¡í„° ì €ì¥ì†Œ ìƒì„±"""

    # 1. PDF ë¡œë“œ
    loader = PyPDFLoader(pdf_path)
    pages = loader.load()
    print(f"âœ… {len(pages)} í˜ì´ì§€ ë¡œë“œ")

    # 2. ì²­í‚¹
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=500,
        chunk_overlap=50
    )
    chunks = splitter.split_documents(pages)
    print(f"âœ… {len(chunks)} ì²­í¬ ìƒì„±")

    # 3. ë²¡í„° ì €ì¥ì†Œ
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
    vectorstore = Chroma.from_documents(
        documents=chunks,
        embedding=embeddings,
        persist_directory=persist_dir
    )
    print(f"âœ… ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì™„ë£Œ")

    return vectorstore

# ì‹¤í–‰
vectorstore = process_pdf("my_document.pdf")
\`\`\`
      `,
      keyPoints: ['PyPDFLoaderë¡œ PDF ë¡œë“œ', 'RecursiveCharacterTextSplitterë¡œ ì²­í‚¹', 'Chroma.from_documentsë¡œ ë²¡í„° ì €ì¥ì†Œ'],
      practiceGoal: 'PDF ë¬¸ì„œë¥¼ ì²˜ë¦¬í•˜ì—¬ ë²¡í„° ì €ì¥ì†Œë¥¼ ìƒì„±í•œë‹¤',
    }),

    createCodeTask('w5d5-rag-chain', 'RAG ì²´ì¸ êµ¬ì„±', 45, {
      introduction: `
# RAG ì²´ì¸ êµ¬ì„±

## ê²€ìƒ‰ê¸° ì„¤ì •

\`\`\`python
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings

# ê¸°ì¡´ ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ
embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
vectorstore = Chroma(
    persist_directory="./chroma_db",
    embedding_function=embeddings
)

# ê²€ìƒ‰ê¸° ìƒì„±
retriever = vectorstore.as_retriever(
    search_type="similarity",
    search_kwargs={"k": 4}
)
\`\`\`

## RAG ì²´ì¸

\`\`\`python
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser

# LLM
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

# í”„ë¡¬í”„íŠ¸
prompt = ChatPromptTemplate.from_template("""
ë‹¹ì‹ ì€ ë¬¸ì„œ ê¸°ë°˜ Q&A ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ë‹¤ìŒ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.

ê·œì¹™:
1. ì»¨í…ìŠ¤íŠ¸ì— ìˆëŠ” ì •ë³´ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.
2. ì»¨í…ìŠ¤íŠ¸ì— ì—†ëŠ” ë‚´ìš©ì€ "ë¬¸ì„œì—ì„œ í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µí•˜ì„¸ìš”.
3. ë‹µë³€ì€ ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.
4. ê°€ëŠ¥í•˜ë©´ ë¬¸ì„œì˜ ê´€ë ¨ ë¶€ë¶„ì„ ì¸ìš©í•˜ì„¸ìš”.

ì»¨í…ìŠ¤íŠ¸:
{context}

ì§ˆë¬¸: {question}

ë‹µë³€:""")

# ì»¨í…ìŠ¤íŠ¸ í¬ë§¤íŒ…
def format_docs(docs):
    return "\\n\\n---\\n\\n".join(
        f"[ì¶œì²˜: {doc.metadata.get('source', 'Unknown')}, í˜ì´ì§€: {doc.metadata.get('page', 'N/A')}]\\n{doc.page_content}"
        for doc in docs
    )

# RAG ì²´ì¸
rag_chain = (
    {"context": retriever | format_docs, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)
\`\`\`

## ì¶œì²˜ í¬í•¨ RAG

\`\`\`python
from langchain_core.runnables import RunnableParallel

# ì¶œì²˜ì™€ ë‹µë³€ ëª¨ë‘ ë°˜í™˜
rag_with_sources = RunnableParallel(
    answer=rag_chain,
    sources=retriever
)

result = rag_with_sources.invoke("ì£¼ìš” ë‚´ìš©ì´ ë­ì•¼?")
print(f"ë‹µë³€: {result['answer']}")
print(f"\\nì¶œì²˜:")
for doc in result['sources']:
    print(f"  - {doc.metadata}")
\`\`\`

## Q&A í•¨ìˆ˜

\`\`\`python
def ask_question(question: str, show_sources: bool = False):
    """ë¬¸ì„œì— ëŒ€í•œ ì§ˆë¬¸ì— ë‹µë³€"""

    if show_sources:
        result = rag_with_sources.invoke(question)
        answer = result['answer']
        sources = result['sources']

        print(f"Q: {question}")
        print(f"A: {answer}")
        print(f"\\nğŸ“š ì°¸ì¡° ë¬¸ì„œ:")
        for doc in sources:
            src = doc.metadata.get('source', 'Unknown')
            page = doc.metadata.get('page', 'N/A')
            print(f"  - {src}, í˜ì´ì§€ {page}")
    else:
        answer = rag_chain.invoke(question)
        print(f"Q: {question}")
        print(f"A: {answer}")

    return answer

# í…ŒìŠ¤íŠ¸
ask_question("ì´ ë¬¸ì„œì˜ í•µì‹¬ ë‚´ìš©ì€ ë¬´ì—‡ì¸ê°€ìš”?", show_sources=True)
\`\`\`
      `,
      keyPoints: ['ê²€ìƒ‰ê¸° + í”„ë¡¬í”„íŠ¸ + LLM ì²´ì¸', 'format_docsë¡œ ì¶œì²˜ ì •ë³´ í¬í•¨', 'RunnableParallelë¡œ ë‹µë³€ + ì¶œì²˜'],
      practiceGoal: 'ì¶œì²˜ë¥¼ í¬í•¨í•œ RAG ì²´ì¸ì„ êµ¬ì„±í•œë‹¤',
    }),

    createCodeTask('w5d5-streamlit-ui', 'Streamlit UI ê°œë°œ', 50, {
      introduction: `
# Streamlit UI ê°œë°œ

## ì„¤ì¹˜

\`\`\`bash
pip install streamlit
\`\`\`

## ê¸°ë³¸ ì•± êµ¬ì¡°

\`\`\`python
# app.py
import streamlit as st
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
import tempfile
import os

st.set_page_config(page_title="ğŸ“š ë¬¸ì„œ Q&A", page_icon="ğŸ“š")
st.title("ğŸ“š ë¬¸ì„œ Q&A ì‹œìŠ¤í…œ")

# ì‚¬ì´ë“œë°”: API í‚¤ ì…ë ¥
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    api_key = st.text_input("OpenAI API Key", type="password")
    if api_key:
        os.environ["OPENAI_API_KEY"] = api_key

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "vectorstore" not in st.session_state:
    st.session_state.vectorstore = None
if "messages" not in st.session_state:
    st.session_state.messages = []

# PDF ì—…ë¡œë“œ
uploaded_file = st.file_uploader("PDF íŒŒì¼ ì—…ë¡œë“œ", type="pdf")

if uploaded_file and api_key:
    if st.button("ë¬¸ì„œ ì²˜ë¦¬"):
        with st.spinner("ë¬¸ì„œ ì²˜ë¦¬ ì¤‘..."):
            # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
            with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
                tmp.write(uploaded_file.getvalue())
                tmp_path = tmp.name

            # PDF ë¡œë“œ ë° ì²˜ë¦¬
            loader = PyPDFLoader(tmp_path)
            pages = loader.load()

            splitter = RecursiveCharacterTextSplitter(
                chunk_size=500, chunk_overlap=50
            )
            chunks = splitter.split_documents(pages)

            embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
            st.session_state.vectorstore = Chroma.from_documents(
                chunks, embeddings
            )

            os.unlink(tmp_path)  # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            st.success(f"âœ… {len(pages)} í˜ì´ì§€, {len(chunks)} ì²­í¬ ì²˜ë¦¬ ì™„ë£Œ!")

# ëŒ€í™” ì¸í„°í˜ì´ìŠ¤
if st.session_state.vectorstore:
    # ëŒ€í™” íˆìŠ¤í† ë¦¬ í‘œì‹œ
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.write(msg["content"])

    # ì‚¬ìš©ì ì…ë ¥
    if question := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”"):
        st.session_state.messages.append({"role": "user", "content": question})
        with st.chat_message("user"):
            st.write(question)

        # RAG ì‹¤í–‰
        with st.chat_message("assistant"):
            with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                retriever = st.session_state.vectorstore.as_retriever(
                    search_kwargs={"k": 4}
                )
                llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

                prompt = ChatPromptTemplate.from_template("""
                ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.
                ì»¨í…ìŠ¤íŠ¸ì— ì—†ìœ¼ë©´ "ë¬¸ì„œì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  í•˜ì„¸ìš”.

                ì»¨í…ìŠ¤íŠ¸: {context}
                ì§ˆë¬¸: {question}
                ë‹µë³€:""")

                def format_docs(docs):
                    return "\\n\\n".join(d.page_content for d in docs)

                chain = (
                    {"context": retriever | format_docs, "question": RunnablePassthrough()}
                    | prompt | llm | StrOutputParser()
                )

                answer = chain.invoke(question)
                st.write(answer)
                st.session_state.messages.append({"role": "assistant", "content": answer})
else:
    st.info("ğŸ‘† PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  'ë¬¸ì„œ ì²˜ë¦¬' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")
\`\`\`

## ì‹¤í–‰

\`\`\`bash
streamlit run app.py
\`\`\`

ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:8501 ì ‘ì†
      `,
      keyPoints: ['st.file_uploaderë¡œ PDF ì—…ë¡œë“œ', 'st.session_stateë¡œ ìƒíƒœ ê´€ë¦¬', 'st.chat_messageë¡œ ëŒ€í™” UI'],
      practiceGoal: 'Streamlitìœ¼ë¡œ RAG ì›¹ ì•±ì„ ê°œë°œí•œë‹¤',
    }),

    createReadingTask('w5d5-deployment', 'ë°°í¬ ë° ìµœì í™”', 30, {
      introduction: `
# ë°°í¬ ë° ìµœì í™”

## 1. í™˜ê²½ ë³€ìˆ˜ ê´€ë¦¬

\`\`\`python
# .env íŒŒì¼
OPENAI_API_KEY=sk-...

# ì½”ë“œì—ì„œ ë¡œë“œ
from dotenv import load_dotenv
load_dotenv()
\`\`\`

## 2. ë²¡í„° ì €ì¥ì†Œ ìµœì í™”

\`\`\`python
# ì˜êµ¬ ì €ì¥
vectorstore = Chroma.from_documents(
    documents=chunks,
    embedding=embeddings,
    persist_directory="./chroma_db"  # ì˜êµ¬ ì €ì¥
)

# ë¡œë“œ
vectorstore = Chroma(
    persist_directory="./chroma_db",
    embedding_function=embeddings
)
\`\`\`

## 3. ìºì‹±

\`\`\`python
import streamlit as st

@st.cache_resource
def load_vectorstore():
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
    return Chroma(
        persist_directory="./chroma_db",
        embedding_function=embeddings
    )
\`\`\`

## 4. Streamlit Cloud ë°°í¬

\`\`\`
1. GitHub ì €ì¥ì†Œ ìƒì„±
2. requirements.txt ì‘ì„±:
   langchain
   langchain-openai
   langchain-chroma
   chromadb
   pypdf
   streamlit
   python-dotenv

3. streamlit.ioì—ì„œ ë°°í¬
4. Secretsì— API í‚¤ ì„¤ì •
\`\`\`

## 5. ë¹„ìš© ìµœì í™”

| í•­ëª© | ìµœì í™” ë°©ë²• |
|------|------------|
| ì„ë² ë”© | text-embedding-3-small ì‚¬ìš© |
| LLM | gpt-4o-mini ì‚¬ìš© |
| ìºì‹± | ë™ì¼ ì§ˆë¬¸ ìºì‹± |
| ì²­í¬ | ì ì ˆí•œ í¬ê¸°ë¡œ í† í° ì ˆì•½ |

## 6. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

\`\`\`python
import time

def timed_query(question: str):
    start = time.time()
    answer = rag_chain.invoke(question)
    elapsed = time.time() - start
    print(f"ì‘ë‹µ ì‹œê°„: {elapsed:.2f}ì´ˆ")
    return answer
\`\`\`
      `,
      keyPoints: ['í™˜ê²½ ë³€ìˆ˜ë¡œ API í‚¤ ê´€ë¦¬', 'Streamlit Cloudë¡œ ë¬´ë£Œ ë°°í¬', 'ìºì‹±ê³¼ ì ì ˆí•œ ëª¨ë¸ë¡œ ë¹„ìš© ì ˆì•½'],
      practiceGoal: 'RAG ì‹œìŠ¤í…œì„ ë°°í¬í•˜ê³  ìµœì í™”í•œë‹¤',
    }),

    createQuizTask('w5d5-quiz', 'Day 5 ë³µìŠµ í€´ì¦ˆ', 15, {
      introduction: '# Day 5 ë³µìŠµ í€´ì¦ˆ',
      questions: [
        {
          id: 'w5d5-q1',
          question: 'PyPDFLoaderì˜ ì—­í• ì€?',
          options: ['PDF ìƒì„±', 'PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ', 'PDF ì••ì¶•', 'PDF ì•”í˜¸í™”'],
          correctAnswer: 1,
          explanation: 'PyPDFLoaderëŠ” PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.',
        },
        {
          id: 'w5d5-q2',
          question: 'Streamlitì˜ st.session_state ìš©ë„ëŠ”?',
          options: ['íŒŒì¼ ì €ì¥', 'ì„¸ì…˜ ê°„ ìƒíƒœ ìœ ì§€', 'ë„¤íŠ¸ì›Œí¬ í†µì‹ ', 'ë¡œê·¸ ê¸°ë¡'],
          correctAnswer: 1,
          explanation: 'st.session_stateëŠ” ì‚¬ìš©ì ì„¸ì…˜ ë™ì•ˆ ìƒíƒœ(ë²¡í„° ì €ì¥ì†Œ, ëŒ€í™” íˆìŠ¤í† ë¦¬ ë“±)ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.',
        },
        {
          id: 'w5d5-q3',
          question: 'RAG ë¹„ìš© ìµœì í™” ë°©ë²•ìœ¼ë¡œ ì ì ˆí•˜ì§€ ì•Šì€ ê²ƒì€?',
          options: ['text-embedding-3-small ì‚¬ìš©', 'gpt-4o-mini ì‚¬ìš©', 'ì²­í¬ í¬ê¸° ë¬´í•œëŒ€ë¡œ', 'ë™ì¼ ì§ˆë¬¸ ìºì‹±'],
          correctAnswer: 2,
          explanation: 'ì²­í¬ í¬ê¸°ë¥¼ ë¬´í•œëŒ€ë¡œ í•˜ë©´ í† í° ì‚¬ìš©ëŸ‰ì´ ì¦ê°€í•˜ì—¬ ë¹„ìš©ì´ ëŠ˜ì–´ë‚©ë‹ˆë‹¤.',
        },
      ],
      keyPoints: ['PyPDFLoader = PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ', 'session_state = ì„¸ì…˜ ìƒíƒœ ìœ ì§€', 'ì ì ˆí•œ ì²­í¬ í¬ê¸°ë¡œ ë¹„ìš© ì ˆì•½'],
      practiceGoal: 'RAG í”„ë¡œì íŠ¸ ê°œë…ì„ í™•ì¸í•œë‹¤',
    }),
  ],

  challenge: createChallengeTask('w5d5-challenge', 'Challenge: ë‚˜ë§Œì˜ ë¬¸ì„œ Q&A ì„œë¹„ìŠ¤', 75, {
    introduction: `
# Challenge: ë‚˜ë§Œì˜ ë¬¸ì„œ Q&A ì„œë¹„ìŠ¤

## ê³¼ì œ

ì‹¤ì œ ì‚¬ìš© ê°€ëŠ¥í•œ ë¬¸ì„œ Q&A ì„œë¹„ìŠ¤ë¥¼ ì™„ì„±í•˜ì„¸ìš”.

## ê¸°ë³¸ ìš”êµ¬ì‚¬í•­

1. **PDF ì—…ë¡œë“œ & ì²˜ë¦¬**
   - ì—¬ëŸ¬ PDF ì—…ë¡œë“œ ì§€ì›
   - ì²˜ë¦¬ ì§„í–‰ ìƒí™© í‘œì‹œ

2. **RAG ì²´ì¸**
   - ìœ ì‚¬ë„ ê²€ìƒ‰
   - ì¶œì²˜ í‘œì‹œ
   - ëŒ€í™” íˆìŠ¤í† ë¦¬ ìœ ì§€

3. **Streamlit UI**
   - ê¹”ë”í•œ ì¸í„°í˜ì´ìŠ¤
   - ì—ëŸ¬ ì²˜ë¦¬

## ë³´ë„ˆìŠ¤ ìš”êµ¬ì‚¬í•­ (ì„ íƒ)

1. **ê²€ìƒ‰ ìµœì í™”**
   - MMR ê²€ìƒ‰ ì ìš©
   - Re-ranking ì¶”ê°€

2. **ë‹¤ì¤‘ ë¬¸ì„œ ë¹„êµ**
   - "ë¬¸ì„œ Aì™€ Bì˜ ì°¨ì´ì ì€?"

3. **ë‚´ë³´ë‚´ê¸°**
   - ëŒ€í™” ë‚´ì—­ ë‹¤ìš´ë¡œë“œ

## ì œì¶œë¬¼

- GitHub ì €ì¥ì†Œ ë§í¬
- README.md (ì„¤ì¹˜ ë°©ë²•, ìŠ¤í¬ë¦°ìƒ·)
- (ì„ íƒ) ë°°í¬ëœ URL

## í‰ê°€ ê¸°ì¤€

| í•­ëª© | ë°°ì  |
|------|------|
| ê¸°ë³¸ ê¸°ëŠ¥ ë™ì‘ | 40% |
| ì½”ë“œ í’ˆì§ˆ | 20% |
| UI/UX | 20% |
| ë³´ë„ˆìŠ¤ ê¸°ëŠ¥ | 20% |
    `,
    keyPoints: ['ì „ì²´ RAG íŒŒì´í”„ë¼ì¸ êµ¬ì¶•', 'Streamlit ì›¹ ì•± ì™„ì„±', 'GitHub ì €ì¥ì†Œë¡œ ì œì¶œ'],
    practiceGoal: 'ì‹¤ì œ ì‚¬ìš© ê°€ëŠ¥í•œ RAG ì„œë¹„ìŠ¤ë¥¼ ì™„ì„±í•œë‹¤',
  }),
}
