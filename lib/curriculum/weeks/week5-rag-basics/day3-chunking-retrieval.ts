// Day 3: ì²­í‚¹ ì „ëµ & ê²€ìƒ‰ ìµœì í™” - ì™„ì „ ë¦¬ë‰´ì–¼ ë²„ì „

import type { Day } from '../../types'
import {
  createVideoTask,
  createReadingTask,
  createCodeTask,
  createQuizTask,
  createChallengeTask,
} from './types'

export const day3ChunkingRetrieval: Day = {
  slug: 'chunking-retrieval',
  title: 'ì²­í‚¹ ì „ëµ & ê²€ìƒ‰ ìµœì í™”',
  totalDuration: 300, // 5ì‹œê°„
  tasks: [
    // ========================================
    // Task 1: ì²­í‚¹ì˜ ê³¼í•™ - ì´ë¡ ê³¼ ì›ë¦¬ (40ë¶„)
    // ========================================
    createVideoTask('w5d3-chunking-science', 'ì²­í‚¹ì˜ ê³¼í•™ - ì´ë¡ ê³¼ ì›ë¦¬', 40, {
      introduction: `
## í•™ìŠµ ëª©í‘œ
- ì²­í‚¹ì´ RAG ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì´í•´í•œë‹¤
- "Lost in the Middle" í˜„ìƒê³¼ í•´ê²°ì±…ì„ í•™ìŠµí•œë‹¤
- ìµœì ì˜ ì²­í¬ í¬ê¸°ë¥¼ ê²°ì •í•˜ëŠ” ê³¼í•™ì  ê·¼ê±°ë¥¼ ì´í•´í•œë‹¤

---

## ì²­í‚¹ì´ RAG ì„±ëŠ¥ì„ ê²°ì •í•œë‹¤

### RAG íŒŒì´í”„ë¼ì¸ì—ì„œ ì²­í‚¹ì˜ ìœ„ì¹˜

\`\`\`
ë¬¸ì„œ ìˆ˜ì§‘ â†’ [ì²­í‚¹] â†’ ì„ë² ë”© â†’ ì €ì¥ â†’ ê²€ìƒ‰ â†’ ìƒì„±

ì²­í‚¹ì´ ì˜ëª»ë˜ë©´:
- ì„ë² ë”© í’ˆì§ˆ ì €í•˜ (ì“°ë ˆê¸° ë„£ìœ¼ë©´ ì“°ë ˆê¸° ë‚˜ì˜¨ë‹¤)
- ê²€ìƒ‰ ì •í™•ë„ ì €í•˜
- ìƒì„± í’ˆì§ˆ ì €í•˜ â†’ í™˜ê° ì¦ê°€
\`\`\`

### ì²­í‚¹ì´ ì¤‘ìš”í•œ ì´ìœ 

**1. ì„ë² ë”© í’ˆì§ˆ ê²°ì •**

\`\`\`
ì²­í¬ê°€ ë„ˆë¬´ ì‘ìœ¼ë©´:
  "RAGëŠ” ê²€ìƒ‰ ì¦ê°•" â†’ ì˜ë¯¸ ë¶ˆì™„ì „
  ì„ë² ë”©ì´ ì „ì²´ ë¬¸ë§¥ì„ í‘œí˜„ ëª»í•¨

ì²­í¬ê°€ ë„ˆë¬´ í¬ë©´:
  "RAGëŠ”... (1000ì)... ê·¸ë˜ì„œ ë²¡í„° DB..." â†’ ë„ˆë¬´ ë§ì€ ì£¼ì œ
  ì„ë² ë”©ì´ í¬ì„ë¨ (ì–´ë–¤ ì£¼ì œë„ ì˜ í‘œí˜„ ëª»í•¨)
\`\`\`

**2. ê²€ìƒ‰ ì •ë°€ë„ ê²°ì •**

\`\`\`
ì ì ˆí•œ ì²­í¬:
  ì¿¼ë¦¬: "RAGì˜ ê²€ìƒ‰ ë‹¨ê³„"
  ë§¤ì¹­: [RAG ê²€ìƒ‰ ë‹¨ê³„ ì„¤ëª… ì²­í¬] â† ì •í™•íˆ ì›í•˜ëŠ” ë‚´ìš©

ë¶€ì ì ˆí•œ ì²­í¬:
  ì¿¼ë¦¬: "RAGì˜ ê²€ìƒ‰ ë‹¨ê³„"
  ë§¤ì¹­: [RAG ì „ì²´ ì„¤ëª…... ê²€ìƒ‰... ìƒì„±... í‰ê°€...] â† ë¶ˆí•„ìš”í•œ ë‚´ìš© í¬í•¨
\`\`\`

**3. ì»¨í…ìŠ¤íŠ¸ íš¨ìœ¨ì„± ê²°ì •**

\`\`\`
LLM ì»¨í…ìŠ¤íŠ¸ ì°½: 128K í† í° (GPT-4o ê¸°ì¤€)

ì²­í¬ 500ì Ã— 5ê°œ = 2,500ì â†’ íš¨ìœ¨ì 
ì²­í¬ 2000ì Ã— 5ê°œ = 10,000ì â†’ ë¹„íš¨ìœ¨ì  (ë¹„ìš© 4ë°°, ë…¸ì´ì¦ˆ ì¦ê°€)
\`\`\`

---

## "Lost in the Middle" í˜„ìƒ

### 2023ë…„ ìŠ¤íƒ í¬ë“œ ì—°êµ¬ ë°œê²¬

\`\`\`
ë…¼ë¬¸: "Lost in the Middle: How Language Models Use Long Contexts"

ì‹¤í—˜: ì •ë‹µì´ ì»¨í…ìŠ¤íŠ¸ì˜ ë‹¤ë¥¸ ìœ„ì¹˜ì— ìˆì„ ë•Œ ì„±ëŠ¥ ì¸¡ì •

ê²°ê³¼:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ì •í™•ë„                                         â”‚
â”‚ 100% â”¤ â—                               â—      â”‚
â”‚  80% â”¤   â—                           â—        â”‚
â”‚  60% â”¤     â—     â—     â—     â—     â—          â”‚
â”‚  40% â”¤       â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—                â”‚
â”‚  20% â”¤                                        â”‚
â”‚   0% â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚       ì²˜ìŒ      â† ì¤‘ê°„ â†’      ë              â”‚
â”‚                 ìœ„ì¹˜                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ì •ë‹µì´ ì²˜ìŒì´ë‚˜ ëì— ìˆìœ¼ë©´ ì˜ ì°¾ì§€ë§Œ,
ì¤‘ê°„ì— ìˆìœ¼ë©´ "ìƒì–´ë²„ë¦°ë‹¤" (Lost in the Middle)
\`\`\`

### RAGì—ì„œì˜ ì‹œì‚¬ì 

\`\`\`
ë¬¸ì œ:
- ê´€ë ¨ ì²­í¬ 5ê°œë¥¼ ê²€ìƒ‰í•´ì„œ LLMì— ì „ë‹¬
- ê°€ì¥ ì¤‘ìš”í•œ ì²­í¬ê°€ ì¤‘ê°„ì— ìœ„ì¹˜í•˜ë©´ ë¬´ì‹œë  ìˆ˜ ìˆìŒ

í•´ê²°ì±…:
1. ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê´€ë ¨ì„± ì—­ìˆœìœ¼ë¡œ ì •ë ¬ (ì¤‘ìš”í•œ ê²ƒì„ ì²˜ìŒê³¼ ëì—)
2. ì ì€ ìˆ˜ì˜ ê³ í’ˆì§ˆ ì²­í¬ ì‚¬ìš© (5ê°œ ì´í•˜)
3. ì²­í¬ í¬ê¸° ìµœì í™” (ë¶ˆí•„ìš”í•œ ë‚´ìš© ì œê±°)
\`\`\`

---

## ìµœì ì˜ ì²­í¬ í¬ê¸°: ê³¼í•™ì  ì ‘ê·¼

### ì²­í¬ í¬ê¸° ì—°êµ¬ ê²°ê³¼

\`\`\`
Pinecone Research (2023):

í…ŒìŠ¤íŠ¸: ë‹¤ì–‘í•œ ì²­í¬ í¬ê¸°ë¡œ RAG ì„±ëŠ¥ ì¸¡ì •
ë°ì´í„°ì…‹: SQuAD, Natural Questions

ê²°ê³¼:
- 512 í† í°: ê°€ì¥ ì¢‹ì€ ê²€ìƒ‰ ì •í™•ë„
- 256 í† í°: ê²€ìƒ‰ì€ ì¢‹ì§€ë§Œ ì»¨í…ìŠ¤íŠ¸ ë¶€ì¡±
- 1024 í† í°: ì»¨í…ìŠ¤íŠ¸ í’ë¶€í•˜ì§€ë§Œ ê²€ìƒ‰ ì •í™•ë„ ì €í•˜
\`\`\`

### ë¬¸ì„œ ìœ í˜•ë³„ ìµœì  ì²­í¬ í¬ê¸°

\`\`\`python
# ì²­í¬ í¬ê¸° ê°€ì´ë“œë¼ì¸ (í† í° ê¸°ì¤€)
CHUNK_SIZE_GUIDE = {
    # êµ¬ì¡°í™”ëœ ë¬¸ì„œ
    "technical_docs": {
        "chunk_size": 512,      # ~2000ì (í•œêµ­ì–´)
        "chunk_overlap": 50,    # 10%
        "reason": "ê°œë… ë‹¨ìœ„ ë³´ì¡´, ê²€ìƒ‰ ì •í™•ë„ ìµœì "
    },

    # ëŒ€í™”í˜• ì½˜í…ì¸ 
    "chat_logs": {
        "chunk_size": 256,      # ~1000ì
        "chunk_overlap": 25,
        "reason": "ì§§ì€ ë°œí™” ë‹¨ìœ„, ë¬¸ë§¥ ì—°ê²°"
    },

    # ë²•ë¥ /ê³„ì•½ ë¬¸ì„œ
    "legal_docs": {
        "chunk_size": 1024,     # ~4000ì
        "chunk_overlap": 100,
        "reason": "ì¡°í•­ ë‹¨ìœ„ ë³´ì¡´, ë§¥ë½ ìœ ì§€"
    },

    # ì½”ë“œ
    "source_code": {
        "chunk_size": "function",  # í•¨ìˆ˜ ë‹¨ìœ„
        "chunk_overlap": 0,
        "reason": "ë…¼ë¦¬ì  ë‹¨ìœ„ ë³´ì¡´"
    },

    # Q&A
    "faq": {
        "chunk_size": "qa_pair",   # ì§ˆë¬¸+ë‹µë³€ ìŒ
        "chunk_overlap": 0,
        "reason": "ì˜ë¯¸ ë‹¨ìœ„ ë³´ì¡´"
    }
}
\`\`\`

### ì²­í¬ í¬ê¸° ì„ íƒ í”„ë ˆì„ì›Œí¬

\`\`\`
Step 1: ë¬¸ì„œ íŠ¹ì„± ë¶„ì„
  - í‰ê·  ë¬¸ì¥ ê¸¸ì´
  - ë‹¨ë½ êµ¬ì¡°
  - ì£¼ì œ ë°€ë„ (í•œ ë‹¨ë½ì— ëª‡ ê°œ ì£¼ì œ?)

Step 2: ì‚¬ìš© ì‚¬ë¡€ ê³ ë ¤
  - ì§ˆë¬¸ ìœ í˜• (ì‚¬ì‹¤ í™•ì¸ vs ìš”ì•½ vs ë¶„ì„)
  - ì •í™•ë„ vs ì»¨í…ìŠ¤íŠ¸ trade-off
  - ë¹„ìš© ì œì•½

Step 3: ì‹¤í—˜ ë° í‰ê°€
  - A/B í…ŒìŠ¤íŠ¸
  - ê²€ìƒ‰ ì •í™•ë„ ì¸¡ì •
  - ì‘ë‹µ í’ˆì§ˆ í‰ê°€
\`\`\`

---

## Overlap(ì¤‘ì²©)ì˜ ì—­í• 

### Overlapì´ í•„ìš”í•œ ì´ìœ 

\`\`\`
Overlap ì—†ì´ ë¶„í• :
  ì²­í¬1: "RAGëŠ” ê²€ìƒ‰ ì¦ê°• ìƒì„±ì…ë‹ˆë‹¤. ì´ ê¸°ìˆ ì€"
  ì²­í¬2: "LLMì˜ í™˜ê°ì„ ì¤„ì—¬ì¤ë‹ˆë‹¤. ì™¸ë¶€ ì§€ì‹ì„"

  â†’ "ì´ ê¸°ìˆ ì€"ì´ ë¬´ì—‡ì„ ê°€ë¦¬í‚¤ëŠ”ì§€ ì•Œ ìˆ˜ ì—†ìŒ
  â†’ ë¬¸ë§¥ ë‹¨ì ˆ

Overlapìœ¼ë¡œ ë¶„í• :
  ì²­í¬1: "RAGëŠ” ê²€ìƒ‰ ì¦ê°• ìƒì„±ì…ë‹ˆë‹¤. ì´ ê¸°ìˆ ì€ LLMì˜"
  ì²­í¬2: "ì´ ê¸°ìˆ ì€ LLMì˜ í™˜ê°ì„ ì¤„ì—¬ì¤ë‹ˆë‹¤. ì™¸ë¶€ ì§€ì‹ì„"

  â†’ ì¤‘ì²©ëœ ë¶€ë¶„ì´ ë¬¸ë§¥ì„ ì—°ê²°
  â†’ ì˜ë¯¸ ë³´ì¡´
\`\`\`

### ìµœì ì˜ Overlap ë¹„ìœ¨

\`\`\`python
# ì—°êµ¬ ê¸°ë°˜ ê¶Œì¥ê°’
def calculate_overlap(chunk_size: int, doc_type: str) -> int:
    """ë¬¸ì„œ ìœ í˜•ì— ë”°ë¥¸ ìµœì  overlap ê³„ì‚°"""

    ratios = {
        "narrative": 0.15,     # ì„œì‚¬í˜• (15%)
        "technical": 0.10,     # ê¸°ìˆ  ë¬¸ì„œ (10%)
        "structured": 0.05,    # êµ¬ì¡°í™”ëœ ë¬¸ì„œ (5%)
        "qa_pairs": 0.0,       # Q&A (0%)
    }

    ratio = ratios.get(doc_type, 0.10)
    return int(chunk_size * ratio)

# ì˜ˆì‹œ
overlap = calculate_overlap(500, "technical")  # 50ì
\`\`\`
      `,
      keyPoints: [
        'ì²­í‚¹ í’ˆì§ˆì´ RAG ì „ì²´ ì„±ëŠ¥ì„ ê²°ì •í•œë‹¤',
        'Lost in the Middle: ì¤‘ê°„ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì†ì‹¤ í˜„ìƒ',
        '512 í† í°(~2000ì)ì´ ëŒ€ë¶€ë¶„ ìµœì , Overlap 10-15%',
      ],
      practiceGoal: 'ì²­í‚¹ì˜ ê³¼í•™ì  ì›ë¦¬ì™€ ìµœì í™” ì „ëµì„ ì´í•´í•œë‹¤',
    }),

    // ========================================
    // Task 2: ì²­í‚¹ ì „ëµ ì‹¬ì¸µ ì‹¤ìŠµ (50ë¶„)
    // ========================================
    createCodeTask('w5d3-chunking-strategies', 'ì²­í‚¹ ì „ëµ ì‹¬ì¸µ ì‹¤ìŠµ', 50, {
      introduction: `
## ì™œ ë°°ìš°ëŠ”ê°€?

**ë¬¸ì œ**: RAGë¥¼ ì²˜ìŒ ë§Œë“¤ë©´ "ê·¸ëƒ¥ 500ìë¡œ ìë¥´ë©´ ë˜ì§€ ì•Šë‚˜?" ì‹¶ì§€ë§Œ, ì‹¤ì œë¡œëŠ” ê²€ìƒ‰ ì •í™•ë„ê°€ 60%ë„ ì•ˆ ë‚˜ì˜µë‹ˆë‹¤.
- ë¬¸ì¥ ì¤‘ê°„ì—ì„œ ì˜ë¦¼ â†’ ì˜ë¯¸ ì†ì‹¤
- ì¤‘ìš”í•œ ì •ë³´ê°€ ë¶„ì‚°ë¨
- ì½”ë“œ/í‘œê°€ ê¹¨ì§

**í•´ê²°**: ë¬¸ì„œ ìœ í˜•ê³¼ ëª©ì ì— ë§ëŠ” ì²­í‚¹ ì „ëµì„ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.

---

## ë¹„ìœ : ì²­í‚¹ = ì±…ì„ ì–´ë–»ê²Œ ë‚˜ëˆŒ ê²ƒì¸ê°€?

\`\`\`
ê³ ì • í¬ê¸° ì²­í‚¹ = 500ìë§ˆë‹¤ ìë¥´ê¸°
- ì¥: "ì˜¤ëŠ˜ì€ ë‚ ì”¨ê°€ ì¢‹"
- ë‹¨ì : ë¬¸ì¥ ì¤‘ê°„ì—ì„œ ëŠê¹€ âŒ

ì¬ê·€ì  ì²­í‚¹ = ë‹¨ë½ â†’ ë¬¸ì¥ â†’ ë‹¨ì–´ ìˆœìœ¼ë¡œ ë‚˜ëˆ„ê¸°
- ì¥: "ì˜¤ëŠ˜ì€ ë‚ ì”¨ê°€ ì¢‹ìŠµë‹ˆë‹¤."
- ì¥ì : ì˜ë¯¸ ë‹¨ìœ„ ë³´ì¡´ âœ…

ì˜ë¯¸ì  ì²­í‚¹ = AIê°€ ì£¼ì œ ë°”ë€ŒëŠ” ê³³ì—ì„œ ë‚˜ëˆ„ê¸°
- ì¥: "ì˜¤ëŠ˜ì€ ë‚ ì”¨ê°€ ì¢‹ìŠµë‹ˆë‹¤. ë‚´ì¼ íšŒì˜ê°€ ìˆìŠµë‹ˆë‹¤."
- ì¥ì : ì£¼ì œë³„ë¡œ ì •í™•íˆ êµ¬ë¶„ âœ…âœ…
\`\`\`

---

## í•µì‹¬ êµ¬í˜„ (ê°„ì†Œí™”)

\`\`\`python
# ğŸ“Œ Step 1: ì¬ê·€ì  ì²­í‚¹ (ê°€ì¥ ê¶Œì¥)
from langchain.text_splitter import RecursiveCharacterTextSplitter

splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,
    chunk_overlap=50,
    separators=["\\n\\n", "\\n", ".", " "]  # ìš°ì„ ìˆœìœ„ëŒ€ë¡œ ì‹œë„
)

chunks = splitter.split_text("ê¸´ ë¬¸ì„œ...")
print(f"ìƒì„±ëœ ì²­í¬: {len(chunks)}ê°œ")

# ğŸ“Œ Step 2: ì˜ë¯¸ì  ì²­í‚¹ (ìµœê³  í’ˆì§ˆ, ëŠë¦¼)
from langchain_experimental.text_splitter import SemanticChunker
from langchain_openai import OpenAIEmbeddings

semantic_splitter = SemanticChunker(
    embeddings=OpenAIEmbeddings(),
    breakpoint_threshold_type="percentile"  # ìƒìœ„ 5%ì—ì„œ ë¶„í• 
)

chunks = semantic_splitter.split_text(text)

# ğŸ“Œ Step 3: ë¬¸ì„œ êµ¬ì¡° ê¸°ë°˜ ì²­í‚¹ (ë§ˆí¬ë‹¤ìš´/HTML)
from langchain.text_splitter import MarkdownHeaderTextSplitter

md_splitter = MarkdownHeaderTextSplitter(
    headers_to_split_on=[("#", "h1"), ("##", "h2"), ("###", "h3")]
)

chunks = md_splitter.split_text(markdown_text)
# ê° ì²­í¬ì— í—¤ë” ë©”íƒ€ë°ì´í„° ìë™ í¬í•¨!

# ğŸ“Œ Step 4: ì½”ë“œ ì²­í‚¹ (ì–¸ì–´ë³„ ìµœì í™”)
from langchain.text_splitter import RecursiveCharacterTextSplitter, Language

code_splitter = RecursiveCharacterTextSplitter.from_language(
    language=Language.PYTHON,
    chunk_size=1000
)

chunks = code_splitter.split_text(python_code)
# í•¨ìˆ˜/í´ë˜ìŠ¤ ë‹¨ìœ„ë¡œ ìë™ ë¶„í• !
\`\`\`

---

## ì „ì²´ ì½”ë“œ (ìƒì„¸)

### 1. ê³ ì • í¬ê¸° ì²­í‚¹ (Fixed Size Chunking)

**ê¸°ë³¸ êµ¬í˜„**

\`\`\`python
from langchain.text_splitter import CharacterTextSplitter

def fixed_size_chunking(text: str, chunk_size: int = 500, overlap: int = 50):
    """ê³ ì • í¬ê¸° ì²­í‚¹ - ê°€ì¥ ë‹¨ìˆœí•œ ë°©ë²•"""

    splitter = CharacterTextSplitter(
        chunk_size=chunk_size,
        chunk_overlap=overlap,
        separator="\\n",           # ì¤„ë°”ê¿ˆ ìš°ì„ 
        length_function=len,      # ë¬¸ì ìˆ˜ ê¸°ì¤€
        is_separator_regex=False
    )

    chunks = splitter.split_text(text)
    return chunks

# ì‚¬ìš©
text = "ê¸´ ë¬¸ì„œ ë‚´ìš©..."
chunks = fixed_size_chunking(text, chunk_size=500, overlap=50)

for i, chunk in enumerate(chunks):
    print(f"Chunk {i+1}: {len(chunk)}ì")
    print(chunk[:100] + "...")
    print("-" * 50)
\`\`\`

### ì¥ë‹¨ì 

\`\`\`
ì¥ì :
  âœ… êµ¬í˜„ì´ ê°€ì¥ ê°„ë‹¨
  âœ… ì˜ˆì¸¡ ê°€ëŠ¥í•œ ì²­í¬ í¬ê¸°
  âœ… ì²˜ë¦¬ ì†ë„ê°€ ë¹ ë¦„

ë‹¨ì :
  âŒ ë¬¸ì¥/ë‹¨ë½ ì¤‘ê°„ì—ì„œ ì˜ë¦´ ìˆ˜ ìˆìŒ
  âŒ ì˜ë¯¸ ë‹¨ìœ„ ë¬´ì‹œ
  âŒ ì¤‘ìš” ì •ë³´ê°€ ë¶„ë¦¬ë  ìˆ˜ ìˆìŒ
\`\`\`

---

## 2. ì¬ê·€ì  ì²­í‚¹ (Recursive Chunking) - ê°€ì¥ ê¶Œì¥

### êµ¬í˜„

\`\`\`python
from langchain.text_splitter import RecursiveCharacterTextSplitter

def recursive_chunking(text: str, chunk_size: int = 500, overlap: int = 50):
    """ì¬ê·€ì  ì²­í‚¹ - ê°€ì¥ ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ìš©"""

    splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,
        chunk_overlap=overlap,
        separators=[
            "\\n\\n\\n",  # ì„¹ì…˜ êµ¬ë¶„ (ê°€ì¥ ìš°ì„ )
            "\\n\\n",    # ë‹¨ë½ êµ¬ë¶„
            "\\n",       # ì¤„ë°”ê¿ˆ
            "ã€‚",        # í•œêµ­ì–´ ë§ˆì¹¨í‘œ
            ".",         # ì˜ì–´ ë§ˆì¹¨í‘œ
            "ï¼",
            "ï¼Ÿ",
            "!",
            "?",
            "ï¼›",
            ";",
            "ï¼Œ",
            ",",
            " ",         # ê³µë°±
            ""           # ë¬¸ì ë‹¨ìœ„ (ìµœí›„ì˜ ìˆ˜ë‹¨)
        ],
        length_function=len,
        is_separator_regex=False
    )

    chunks = splitter.split_text(text)
    return chunks
\`\`\`

### ì‘ë™ ì›ë¦¬

\`\`\`
ì…ë ¥: "RAG ì‹œìŠ¤í…œ ê°œìš”\\n\\nRAGëŠ” ê²€ìƒ‰ ì¦ê°• ìƒì„±ì…ë‹ˆë‹¤.\\nì´ ê¸°ìˆ ì€..."

Step 1: \\n\\në¡œ ë¶„í•  ì‹œë„
  â†’ ["RAG ì‹œìŠ¤í…œ ê°œìš”", "RAGëŠ” ê²€ìƒ‰ ì¦ê°• ìƒì„±ì…ë‹ˆë‹¤.\\nì´ ê¸°ìˆ ì€..."]

Step 2: ê° ì²­í¬ê°€ chunk_size ì´ˆê³¼í•˜ë©´ ë‹¤ìŒ êµ¬ë¶„ìë¡œ ì¬ë¶„í• 
  â†’ ì²« ë²ˆì§¸ ì²­í¬ëŠ” OK
  â†’ ë‘ ë²ˆì§¸ ì²­í¬ê°€ í¬ë©´ \\në¡œ ë¶„í• 

Step 3: ë°˜ë³µ...

ê²°ê³¼: êµ¬ì¡°ë¥¼ ìµœëŒ€í•œ ë³´ì¡´í•˜ë©´ì„œ ì ì ˆí•œ í¬ê¸°ë¡œ ë¶„í• 
\`\`\`

---

## 3. ì˜ë¯¸ì  ì²­í‚¹ (Semantic Chunking)

### êµ¬í˜„

\`\`\`python
from langchain_experimental.text_splitter import SemanticChunker
from langchain_openai import OpenAIEmbeddings
import numpy as np

def semantic_chunking(text: str, threshold_type: str = "percentile"):
    """ì˜ë¯¸ì  ì²­í‚¹ - ì„ë² ë”© ìœ ì‚¬ë„ ê¸°ë°˜ ë¶„í• """

    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")

    splitter = SemanticChunker(
        embeddings=embeddings,
        breakpoint_threshold_type=threshold_type,  # percentile, standard_deviation, interquartile
        breakpoint_threshold_amount=95             # ìƒìœ„ 5%ì—ì„œ ë¶„í• 
    )

    chunks = splitter.split_text(text)
    return chunks
\`\`\`

### ì‘ë™ ì›ë¦¬

\`\`\`
Step 1: ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• 
  ["RAGëŠ” ê²€ìƒ‰ ê¸°ìˆ ì´ë‹¤.", "LLMê³¼ ê²°í•©í•œë‹¤.", "ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì¢‹ë‹¤."]

Step 2: ê° ë¬¸ì¥ ì„ë² ë”© ìƒì„±
  [vec1, vec2, vec3]

Step 3: ì¸ì ‘ ë¬¸ì¥ ê°„ ìœ ì‚¬ë„ ê³„ì‚°
  sim(vec1, vec2) = 0.85  (ë†’ìŒ â†’ ê°™ì€ ì²­í¬)
  sim(vec2, vec3) = 0.30  (ë‚®ìŒ â†’ ë¶„í• ì !)

Step 4: ì„ê³„ê°’ ì´í•˜ì—ì„œ ë¶„í• 
  ì²­í¬1: ["RAGëŠ” ê²€ìƒ‰ ê¸°ìˆ ì´ë‹¤.", "LLMê³¼ ê²°í•©í•œë‹¤."]
  ì²­í¬2: ["ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì¢‹ë‹¤."]
\`\`\`

### ì¥ë‹¨ì 

\`\`\`
ì¥ì :
  âœ… ì˜ë¯¸ì ìœ¼ë¡œ ì¼ê´€ëœ ì²­í¬
  âœ… ì£¼ì œ ë³€í™”ì— ë”°ë¥¸ ìì—°ìŠ¤ëŸ¬ìš´ ë¶„í• 
  âœ… ê²€ìƒ‰ í’ˆì§ˆ í–¥ìƒ

ë‹¨ì :
  âŒ ì„ë² ë”© ë¹„ìš© ë°œìƒ
  âŒ ì²˜ë¦¬ ì†ë„ ëŠë¦¼
  âŒ ì„ê³„ê°’ íŠœë‹ í•„ìš”
\`\`\`

---

## 4. ë¬¸ì„œ êµ¬ì¡° ê¸°ë°˜ ì²­í‚¹

### ë§ˆí¬ë‹¤ìš´ í—¤ë” ê¸°ë°˜

\`\`\`python
from langchain.text_splitter import MarkdownHeaderTextSplitter

def markdown_chunking(markdown_text: str):
    """ë§ˆí¬ë‹¤ìš´ í—¤ë” ê¸°ë°˜ ì²­í‚¹"""

    headers_to_split = [
        ("#", "h1"),
        ("##", "h2"),
        ("###", "h3"),
    ]

    splitter = MarkdownHeaderTextSplitter(
        headers_to_split_on=headers_to_split,
        strip_headers=False  # í—¤ë” ìœ ì§€
    )

    chunks = splitter.split_text(markdown_text)

    # ê° ì²­í¬ì— í—¤ë” ë©”íƒ€ë°ì´í„° í¬í•¨
    for chunk in chunks:
        print(f"Content: {chunk.page_content[:50]}...")
        print(f"Metadata: {chunk.metadata}")
        print("-" * 50)

    return chunks

# ì…ë ¥ ì˜ˆì‹œ
markdown = """
# RAG ì‹œìŠ¤í…œ

## ê°œìš”
RAGëŠ” ê²€ìƒ‰ ì¦ê°• ìƒì„±ì…ë‹ˆë‹¤.

## êµ¬ì„±ìš”ì†Œ
### ê²€ìƒ‰ê¸°
ë²¡í„° ê²€ìƒ‰ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

### ìƒì„±ê¸°
LLMì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
"""

chunks = markdown_chunking(markdown)
# Chunk 1: metadata={"h1": "RAG ì‹œìŠ¤í…œ", "h2": "ê°œìš”"}
# Chunk 2: metadata={"h1": "RAG ì‹œìŠ¤í…œ", "h2": "êµ¬ì„±ìš”ì†Œ", "h3": "ê²€ìƒ‰ê¸°"}
\`\`\`

### HTML êµ¬ì¡° ê¸°ë°˜

\`\`\`python
from langchain.text_splitter import HTMLHeaderTextSplitter

def html_chunking(html_text: str):
    """HTML í—¤ë” ê¸°ë°˜ ì²­í‚¹"""

    headers_to_split = [
        ("h1", "Header 1"),
        ("h2", "Header 2"),
        ("h3", "Header 3"),
    ]

    splitter = HTMLHeaderTextSplitter(headers_to_split_on=headers_to_split)
    chunks = splitter.split_text(html_text)
    return chunks
\`\`\`

---

## 5. ì½”ë“œ ì²­í‚¹

### ì–¸ì–´ë³„ ìµœì í™”

\`\`\`python
from langchain.text_splitter import RecursiveCharacterTextSplitter, Language

def code_chunking(code: str, language: Language):
    """í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì— ìµœì í™”ëœ ì²­í‚¹"""

    splitter = RecursiveCharacterTextSplitter.from_language(
        language=language,
        chunk_size=1000,
        chunk_overlap=100
    )

    chunks = splitter.split_text(code)
    return chunks

# ì§€ì› ì–¸ì–´ ëª©ë¡
supported_languages = [
    Language.PYTHON,
    Language.JS,
    Language.TYPESCRIPT,
    Language.JAVA,
    Language.GO,
    Language.RUST,
    Language.CPP,
    Language.RUBY,
    Language.PHP,
    Language.SWIFT,
    Language.KOTLIN,
    Language.SCALA,
]

# Python ì½”ë“œ ì²­í‚¹
python_code = '''
class RAGPipeline:
    """RAG íŒŒì´í”„ë¼ì¸ í´ë˜ìŠ¤"""

    def __init__(self, vectorstore, llm):
        self.vectorstore = vectorstore
        self.llm = llm

    def retrieve(self, query: str, k: int = 5):
        """ë¬¸ì„œ ê²€ìƒ‰"""
        return self.vectorstore.similarity_search(query, k=k)

    def generate(self, query: str, context: list):
        """ì‘ë‹µ ìƒì„±"""
        prompt = f"Context: {context}\\n\\nQuestion: {query}"
        return self.llm.invoke(prompt)
'''

chunks = code_chunking(python_code, Language.PYTHON)
# í•¨ìˆ˜/í´ë˜ìŠ¤ ë‹¨ìœ„ë¡œ ë¶„í• ë¨
\`\`\`

---

## ì²­í‚¹ ì „ëµ ë¹„êµ í”„ë ˆì„ì›Œí¬

\`\`\`python
def compare_chunking_strategies(text: str):
    """ì—¬ëŸ¬ ì²­í‚¹ ì „ëµ ë¹„êµ"""

    results = {}

    # 1. ê³ ì • í¬ê¸°
    fixed_chunks = fixed_size_chunking(text)
    results["fixed"] = {
        "count": len(fixed_chunks),
        "avg_size": sum(len(c) for c in fixed_chunks) / len(fixed_chunks),
        "pros": "ë¹ ë¦„, ì˜ˆì¸¡ ê°€ëŠ¥",
        "cons": "ì˜ë¯¸ ë¬´ì‹œ"
    }

    # 2. ì¬ê·€ì 
    recursive_chunks = recursive_chunking(text)
    results["recursive"] = {
        "count": len(recursive_chunks),
        "avg_size": sum(len(c) for c in recursive_chunks) / len(recursive_chunks),
        "pros": "êµ¬ì¡° ì¡´ì¤‘",
        "cons": "ì„¤ì • í•„ìš”"
    }

    # 3. ì˜ë¯¸ì 
    semantic_chunks = semantic_chunking(text)
    results["semantic"] = {
        "count": len(semantic_chunks),
        "avg_size": sum(len(c) for c in semantic_chunks) / len(semantic_chunks),
        "pros": "ì˜ë¯¸ ë³´ì¡´",
        "cons": "ëŠë¦¼, ë¹„ìš©"
    }

    # ë¹„êµ í‘œ ì¶œë ¥
    print(f"{'Strategy':<15} {'Count':<10} {'Avg Size':<10}")
    print("-" * 35)
    for strategy, data in results.items():
        print(f"{strategy:<15} {data['count']:<10} {data['avg_size']:<10.1f}")

    return results
\`\`\`

---

## ğŸ’¥ Common Pitfalls (ìì£¼ í•˜ëŠ” ì‹¤ìˆ˜)

### 1. [í¬ê¸° ì„¤ì •] chunk_overlapì´ chunk_sizeë³´ë‹¤ í¼

\`\`\`python
# âŒ ì˜ëª»ëœ ì˜ˆì‹œ: overlapì´ sizeë³´ë‹¤ í¼
splitter = RecursiveCharacterTextSplitter(
    chunk_size=100,
    chunk_overlap=150  # ğŸ”´ chunk_sizeë³´ë‹¤ í¼!
)
# ValueError: chunk_overlap must be less than chunk_size

# âœ… ì˜¬ë°”ë¥¸ ì˜ˆì‹œ: overlapì€ sizeì˜ 10-20%
splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,
    chunk_overlap=50  # 10% (ê¶Œì¥: 10-20%)
)
\`\`\`

**ê¸°ì–µí•  ì **: overlapì€ chunk_sizeì˜ 10-20%ê°€ ì ì •. ë„ˆë¬´ í¬ë©´ ì¤‘ë³µ, ë„ˆë¬´ ì‘ìœ¼ë©´ ë¬¸ë§¥ ë‹¨ì ˆ.

---

### 2. [êµ¬ë¶„ì ìˆœì„œ] separators ìš°ì„ ìˆœìœ„ ë¬´ì‹œ

\`\`\`python
# âŒ ì˜ëª»ëœ ì˜ˆì‹œ: ì‘ì€ ë‹¨ìœ„ë¶€í„° ì‹œì‘
splitter = RecursiveCharacterTextSplitter(
    separators=[" ", ".", "\\n", "\\n\\n"]  # ğŸ”´ ê³µë°±ì´ ë¨¼ì €!
)
# ê²°ê³¼: ëª¨ë“  ê³³ì—ì„œ ê³µë°±ìœ¼ë¡œ ë¶„í•  â†’ ì˜ë¯¸ ì—†ëŠ” ë‹¨í¸

# âœ… ì˜¬ë°”ë¥¸ ì˜ˆì‹œ: í° ë‹¨ìœ„ë¶€í„° ì‘ì€ ë‹¨ìœ„ë¡œ
splitter = RecursiveCharacterTextSplitter(
    separators=["\\n\\n\\n", "\\n\\n", "\\n", ".", " ", ""]
)
# ê²°ê³¼: ë‹¨ë½ â†’ ë¬¸ì¥ â†’ ë‹¨ì–´ ìˆœìœ¼ë¡œ ì‹œë„
\`\`\`

**ê¸°ì–µí•  ì **: separatorsëŠ” "ê°€ì¥ ë¨¼ì € ì‹œë„í•  êµ¬ë¶„ì"ê°€ ì²« ë²ˆì§¸. í° ë‹¨ìœ„(ë‹¨ë½)ë¶€í„° ì‹œì‘í•´ì•¼ êµ¬ì¡° ë³´ì¡´.

---

### 3. [í† í° vs ë¬¸ì] ì„ë² ë”© ëª¨ë¸ í† í° ì œí•œ ë¬´ì‹œ

\`\`\`python
# âŒ ì˜ëª»ëœ ì˜ˆì‹œ: ë¬¸ì ìˆ˜ë¡œë§Œ ì„¤ì •
splitter = RecursiveCharacterTextSplitter(
    chunk_size=8000,  # 8000ì = ì•½ 2000 í† í°
    length_function=len  # ë¬¸ì ìˆ˜ ê¸°ì¤€
)
# ë¬¸ì œ: text-embedding-3-small ìµœëŒ€ 8191 í† í°
#       8000ì í•œê¸€ â†’ ì¼ë¶€ ì²­í¬ê°€ í† í° ì œí•œ ì´ˆê³¼ ê°€ëŠ¥

# âœ… ì˜¬ë°”ë¥¸ ì˜ˆì‹œ: í† í° ê¸°ì¤€ìœ¼ë¡œ ì„¤ì •
import tiktoken

encoder = tiktoken.encoding_for_model("gpt-4o")

splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,  # í† í° ê¸°ì¤€!
    chunk_overlap=50,
    length_function=lambda text: len(encoder.encode(text))
)
\`\`\`

**ê¸°ì–µí•  ì **: ì„ë² ë”© ëª¨ë¸ í† í° ì œí•œ í™•ì¸ í•„ìˆ˜. í•œê¸€ì€ ì˜ì–´ë³´ë‹¤ í† í° íš¨ìœ¨ ë‚®ìŒ (1ê¸€ì â‰ˆ 1-2 í† í°).
      `,
      keyPoints: [
        'ğŸ”„ RecursiveCharacterTextSplitterê°€ ê°€ì¥ ë²”ìš©ì ',
        'ğŸ¤– SemanticChunkerëŠ” ë¹„ìš© ëŒ€ë¹„ í’ˆì§ˆ ìµœê³ ',
        'ğŸ“‹ ë¬¸ì„œ ìœ í˜•ì— ë”°ë¼ ì „ëµ ì„ íƒ',
      ],
      practiceGoal: 'ë‹¤ì–‘í•œ ì²­í‚¹ ì „ëµì„ êµ¬í˜„í•˜ê³  ë¹„êµí•  ìˆ˜ ìˆë‹¤',
    }),

    // ========================================
    // Task 3: ê²€ìƒ‰ ìµœì í™” ì‹¬ì¸µ ë¶„ì„ (45ë¶„)
    // ========================================
    createReadingTask('w5d3-retrieval-deep', 'ê²€ìƒ‰ ìµœì í™” ì‹¬ì¸µ ë¶„ì„', 45, {
      introduction: `
## í•™ìŠµ ëª©í‘œ
- Sparse vs Dense ê²€ìƒ‰ì˜ ì°¨ì´ë¥¼ ì´í•´í•œë‹¤
- í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì˜ ì›ë¦¬ë¥¼ í•™ìŠµí•œë‹¤
- Re-rankingì˜ íš¨ê³¼ì™€ êµ¬í˜„ ë°©ë²•ì„ ì´í•´í•œë‹¤

---

## ê²€ìƒ‰ ë°©ì‹ì˜ ì§„í™”

### 1ì„¸ëŒ€: í‚¤ì›Œë“œ ê²€ìƒ‰ (Sparse)

\`\`\`
ì•Œê³ ë¦¬ì¦˜: TF-IDF, BM25

ì‘ë™ ì›ë¦¬:
  ì¿¼ë¦¬: "RAG ì•„í‚¤í…ì²˜"
  â†’ "RAG"ì™€ "ì•„í‚¤í…ì²˜" ë‹¨ì–´ê°€ í¬í•¨ëœ ë¬¸ì„œ ê²€ìƒ‰
  â†’ ë‹¨ì–´ ë¹ˆë„ì™€ ë¬¸ì„œ ë¹ˆë„ë¡œ ì ìˆ˜ ê³„ì‚°

BM25 ê³µì‹:
  score(D, Q) = Î£ IDF(qi) Ã— (f(qi, D) Ã— (k1 + 1)) / (f(qi, D) + k1 Ã— (1 - b + b Ã— |D|/avgdl))

ì¥ì :
  âœ… ì •í™•í•œ í‚¤ì›Œë“œ ë§¤ì¹­
  âœ… ë¹ ë¥¸ ì†ë„
  âœ… ì„¤ëª… ê°€ëŠ¥ (ì–´ë–¤ ë‹¨ì–´ê°€ ë§¤ì¹­ë˜ì—ˆëŠ”ì§€)
  âœ… ì €ë¹„ìš©

ë‹¨ì :
  âŒ ë™ì˜ì–´ ì¸ì‹ ë¶ˆê°€ ("AI" vs "ì¸ê³µì§€ëŠ¥")
  âŒ ì˜ë¯¸ì  ìœ ì‚¬ì„± ë¬´ì‹œ
  âŒ ì–´íœ˜ ë¶ˆì¼ì¹˜ ë¬¸ì œ (Vocabulary Mismatch)
\`\`\`

### 2ì„¸ëŒ€: ì˜ë¯¸ ê²€ìƒ‰ (Dense/Vector)

\`\`\`
ì•Œê³ ë¦¬ì¦˜: ì„ë² ë”© ê¸°ë°˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„

ì‘ë™ ì›ë¦¬:
  ì¿¼ë¦¬: "ê²€ìƒ‰ ê¸°ë°˜ ìƒì„± AI"
  â†’ ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
  â†’ ì €ì¥ëœ ë¬¸ì„œ ì„ë² ë”©ê³¼ ìœ ì‚¬ë„ ê³„ì‚°
  â†’ ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œ ë°˜í™˜

ì¥ì :
  âœ… ì˜ë¯¸ì  ìœ ì‚¬ì„± í¬ì°©
  âœ… ë™ì˜ì–´, ìœ ì‚¬ í‘œí˜„ ì²˜ë¦¬
  âœ… ë‹¤êµ­ì–´ ê²€ìƒ‰ ê°€ëŠ¥

ë‹¨ì :
  âŒ ì •í™•í•œ í‚¤ì›Œë“œ ë§¤ì¹­ ì•½í•¨
  âŒ ì„ë² ë”© í’ˆì§ˆì— ì˜ì¡´
  âŒ ì„¤ëª…í•˜ê¸° ì–´ë ¤ì›€
  âŒ í¬ê·€ ìš©ì–´/ì „ë¬¸ ìš©ì–´ ì•½í•¨
\`\`\`

### 3ì„¸ëŒ€: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰

\`\`\`
í‚¤ì›Œë“œ ê²€ìƒ‰ì˜ ì •í™•ì„± + ì˜ë¯¸ ê²€ìƒ‰ì˜ ì´í•´ë ¥ ê²°í•©

hybrid_score = Î± Ã— sparse_score + (1-Î±) Ã— dense_score

Î± ê°’ ì„ íƒ:
  - Î± = 0.3: ì˜ë¯¸ ê²€ìƒ‰ ìœ„ì£¼ (ì¼ë°˜ Q&A)
  - Î± = 0.5: ê· í˜• (ëŒ€ë¶€ë¶„ì˜ ê²½ìš°)
  - Î± = 0.7: í‚¤ì›Œë“œ ê²€ìƒ‰ ìœ„ì£¼ (ì „ë¬¸ ìš©ì–´, ì½”ë“œ)

ì—°êµ¬ ê²°ê³¼ (2023):
  - í•˜ì´ë¸Œë¦¬ë“œê°€ ë‹¨ë… ë°©ì‹ë³´ë‹¤ 10-15% ì„±ëŠ¥ í–¥ìƒ
  - íŠ¹íˆ ì „ë¬¸ ìš©ì–´ê°€ ë§ì€ ë„ë©”ì¸ì—ì„œ íš¨ê³¼ì 
\`\`\`

---

## Re-ranking: ê²€ìƒ‰ í’ˆì§ˆì˜ ë§ˆì§€ë§‰ ë‹¨ê³„

### Re-rankingì´ë€?

\`\`\`
1ì°¨ ê²€ìƒ‰ â†’ [Top-20 ë¬¸ì„œ] â†’ Re-ranker â†’ [Top-5 ë¬¸ì„œ]

1ì°¨ ê²€ìƒ‰: ë¹ ë¥´ì§€ë§Œ ëŒ€ëµì ì¸ ê²€ìƒ‰ (recall ì¤‘ì‹œ)
Re-ranking: ëŠë¦¬ì§€ë§Œ ì •ë°€í•œ ì¬ì •ë ¬ (precision ì¤‘ì‹œ)

ë¹„ìœ :
  1ì°¨ ê²€ìƒ‰ = ê·¸ë¬¼ë¡œ ë¬¼ê³ ê¸° ì¡ê¸° (ë§ì´ ì¡ìŒ)
  Re-ranking = ì¢‹ì€ ë¬¼ê³ ê¸°ë§Œ ê³¨ë¼ë‚´ê¸° (í’ˆì§ˆ í–¥ìƒ)
\`\`\`

### Cross-Encoder vs Bi-Encoder

\`\`\`
Bi-Encoder (ì„ë² ë”© ê¸°ë°˜):
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  ì¿¼ë¦¬   â”‚     â”‚  ë¬¸ì„œ   â”‚
  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
       â†“                â†“
  â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
  â”‚ Encoder â”‚     â”‚ Encoder â”‚
  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
       â†“                â†“
    [ì¿¼ë¦¬ ë²¡í„°]    [ë¬¸ì„œ ë²¡í„°]
            â•²      â•±
         ì½”ì‚¬ì¸ ìœ ì‚¬ë„
              â†“
           ì ìˆ˜

  íŠ¹ì§•: ë¹ ë¦„, ë¬¸ì„œ ë²¡í„° ë¯¸ë¦¬ ê³„ì‚° ê°€ëŠ¥

Cross-Encoder (Re-ranking):
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚   [ì¿¼ë¦¬] [SEP] [ë¬¸ì„œ]   â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚       Transformer       â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
            ì ìˆ˜

  íŠ¹ì§•: ì •í™•í•¨, ì¿¼ë¦¬ë§ˆë‹¤ ì¬ê³„ì‚° í•„ìš” (ëŠë¦¼)
\`\`\`

### Re-ranker ì¢…ë¥˜

\`\`\`
1. Cohere Rerank API
   - ìƒìš© ì„œë¹„ìŠ¤, ê³ í’ˆì§ˆ
   - ê°€ê²©: $0.002/ê²€ìƒ‰
   - ë‹¤êµ­ì–´ ì§€ì›

2. BGE Reranker (ì˜¤í”ˆì†ŒìŠ¤)
   - BAAIì—ì„œ ê°œë°œ
   - ë¡œì»¬ ì‹¤í–‰ ê°€ëŠ¥
   - í•œêµ­ì–´ ì§€ì›

3. Cross-Encoder (sentence-transformers)
   - ì™„ì „ ì˜¤í”ˆì†ŒìŠ¤
   - ì»¤ìŠ¤í„°ë§ˆì´ì§• ê°€ëŠ¥
   - GPU ê¶Œì¥

4. ColBERT
   - í† í° ë‹¨ìœ„ ìƒí˜¸ì‘ìš©
   - ë§¤ìš° ì •í™•
   - ì¸ë±ì‹± í•„ìš”
\`\`\`

---

## MMR (Maximal Marginal Relevance)

### ë¬¸ì œ: ê²€ìƒ‰ ê²°ê³¼ì˜ ë‹¤ì–‘ì„± ë¶€ì¡±

\`\`\`
ì¿¼ë¦¬: "íŒŒì´ì¬ ë°ì´í„° ë¶„ì„"

ì¼ë°˜ ê²€ìƒ‰ Top-5:
  1. "íŒŒì´ì¬ ë°ì´í„° ë¶„ì„ ì…ë¬¸"
  2. "íŒŒì´ì¬ ë°ì´í„° ë¶„ì„ ê¸°ì´ˆ"  â† ê±°ì˜ ë™ì¼
  3. "íŒŒì´ì¬ ë°ì´í„° ë¶„ì„ ì²«ê±¸ìŒ"  â† ê±°ì˜ ë™ì¼
  4. "íŒŒì´ì¬ ë°ì´í„° ë¶„ì„ ì‹œì‘"  â† ê±°ì˜ ë™ì¼
  5. "íŒŒì´ì¬ ë°ì´í„° ë¶„ì„ ê°œìš”"  â† ê±°ì˜ ë™ì¼

ë¬¸ì œ: ì¤‘ë³µëœ ì •ë³´, ë‹¤ì–‘í•œ ê´€ì  ë¶€ì¡±
\`\`\`

### MMR í•´ê²°ì±…

\`\`\`
MMR Score = Î» Ã— Relevance(doc, query)
          - (1-Î») Ã— max[Similarity(doc, selected_docs)]

Î» = 1.0: ìˆœìˆ˜ ê´€ë ¨ì„± (ë‹¤ì–‘ì„± ë¬´ì‹œ)
Î» = 0.5: ê´€ë ¨ì„±ê³¼ ë‹¤ì–‘ì„± ê· í˜•
Î» = 0.0: ìˆœìˆ˜ ë‹¤ì–‘ì„± (ê´€ë ¨ì„± ë¬´ì‹œ)

ê²°ê³¼:
  1. "íŒŒì´ì¬ ë°ì´í„° ë¶„ì„ ì…ë¬¸" (ê´€ë ¨ì„± ë†’ìŒ)
  2. "Pandas íŠœí† ë¦¬ì–¼" (ë‹¤ë¥¸ ê´€ì )
  3. "NumPyë¡œ ì‹œì‘í•˜ëŠ” ê³¼í•™ ê³„ì‚°" (ë‹¤ë¥¸ ê´€ì )
  4. "ë°ì´í„° ì‹œê°í™” Matplotlib" (ë‹¤ë¥¸ ê´€ì )
  5. "Jupyter Notebook ì‚¬ìš©ë²•" (ë‹¤ë¥¸ ê´€ì )
\`\`\`

---

## Query Transformation ê¸°ë²•

### 1. Query Expansion (ì¿¼ë¦¬ í™•ì¥)

\`\`\`
ì›ë³¸ ì¿¼ë¦¬: "RAG ì„±ëŠ¥ í–¥ìƒ"

LLMìœ¼ë¡œ í™•ì¥:
  â†’ "RAG ìµœì í™” ë°©ë²•"
  â†’ "ê²€ìƒ‰ ì¦ê°• ìƒì„± ê°œì„  ì „ëµ"
  â†’ "RAG ì‹œìŠ¤í…œ íŠœë‹ ê¸°ë²•"
  â†’ "Retrieval Augmented Generation ì„±ëŠ¥"

ê° ì¿¼ë¦¬ë¡œ ê²€ìƒ‰ â†’ ê²°ê³¼ í†µí•© â†’ ì¤‘ë³µ ì œê±°
\`\`\`

### 2. HyDE (Hypothetical Document Embedding)

\`\`\`
ì›ë³¸ ì¿¼ë¦¬: "RAG ì„±ëŠ¥ í–¥ìƒ ë°©ë²•ì€?"

Step 1: LLMìœ¼ë¡œ ê°€ìƒì˜ ë‹µë³€ ìƒì„±
  "RAG ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ë ¤ë©´ ì²­í‚¹ ì „ëµ ìµœì í™”,
   í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ë„ì…, Re-ranking ì ìš©ì´ íš¨ê³¼ì ì…ë‹ˆë‹¤..."

Step 2: ê°€ìƒ ë‹µë³€ì„ ì„ë² ë”©

Step 3: ê°€ìƒ ë‹µë³€ ì„ë² ë”©ìœ¼ë¡œ ê²€ìƒ‰

ì¥ì : ì§ˆë¬¸ë³´ë‹¤ ë‹µë³€ê³¼ ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰
ë‹¨ì : LLM í˜¸ì¶œ ë¹„ìš©, í™˜ê° ìœ„í—˜
\`\`\`

### 3. Step-back Prompting

\`\`\`
ì›ë³¸ ì¿¼ë¦¬: "GPT-4ì˜ ì»¨í…ìŠ¤íŠ¸ ì°½ í¬ê¸°ëŠ”?"

Step-back ì¿¼ë¦¬: "GPT-4ì˜ ì•„í‚¤í…ì²˜ì™€ íŠ¹ì§•ì€?"

ë” ë„“ì€ ë²”ìœ„ì˜ ë¬¸ì„œ ê²€ìƒ‰ â†’ ì„¸ë¶€ ì •ë³´ í¬í•¨ í™•ë¥  ë†’ìŒ
\`\`\`
      `,
      keyPoints: [
        'í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì´ ëŒ€ë¶€ë¶„ ìµœì  (í‚¤ì›Œë“œ + ì˜ë¯¸)',
        'Re-rankingìœ¼ë¡œ 10-15% ì •í™•ë„ í–¥ìƒ',
        'MMRë¡œ ê²€ìƒ‰ ê²°ê³¼ ë‹¤ì–‘ì„± í™•ë³´',
      ],
      practiceGoal: 'ê²€ìƒ‰ ìµœì í™” ê¸°ë²•ë“¤ì˜ ì›ë¦¬ì™€ íš¨ê³¼ë¥¼ ì´í•´í•œë‹¤',
    }),

    // ========================================
    // Task 4: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ & Re-ranking ì‹¤ìŠµ (50ë¶„)
    // ========================================
    createCodeTask('w5d3-hybrid-reranking', 'í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ & Re-ranking ì‹¤ìŠµ', 50, {
      introduction: `
## ì™œ ë°°ìš°ëŠ”ê°€?

**ë¬¸ì œ**: ë²¡í„° ê²€ìƒ‰ë§Œ ì“°ë©´ "AI ì¸ê³µì§€ëŠ¥" ê°™ì€ ì •í™•í•œ í‚¤ì›Œë“œë¥¼ ëª» ì°¾ê³ , í‚¤ì›Œë“œ ê²€ìƒ‰ë§Œ ì“°ë©´ "ê²€ìƒ‰ ê¸°ë°˜ ìƒì„± ê¸°ìˆ "ê³¼ "RAG"ë¥¼ ë§¤ì¹­ ëª» í•©ë‹ˆë‹¤.

**í•´ê²°**: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰(í‚¤ì›Œë“œ + ë²¡í„°)ê³¼ Re-rankingìœ¼ë¡œ ì •í™•ë„ë¥¼ 10-15% í–¥ìƒì‹œí‚µë‹ˆë‹¤.

---

## ë¹„ìœ : ê²€ìƒ‰ = ë¬¼ê³ ê¸° ì¡ê¸°

\`\`\`
1ì°¨ ê²€ìƒ‰ (Hybrid) = ê·¸ë¬¼ë¡œ ë„“ê²Œ ì¡ê¸°
- BM25 (í‚¤ì›Œë“œ): "RAG" ë‹¨ì–´ê°€ ìˆëŠ” ë¬¸ì„œ
- Vector (ë²¡í„°): "ê²€ìƒ‰ ì¦ê°• ìƒì„±"ê³¼ ì˜ë¯¸ ë¹„ìŠ·í•œ ë¬¸ì„œ
- ê²°ê³¼: 20ë§ˆë¦¬ ì¡ìŒ (í•˜ì§€ë§Œ ì‘ì€ ë¬¼ê³ ê¸°ë„ ì„ì„)

Re-ranking = ì¢‹ì€ ë¬¼ê³ ê¸°ë§Œ ê³¨ë¼ë‚´ê¸°
- Cross-Encoder: ê° ë¬¼ê³ ê¸°ë¥¼ ìì„¸íˆ ê²€ì‚¬
- ê²°ê³¼: ìƒìœ„ 5ë§ˆë¦¬ë§Œ ì„ íƒ (ì •í™•ë„ ë†’ìŒ)
\`\`\`

---

## í•µì‹¬ êµ¬í˜„ (ê°„ì†Œí™”)

\`\`\`python
# ğŸ“Œ Step 1: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (BM25 + Vector)
from langchain.retrievers import EnsembleRetriever
from langchain_community.retrievers import BM25Retriever
from langchain_chroma import Chroma

# BM25 (í‚¤ì›Œë“œ ê²€ìƒ‰)
bm25 = BM25Retriever.from_documents(docs, k=10)

# Vector (ì˜ë¯¸ ê²€ìƒ‰)
vectorstore = Chroma.from_documents(docs, embeddings)
vector = vectorstore.as_retriever(search_kwargs={"k": 10})

# ì•™ìƒë¸” (40% í‚¤ì›Œë“œ + 60% ë²¡í„°)
hybrid = EnsembleRetriever(
    retrievers=[bm25, vector],
    weights=[0.4, 0.6]
)

results = hybrid.invoke("ê²€ìƒ‰ ê¸°ë°˜ AI")

# ğŸ“Œ Step 2: Re-ranking (ì •ë°€ë„ í–¥ìƒ)
from sentence_transformers import CrossEncoder

reranker = CrossEncoder("BAAI/bge-reranker-base")

# 1ì°¨: 20ê°œ ê²€ìƒ‰
initial_results = hybrid.invoke(query)

# 2ì°¨: ì ìˆ˜ ì¬ê³„ì‚°
pairs = [(query, doc.page_content) for doc in initial_results]
scores = reranker.predict(pairs)

# 3ì°¨: ìƒìœ„ 5ê°œë§Œ ì„ íƒ
top_5_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:5]
final_results = [initial_results[i] for i in top_5_indices]

# ğŸ“Œ Step 3: MMR (ë‹¤ì–‘ì„± í™•ë³´)
mmr_retriever = vectorstore.as_retriever(
    search_type="mmr",
    search_kwargs={
        "k": 5,
        "fetch_k": 20,
        "lambda_mult": 0.5  # 0=ë‹¤ì–‘ì„±, 1=ê´€ë ¨ì„±
    }
)

diverse_results = mmr_retriever.invoke(query)
\`\`\`

---

## ì „ì²´ ì½”ë“œ (ìƒì„¸)

### 1. BM25 ê²€ìƒ‰ê¸° êµ¬í˜„

\`\`\`python
from langchain_community.retrievers import BM25Retriever
from langchain.schema import Document

def create_bm25_retriever(documents: list[Document], k: int = 5):
    """BM25 í‚¤ì›Œë“œ ê²€ìƒ‰ê¸° ìƒì„±"""

    retriever = BM25Retriever.from_documents(
        documents,
        k=k
    )

    return retriever

# ì‚¬ìš©
docs = [
    Document(page_content="RAGëŠ” ê²€ìƒ‰ ì¦ê°• ìƒì„±ì…ë‹ˆë‹¤.", metadata={"source": "doc1"}),
    Document(page_content="ë²¡í„° ê²€ìƒ‰ì€ ì„ë² ë”©ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.", metadata={"source": "doc2"}),
    Document(page_content="BM25ëŠ” í‚¤ì›Œë“œ ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤.", metadata={"source": "doc3"}),
]

bm25 = create_bm25_retriever(docs, k=3)
results = bm25.invoke("ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜")

for doc in results:
    print(f"[BM25] {doc.page_content[:50]}...")
\`\`\`

---

## 2. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (Ensemble Retriever)

\`\`\`python
from langchain.retrievers import EnsembleRetriever
from langchain_community.retrievers import BM25Retriever
from langchain_chroma import Chroma
from langchain_openai import OpenAIEmbeddings

def create_hybrid_retriever(
    documents: list[Document],
    vectorstore: Chroma,
    bm25_weight: float = 0.4,
    vector_weight: float = 0.6,
    k: int = 5
):
    """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸° ìƒì„±"""

    # BM25 ê²€ìƒ‰ê¸°
    bm25_retriever = BM25Retriever.from_documents(
        documents,
        k=k
    )

    # ë²¡í„° ê²€ìƒ‰ê¸°
    vector_retriever = vectorstore.as_retriever(
        search_type="similarity",
        search_kwargs={"k": k}
    )

    # ì•™ìƒë¸” ê²€ìƒ‰ê¸°
    ensemble = EnsembleRetriever(
        retrievers=[bm25_retriever, vector_retriever],
        weights=[bm25_weight, vector_weight]
    )

    return ensemble

# ì‚¬ìš© ì˜ˆì‹œ
embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
vectorstore = Chroma.from_documents(docs, embeddings)

hybrid = create_hybrid_retriever(
    documents=docs,
    vectorstore=vectorstore,
    bm25_weight=0.4,  # í‚¤ì›Œë“œ 40%
    vector_weight=0.6  # ë²¡í„° 60%
)

results = hybrid.invoke("ê²€ìƒ‰ ê¸°ë°˜ AI ê¸°ìˆ ")
for doc in results:
    print(f"[Hybrid] {doc.page_content[:50]}...")
\`\`\`

---

## 3. Re-ranking with Cohere

\`\`\`python
from langchain.retrievers import ContextualCompressionRetriever
from langchain.retrievers.document_compressors import CohereRerank
from langchain_community.retrievers import BM25Retriever
import os

def create_reranking_retriever(
    base_retriever,
    top_n: int = 5,
    initial_k: int = 20
):
    """Cohere Re-rankerê°€ ì ìš©ëœ ê²€ìƒ‰ê¸°"""

    # Cohere Reranker
    reranker = CohereRerank(
        cohere_api_key=os.environ["COHERE_API_KEY"],
        top_n=top_n,
        model="rerank-multilingual-v3.0"  # ë‹¤êµ­ì–´ ì§€ì›
    )

    # ì••ì¶• ê²€ìƒ‰ê¸° (1ì°¨ ê²€ìƒ‰ â†’ Re-ranking)
    compression_retriever = ContextualCompressionRetriever(
        base_compressor=reranker,
        base_retriever=base_retriever
    )

    return compression_retriever

# ì‚¬ìš© ì˜ˆì‹œ
base_retriever = vectorstore.as_retriever(search_kwargs={"k": 20})
reranking_retriever = create_reranking_retriever(base_retriever, top_n=5)

# 20ê°œ ê²€ìƒ‰ â†’ 5ê°œë¡œ Re-rank
results = reranking_retriever.invoke("RAG ì‹œìŠ¤í…œ ìµœì í™” ë°©ë²•")
\`\`\`

---

## 4. ì˜¤í”ˆì†ŒìŠ¤ Re-ranker (BGE)

\`\`\`python
from sentence_transformers import CrossEncoder
import numpy as np

class BGEReranker:
    """BGE Cross-Encoder ê¸°ë°˜ Re-ranker"""

    def __init__(self, model_name: str = "BAAI/bge-reranker-base"):
        self.model = CrossEncoder(model_name)

    def rerank(
        self,
        query: str,
        documents: list[Document],
        top_n: int = 5
    ) -> list[Document]:
        """ë¬¸ì„œ ì¬ì •ë ¬"""

        # ì¿¼ë¦¬-ë¬¸ì„œ ìŒ ìƒì„±
        pairs = [(query, doc.page_content) for doc in documents]

        # ì ìˆ˜ ê³„ì‚°
        scores = self.model.predict(pairs)

        # ì •ë ¬
        sorted_indices = np.argsort(scores)[::-1][:top_n]

        # ìƒìœ„ Nê°œ ë°˜í™˜
        return [documents[i] for i in sorted_indices]

# ì‚¬ìš©
reranker = BGEReranker()

# 1ì°¨ ê²€ìƒ‰
initial_results = vectorstore.similarity_search("RAG ìµœì í™”", k=20)

# Re-ranking
final_results = reranker.rerank("RAG ìµœì í™”", initial_results, top_n=5)
\`\`\`

---

## 5. MMR ê²€ìƒ‰

\`\`\`python
def create_mmr_retriever(
    vectorstore: Chroma,
    k: int = 5,
    fetch_k: int = 20,
    lambda_mult: float = 0.5
):
    """MMR ê²€ìƒ‰ê¸° ìƒì„±"""

    retriever = vectorstore.as_retriever(
        search_type="mmr",
        search_kwargs={
            "k": k,              # ìµœì¢… ë°˜í™˜ ê°œìˆ˜
            "fetch_k": fetch_k,  # í›„ë³´êµ° í¬ê¸°
            "lambda_mult": lambda_mult  # ë‹¤ì–‘ì„± ê°€ì¤‘ì¹˜ (0=ë‹¤ì–‘ì„±, 1=ê´€ë ¨ì„±)
        }
    )

    return retriever

# ë‹¤ì–‘ì„± ì¤‘ì‹œ
diverse_retriever = create_mmr_retriever(vectorstore, lambda_mult=0.3)

# ê´€ë ¨ì„± ì¤‘ì‹œ
relevant_retriever = create_mmr_retriever(vectorstore, lambda_mult=0.7)
\`\`\`

---

## 6. ì „ì²´ ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸

\`\`\`python
from dataclasses import dataclass
from typing import Optional
from langchain.schema import Document

@dataclass
class SearchConfig:
    """ê²€ìƒ‰ ì„¤ì •"""
    use_hybrid: bool = True
    bm25_weight: float = 0.4
    use_reranking: bool = True
    use_mmr: bool = True
    initial_k: int = 20
    final_k: int = 5
    mmr_lambda: float = 0.5

class AdvancedRetriever:
    """í”„ë¡œë•ì…˜ê¸‰ ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸"""

    def __init__(
        self,
        vectorstore: Chroma,
        documents: list[Document],
        config: SearchConfig
    ):
        self.vectorstore = vectorstore
        self.documents = documents
        self.config = config

        # ê²€ìƒ‰ê¸° ì´ˆê¸°í™”
        self._setup_retrievers()

    def _setup_retrievers(self):
        """ê²€ìƒ‰ê¸° ì„¤ì •"""
        if self.config.use_hybrid:
            # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸°
            bm25 = BM25Retriever.from_documents(
                self.documents,
                k=self.config.initial_k
            )
            vector = self.vectorstore.as_retriever(
                search_kwargs={"k": self.config.initial_k}
            )
            self.base_retriever = EnsembleRetriever(
                retrievers=[bm25, vector],
                weights=[self.config.bm25_weight, 1 - self.config.bm25_weight]
            )
        else:
            self.base_retriever = self.vectorstore.as_retriever(
                search_kwargs={"k": self.config.initial_k}
            )

        if self.config.use_reranking:
            self.reranker = BGEReranker()

    def search(self, query: str) -> list[Document]:
        """ê²€ìƒ‰ ì‹¤í–‰"""
        # 1ì°¨ ê²€ìƒ‰
        results = self.base_retriever.invoke(query)

        # Re-ranking
        if self.config.use_reranking:
            results = self.reranker.rerank(query, results, self.config.final_k)
        else:
            results = results[:self.config.final_k]

        return results

# ì‚¬ìš©
config = SearchConfig(
    use_hybrid=True,
    bm25_weight=0.4,
    use_reranking=True,
    initial_k=20,
    final_k=5
)

retriever = AdvancedRetriever(vectorstore, docs, config)
results = retriever.search("RAG ì‹œìŠ¤í…œ êµ¬ì¶• ë°©ë²•")
\`\`\`

---

## ğŸ’¥ Common Pitfalls (ìì£¼ í•˜ëŠ” ì‹¤ìˆ˜)

### 1. [ì•™ìƒë¸” ê°€ì¤‘ì¹˜] ê·¹ë‹¨ì ì¸ ê°€ì¤‘ì¹˜ ì„¤ì •

\`\`\`python
# âŒ ì˜ëª»ëœ ì˜ˆì‹œ: í•œìª½ì— 100% ê°€ì¤‘ì¹˜
ensemble = EnsembleRetriever(
    retrievers=[bm25, vector],
    weights=[1.0, 0.0]  # ğŸ”´ BM25ë§Œ ì‚¬ìš© â†’ í•˜ì´ë¸Œë¦¬ë“œ ì˜ë¯¸ ì—†ìŒ
)

# âŒ ë˜ ë‹¤ë¥¸ ì‹¤ìˆ˜: ê°€ì¤‘ì¹˜ í•©ì´ 1ì´ ì•„ë‹˜
ensemble = EnsembleRetriever(
    retrievers=[bm25, vector],
    weights=[0.7, 0.7]  # ğŸ”´ í•©ì´ 1.4 â†’ ì˜ˆìƒì¹˜ ëª»í•œ ë™ì‘
)

# âœ… ì˜¬ë°”ë¥¸ ì˜ˆì‹œ: ê· í˜• ì¡íŒ ê°€ì¤‘ì¹˜
ensemble = EnsembleRetriever(
    retrievers=[bm25, vector],
    weights=[0.4, 0.6]  # ì¼ë°˜ì ìœ¼ë¡œ ë²¡í„°ì— ì•½ê°„ ë†’ì€ ê°€ì¤‘ì¹˜
)
\`\`\`

**ê¸°ì–µí•  ì **: ê°€ì¤‘ì¹˜ í•©ì€ 1.0ì´ ê¶Œì¥. ë„ë©”ì¸ì— ë”°ë¼ 0.3~0.7 ë²”ìœ„ì—ì„œ ì¡°ì •.

---

### 2. [Re-ranking ë¹„ìš©] ëª¨ë“  ê²°ê³¼ì— Re-ranking ì ìš©

\`\`\`python
# âŒ ì˜ëª»ëœ ì˜ˆì‹œ: 1ì°¨ ê²€ìƒ‰ ê²°ê³¼ ì „ì²´ì— Re-ranking
initial_results = vectorstore.similarity_search(query, k=1000)  # ğŸ”´ 1000ê°œ!
reranked = reranker.rerank(query, initial_results, top_n=5)
# ë¬¸ì œ: Cross-EncoderëŠ” ëŠë¦¼ â†’ 1000ê°œ ì²˜ë¦¬ì— ìˆ˜ì‹­ ì´ˆ

# âœ… ì˜¬ë°”ë¥¸ ì˜ˆì‹œ: 2ë‹¨ê³„ íŒŒì´í”„ë¼ì¸
# 1ì°¨: ë¹ ë¥¸ ê²€ìƒ‰ìœ¼ë¡œ í›„ë³´êµ° (20-50ê°œ)
initial_results = vectorstore.similarity_search(query, k=20)
# 2ì°¨: Re-rankingìœ¼ë¡œ ì •ì œ (5ê°œ)
final_results = reranker.rerank(query, initial_results, top_n=5)
\`\`\`

**ê¸°ì–µí•  ì **: Re-rankingì€ 1ì°¨ ê²€ìƒ‰ í›„ 20-50ê°œ í›„ë³´ì—ë§Œ ì ìš©. ì „ì²´ì— ì ìš©í•˜ë©´ ë¹„ìš©/ì‹œê°„ í­ì¦.

---

### 3. [MMR lambda] ë‹¤ì–‘ì„±ê³¼ ê´€ë ¨ì„± í˜¼ë™

\`\`\`python
# âŒ ì˜ëª»ëœ ì˜ˆì‹œ: lambda ì´í•´ ë¶€ì¡±
retriever = vectorstore.as_retriever(
    search_type="mmr",
    search_kwargs={
        "lambda_mult": 0.0  # ğŸ”´ ê´€ë ¨ì„± 0%, ë‹¤ì–‘ì„± 100%
    }
)
# ê²°ê³¼: ê´€ë ¨ ì—†ëŠ” ë¬¸ì„œë„ ë‹¤ì–‘ì„± ë•Œë¬¸ì— í¬í•¨!

# âœ… ì˜¬ë°”ë¥¸ ì˜ˆì‹œ: ê· í˜• ìˆëŠ” lambda
retriever = vectorstore.as_retriever(
    search_type="mmr",
    search_kwargs={
        "k": 5,
        "fetch_k": 20,
        "lambda_mult": 0.5  # ê´€ë ¨ì„± 50% + ë‹¤ì–‘ì„± 50%
    }
)
\`\`\`

**ê¸°ì–µí•  ì **: lambda_mult=1.0ì€ ìˆœìˆ˜ ê´€ë ¨ì„±(MMR ì•„ë‹˜), 0.5ê°€ ì¼ë°˜ì  ì‹œì‘ì . ë„ˆë¬´ ë‚®ìœ¼ë©´ ê´€ë ¨ ì—†ëŠ” ë¬¸ì„œ í¬í•¨.
      `,
      keyPoints: [
        'ğŸ¯ EnsembleRetrieverë¡œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ êµ¬í˜„',
        'ğŸ¥‡ Cohere/BGEë¡œ Re-ranking ì ìš©',
        'âš™ï¸ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ì „ì²´ ê²€ìƒ‰ í”„ë¡œì„¸ìŠ¤ í†µí•©',
      ],
      practiceGoal: 'í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê³¼ Re-rankingì„ êµ¬í˜„í•  ìˆ˜ ìˆë‹¤',
    }),

    // ========================================
    // Task 5: RAG í‰ê°€ ì§€í‘œì™€ ë²¤ì¹˜ë§ˆí‚¹ (35ë¶„)
    // ========================================
    createReadingTask('w5d3-rag-evaluation', 'RAG í‰ê°€ ì§€í‘œì™€ ë²¤ì¹˜ë§ˆí‚¹', 35, {
      introduction: `
## í•™ìŠµ ëª©í‘œ
- RAG ì‹œìŠ¤í…œì˜ ì£¼ìš” í‰ê°€ ì§€í‘œë¥¼ ì´í•´í•œë‹¤
- ê²€ìƒ‰ í’ˆì§ˆê³¼ ìƒì„± í’ˆì§ˆì„ ì¸¡ì •í•˜ëŠ” ë°©ë²•ì„ í•™ìŠµí•œë‹¤
- ìë™í™”ëœ í‰ê°€ íŒŒì´í”„ë¼ì¸ì„ ì„¤ê³„í•œë‹¤

---

## RAG í‰ê°€ì˜ ë‘ ì¶•

\`\`\`
RAG ì‹œìŠ¤í…œ = ê²€ìƒ‰ + ìƒì„±

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ê²€ìƒ‰ í’ˆì§ˆ í‰ê°€  â”‚  ìƒì„± í’ˆì§ˆ í‰ê°€  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ - Precision@K   â”‚ - Faithfulness  â”‚
â”‚ - Recall@K      â”‚ - Answer Relevanceâ”‚
â”‚ - MRR           â”‚ - Context Relevanceâ”‚
â”‚ - NDCG          â”‚ - Hallucination Rateâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\`\`\`

---

## ê²€ìƒ‰ í’ˆì§ˆ í‰ê°€ ì§€í‘œ

### 1. Precision@K

\`\`\`python
def precision_at_k(relevant_docs: set, retrieved_docs: list, k: int) -> float:
    """
    ìƒìœ„ Kê°œ ì¤‘ ê´€ë ¨ ë¬¸ì„œ ë¹„ìœ¨

    Precision@K = (ê´€ë ¨ ë¬¸ì„œ ìˆ˜) / K
    """
    top_k = set(retrieved_docs[:k])
    relevant_in_top_k = len(relevant_docs & top_k)
    return relevant_in_top_k / k

# ì˜ˆì‹œ
relevant = {"doc1", "doc3", "doc5"}
retrieved = ["doc1", "doc2", "doc3", "doc4", "doc5"]

print(f"Precision@3: {precision_at_k(relevant, retrieved, 3)}")  # 0.67
print(f"Precision@5: {precision_at_k(relevant, retrieved, 5)}")  # 0.60
\`\`\`

### 2. Recall@K

\`\`\`python
def recall_at_k(relevant_docs: set, retrieved_docs: list, k: int) -> float:
    """
    ê´€ë ¨ ë¬¸ì„œ ì¤‘ ìƒìœ„ Kê°œì— í¬í•¨ëœ ë¹„ìœ¨

    Recall@K = (ìƒìœ„ Kê°œì—ì„œ ì°¾ì€ ê´€ë ¨ ë¬¸ì„œ) / (ì „ì²´ ê´€ë ¨ ë¬¸ì„œ)
    """
    top_k = set(retrieved_docs[:k])
    relevant_in_top_k = len(relevant_docs & top_k)
    return relevant_in_top_k / len(relevant_docs)

# ì˜ˆì‹œ
print(f"Recall@3: {recall_at_k(relevant, retrieved, 3)}")  # 0.67
print(f"Recall@5: {recall_at_k(relevant, retrieved, 5)}")  # 1.00
\`\`\`

### 3. MRR (Mean Reciprocal Rank)

\`\`\`python
def mrr(queries_results: list[tuple[set, list]]) -> float:
    """
    ì²« ë²ˆì§¸ ê´€ë ¨ ë¬¸ì„œì˜ ì—­ìˆœìœ„ í‰ê· 

    MRR = (1/N) Ã— Î£ (1/rank_i)
    """
    reciprocal_ranks = []

    for relevant, retrieved in queries_results:
        for rank, doc in enumerate(retrieved, 1):
            if doc in relevant:
                reciprocal_ranks.append(1 / rank)
                break
        else:
            reciprocal_ranks.append(0)

    return sum(reciprocal_ranks) / len(reciprocal_ranks)

# ì˜ˆì‹œ
queries = [
    ({"doc3"}, ["doc1", "doc2", "doc3"]),  # 1/3
    ({"doc1"}, ["doc1", "doc2"]),          # 1/1
    ({"doc5"}, ["doc1", "doc2", "doc3"]),  # 0 (ëª» ì°¾ìŒ)
]
print(f"MRR: {mrr(queries)}")  # 0.44
\`\`\`

---

## ìƒì„± í’ˆì§ˆ í‰ê°€ ì§€í‘œ

### 1. Faithfulness (ì¶©ì‹¤ë„)

\`\`\`
ì •ì˜: ìƒì„±ëœ ë‹µë³€ì´ ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ì— ê·¼ê±°í•˜ëŠ”ì§€

ì¸¡ì • ë°©ë²• (LLM-as-Judge):
  í”„ë¡¬í”„íŠ¸: "ë‹¤ìŒ ë‹µë³€ì˜ ê° ì£¼ì¥ì´ ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì§€ì§€ë˜ëŠ”ì§€ í‰ê°€í•˜ì„¸ìš”"

  ì»¨í…ìŠ¤íŠ¸: "RAGëŠ” 2020ë…„ Meta AIì—ì„œ ë°œí‘œë˜ì—ˆìŠµë‹ˆë‹¤."
  ë‹µë³€: "RAGëŠ” 2020ë…„ì— Googleì´ ë°œí‘œí–ˆìŠµë‹ˆë‹¤."

  í‰ê°€: "RAG ë°œí‘œ ì‹œê¸°ëŠ” ë§ì§€ë§Œ, ë°œí‘œ ì£¼ì²´ê°€ í‹€ë¦¼ â†’ Faithfulness: 0.5"

ì ìˆ˜: 0.0 ~ 1.0 (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)
\`\`\`

### 2. Answer Relevance (ë‹µë³€ ê´€ë ¨ì„±)

\`\`\`
ì •ì˜: ë‹µë³€ì´ ì§ˆë¬¸ì— ì ì ˆíˆ ëŒ€ì‘í•˜ëŠ”ì§€

ì¸¡ì • ë°©ë²•:
  ì§ˆë¬¸: "RAGì˜ ì¥ì ì€?"
  ë‹µë³€: "RAGëŠ” 2020ë…„ì— ë°œí‘œë˜ì—ˆìŠµë‹ˆë‹¤." â† ê´€ë ¨ ì—†ìŒ!

  ì˜¬ë°”ë¥¸ ë‹µë³€: "RAGì˜ ì¥ì ì€ í™˜ê° ê°ì†Œ, ìµœì‹  ì •ë³´ í™œìš©..." â† ê´€ë ¨ ìˆìŒ

ë°©ë²• 1: LLM-as-Judge
ë°©ë²• 2: ë‹µë³€ì—ì„œ ì§ˆë¬¸ ì¬ìƒì„± â†’ ì›ë˜ ì§ˆë¬¸ê³¼ ìœ ì‚¬ë„ ì¸¡ì •
\`\`\`

### 3. Context Relevance (ì»¨í…ìŠ¤íŠ¸ ê´€ë ¨ì„±)

\`\`\`
ì •ì˜: ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ê°€ ì§ˆë¬¸ê³¼ ê´€ë ¨ ìˆëŠ”ì§€

ì¤‘ìš”ì„±:
  - ê´€ë ¨ ì—†ëŠ” ì»¨í…ìŠ¤íŠ¸ â†’ í† í° ë‚­ë¹„
  - ê´€ë ¨ ì—†ëŠ” ì»¨í…ìŠ¤íŠ¸ â†’ í™˜ê° ìœ ë°œ ê°€ëŠ¥
  - ê´€ë ¨ ì—†ëŠ” ì»¨í…ìŠ¤íŠ¸ â†’ ì‘ë‹µ í’ˆì§ˆ ì €í•˜

ì¸¡ì •:
  ì§ˆë¬¸: "RAGì˜ ê²€ìƒ‰ ë‹¨ê³„ëŠ”?"
  ì»¨í…ìŠ¤íŠ¸1: "RAGì˜ ê²€ìƒ‰ ë‹¨ê³„ëŠ” ì¿¼ë¦¬ ì„ë² ë”©..." â† ê´€ë ¨ ë†’ìŒ
  ì»¨í…ìŠ¤íŠ¸2: "ì˜¤ëŠ˜ ì„œìš¸ ë‚ ì”¨ëŠ” ë§‘ìŒ..." â† ê´€ë ¨ ì—†ìŒ

  Context Relevance = ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ / ì „ì²´ ì»¨í…ìŠ¤íŠ¸
\`\`\`

---

## RAGAS í”„ë ˆì„ì›Œí¬

\`\`\`python
# RAGAS: RAG Assessment í”„ë ˆì„ì›Œí¬
from ragas import evaluate
from ragas.metrics import (
    faithfulness,
    answer_relevancy,
    context_precision,
    context_recall
)
from datasets import Dataset

# í‰ê°€ ë°ì´í„° ì¤€ë¹„
data = {
    "question": ["RAGë€ ë¬´ì—‡ì¸ê°€?"],
    "answer": ["RAGëŠ” ê²€ìƒ‰ ì¦ê°• ìƒì„±ìœ¼ë¡œ..."],
    "contexts": [["RAGëŠ” Retrieval Augmented Generationì˜ ì•½ìë¡œ..."]],
    "ground_truth": ["RAGëŠ” ê²€ìƒ‰ê³¼ ìƒì„±ì„ ê²°í•©í•œ ê¸°ìˆ ì…ë‹ˆë‹¤."]
}

dataset = Dataset.from_dict(data)

# í‰ê°€ ì‹¤í–‰
result = evaluate(
    dataset,
    metrics=[
        faithfulness,
        answer_relevancy,
        context_precision,
        context_recall
    ]
)

print(result)
# {'faithfulness': 0.95, 'answer_relevancy': 0.88, ...}
\`\`\`

---

## ì‹¤ìš©ì ì¸ í‰ê°€ íŒŒì´í”„ë¼ì¸

\`\`\`python
from dataclasses import dataclass
from typing import Optional
import json

@dataclass
class EvaluationResult:
    """í‰ê°€ ê²°ê³¼"""
    query: str
    precision_at_5: float
    recall_at_5: float
    mrr: float
    faithfulness: float
    answer_relevance: float

class RAGEvaluator:
    """RAG ì‹œìŠ¤í…œ í‰ê°€ê¸°"""

    def __init__(self, rag_pipeline, llm_judge):
        self.rag = rag_pipeline
        self.judge = llm_judge

    def evaluate_retrieval(
        self,
        query: str,
        relevant_docs: set[str],
        k: int = 5
    ) -> dict:
        """ê²€ìƒ‰ í’ˆì§ˆ í‰ê°€"""
        results = self.rag.retrieve(query)
        retrieved_ids = [doc.metadata.get("id") for doc in results]

        return {
            "precision": precision_at_k(relevant_docs, retrieved_ids, k),
            "recall": recall_at_k(relevant_docs, retrieved_ids, k),
            "mrr": self._calculate_mrr(relevant_docs, retrieved_ids)
        }

    def evaluate_generation(
        self,
        query: str,
        answer: str,
        contexts: list[str]
    ) -> dict:
        """ìƒì„± í’ˆì§ˆ í‰ê°€ (LLM-as-Judge)"""

        # Faithfulness í‰ê°€
        faithfulness_prompt = f"""
        Context: {contexts}
        Answer: {answer}

        ìœ„ ë‹µë³€ì´ ì»¨í…ìŠ¤íŠ¸ì— ê·¼ê±°í•˜ëŠ”ì§€ 0-1 ì ìˆ˜ë¡œ í‰ê°€í•˜ì„¸ìš”.
        JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥: {{"score": 0.0-1.0, "reason": "..."}}
        """
        faithfulness_result = json.loads(self.judge.invoke(faithfulness_prompt))

        # Answer Relevance í‰ê°€
        relevance_prompt = f"""
        Question: {query}
        Answer: {answer}

        ë‹µë³€ì´ ì§ˆë¬¸ì— ì ì ˆí•œì§€ 0-1 ì ìˆ˜ë¡œ í‰ê°€í•˜ì„¸ìš”.
        JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥: {{"score": 0.0-1.0, "reason": "..."}}
        """
        relevance_result = json.loads(self.judge.invoke(relevance_prompt))

        return {
            "faithfulness": faithfulness_result["score"],
            "answer_relevance": relevance_result["score"]
        }

    def full_evaluation(
        self,
        test_cases: list[dict]
    ) -> list[EvaluationResult]:
        """ì „ì²´ í‰ê°€ ì‹¤í–‰"""
        results = []

        for case in test_cases:
            # RAG ì‹¤í–‰
            response = self.rag.invoke(case["query"])

            # ê²€ìƒ‰ í‰ê°€
            retrieval_scores = self.evaluate_retrieval(
                case["query"],
                set(case["relevant_doc_ids"])
            )

            # ìƒì„± í‰ê°€
            generation_scores = self.evaluate_generation(
                case["query"],
                response["answer"],
                response["contexts"]
            )

            results.append(EvaluationResult(
                query=case["query"],
                precision_at_5=retrieval_scores["precision"],
                recall_at_5=retrieval_scores["recall"],
                mrr=retrieval_scores["mrr"],
                faithfulness=generation_scores["faithfulness"],
                answer_relevance=generation_scores["answer_relevance"]
            ))

        return results
\`\`\`
      `,
      keyPoints: [
        'ê²€ìƒ‰ í‰ê°€: Precision@K, Recall@K, MRR',
        'ìƒì„± í‰ê°€: Faithfulness, Answer Relevance',
        'RAGAS í”„ë ˆì„ì›Œí¬ë¡œ ìë™í™”ëœ í‰ê°€',
      ],
      practiceGoal: 'RAG ì‹œìŠ¤í…œì˜ í‰ê°€ ì§€í‘œì™€ ì¸¡ì • ë°©ë²•ì„ ì´í•´í•œë‹¤',
    }),

    // ========================================
    // Task 6: Day 3 ì¢…í•© í€´ì¦ˆ (20ë¶„)
    // ========================================
    createQuizTask('w5d3-quiz', 'Day 3 ì¢…í•© í€´ì¦ˆ', 20, {
      introduction: `
## í€´ì¦ˆ ì•ˆë‚´

Day 3ì—ì„œ í•™ìŠµí•œ ì²­í‚¹ ì „ëµê³¼ ê²€ìƒ‰ ìµœì í™” ê°œë…ì„ í™•ì¸í•©ë‹ˆë‹¤.
ê° ë¬¸ì œë¥¼ ì‹ ì¤‘í•˜ê²Œ ì½ê³  ë‹µë³€í•´ì£¼ì„¸ìš”.
      `,
      questions: [
        {
          id: 'w5d3-q1',
          question: '"Lost in the Middle" í˜„ìƒì€ ë¬´ì—‡ì„ ì˜ë¯¸í•˜ë‚˜ìš”?',
          options: [
            'LLMì´ ê¸´ ì»¨í…ìŠ¤íŠ¸ì˜ ì¤‘ê°„ ë¶€ë¶„ ì •ë³´ë¥¼ ì˜ í™œìš©í•˜ì§€ ëª»í•˜ëŠ” í˜„ìƒ',
            'ì²­í‚¹ ì‹œ ë¬¸ì„œ ì¤‘ê°„ ë¶€ë¶„ì´ ëˆ„ë½ë˜ëŠ” í˜„ìƒ',
            'ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì¤‘ê°„ ìˆœìœ„ ë¬¸ì„œê°€ ë¬´ì‹œë˜ëŠ” í˜„ìƒ',
            'ì„ë² ë”© ì‹œ ì¤‘ê°„ ë‹¨ì–´ê°€ ì˜ í‘œí˜„ë˜ì§€ ì•ŠëŠ” í˜„ìƒ',
          ],
          correctAnswer: 0,
          explanation: '"Lost in the Middle"ì€ 2023ë…„ ìŠ¤íƒ í¬ë“œ ì—°êµ¬ì—ì„œ ë°œê²¬ëœ í˜„ìƒìœ¼ë¡œ, LLMì´ ì»¨í…ìŠ¤íŠ¸ì˜ ì²˜ìŒê³¼ ë ì •ë³´ëŠ” ì˜ í™œìš©í•˜ì§€ë§Œ ì¤‘ê°„ ë¶€ë¶„ì€ ë¬´ì‹œí•˜ëŠ” ê²½í–¥ì…ë‹ˆë‹¤.',
        },
        {
          id: 'w5d3-q2',
          question: 'RecursiveCharacterTextSplitterì˜ ì£¼ìš” íŠ¹ì§•ì€?',
          options: [
            'ê³ ì • í¬ê¸°ë¡œë§Œ ë¶„í• ',
            'ì—¬ëŸ¬ êµ¬ë¶„ìë¥¼ ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ìˆœì°¨ì ìœ¼ë¡œ ì‹œë„',
            'ì„ë² ë”© ìœ ì‚¬ë„ ê¸°ë°˜ ë¶„í• ',
            'ë§ˆí¬ë‹¤ìš´ í—¤ë” ê¸°ë°˜ ë¶„í• ',
          ],
          correctAnswer: 1,
          explanation: 'RecursiveCharacterTextSplitterëŠ” \\n\\n, \\n, ë§ˆì¹¨í‘œ, ê³µë°± ë“± ì—¬ëŸ¬ êµ¬ë¶„ìë¥¼ ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ì‹œë„í•˜ì—¬ ë¬¸ì„œ êµ¬ì¡°ë¥¼ ìµœëŒ€í•œ ë³´ì¡´í•©ë‹ˆë‹¤.',
        },
        {
          id: 'w5d3-q3',
          question: 'í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì˜ ê³µì‹ hybrid_score = Î± Ã— sparse_score + (1-Î±) Ã— dense_scoreì—ì„œ Î± = 0.7ì¼ ë•Œì˜ ì˜ë¯¸ëŠ”?',
          options: [
            'ì˜ë¯¸ ê²€ìƒ‰ 70%, í‚¤ì›Œë“œ ê²€ìƒ‰ 30%',
            'í‚¤ì›Œë“œ ê²€ìƒ‰ 70%, ì˜ë¯¸ ê²€ìƒ‰ 30%',
            'ë‘ ê²€ìƒ‰ ë°©ì‹ì´ ë™ì¼í•œ ë¹„ì¤‘',
            'Î± ê°’ì€ ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜ë¥¼ ì˜ë¯¸',
          ],
          correctAnswer: 1,
          explanation: 'Î± = 0.7ì€ sparse(í‚¤ì›Œë“œ) ê²€ìƒ‰ì— 70% ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•˜ê³ , dense(ì˜ë¯¸) ê²€ìƒ‰ì— 30% ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•©ë‹ˆë‹¤. ì „ë¬¸ ìš©ì–´ê°€ ë§ì€ ë„ë©”ì¸ì—ì„œ ìœ ìš©í•©ë‹ˆë‹¤.',
        },
        {
          id: 'w5d3-q4',
          question: 'Re-rankingì—ì„œ Cross-Encoderê°€ Bi-Encoderë³´ë‹¤ ì •í™•í•œ ì´ìœ ëŠ”?',
          options: [
            'Cross-Encoderê°€ ë” í° ëª¨ë¸ì„ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸',
            'Cross-EncoderëŠ” ì¿¼ë¦¬ì™€ ë¬¸ì„œë¥¼ í•¨ê»˜ ì…ë ¥ë°›ì•„ ìƒí˜¸ì‘ìš©ì„ ê³ ë ¤í•˜ê¸° ë•Œë¬¸',
            'Cross-Encoderê°€ ë” ë§ì€ ë°ì´í„°ë¡œ í•™ìŠµë˜ì—ˆê¸° ë•Œë¬¸',
            'Cross-Encoderê°€ GPUë¥¼ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸',
          ],
          correctAnswer: 1,
          explanation: 'Cross-EncoderëŠ” ì¿¼ë¦¬ì™€ ë¬¸ì„œë¥¼ [CLS] ì¿¼ë¦¬ [SEP] ë¬¸ì„œ í˜•íƒœë¡œ í•¨ê»˜ ì…ë ¥ë°›ì•„ Transformerê°€ ì–‘ìª½ì„ ë™ì‹œì— ë³´ê³  ìƒí˜¸ì‘ìš©ì„ ê³ ë ¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Bi-EncoderëŠ” ê°ê° ë…ë¦½ì ìœ¼ë¡œ ì„ë² ë”©í•©ë‹ˆë‹¤.',
        },
        {
          id: 'w5d3-q5',
          question: 'RAG í‰ê°€ì—ì„œ Faithfulness ì§€í‘œëŠ” ë¬´ì—‡ì„ ì¸¡ì •í•˜ë‚˜ìš”?',
          options: [
            'ê²€ìƒ‰ëœ ë¬¸ì„œì˜ ê´€ë ¨ì„±',
            'ìƒì„±ëœ ë‹µë³€ì´ ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ì— ê·¼ê±°í•˜ëŠ” ì •ë„',
            'ë‹µë³€ì´ ì§ˆë¬¸ì— ì ì ˆíˆ ëŒ€ì‘í•˜ëŠ” ì •ë„',
            'ê²€ìƒ‰ ì†ë„ì™€ íš¨ìœ¨ì„±',
          ],
          correctAnswer: 1,
          explanation: 'Faithfulness(ì¶©ì‹¤ë„)ëŠ” ìƒì„±ëœ ë‹µë³€ì˜ ê° ì£¼ì¥ì´ ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì§€ì§€ë˜ëŠ”ì§€ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤. í™˜ê°(Hallucination) ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ëŠ” í•µì‹¬ ì§€í‘œì…ë‹ˆë‹¤.',
        },
      ],
      keyPoints: [
        'Lost in the Middle: LLMì€ ì»¨í…ìŠ¤íŠ¸ ì¤‘ê°„ ì •ë³´ë¥¼ ì˜ í™œìš© ëª»í•¨',
        'RecursiveCharacterTextSplitter: ì—¬ëŸ¬ êµ¬ë¶„ì ìˆœì°¨ ì‹œë„',
        'Faithfulness: ë‹µë³€ì´ ì»¨í…ìŠ¤íŠ¸ì— ê·¼ê±°í•˜ëŠ” ì •ë„',
      ],
      practiceGoal: 'Day 3 í•µì‹¬ ê°œë…ì„ ì´í•´í–ˆëŠ”ì§€ í™•ì¸í•œë‹¤',
    }),

    // ========================================
    // Challenge: ì²­í‚¹ & ê²€ìƒ‰ ìµœì í™” ì‹œìŠ¤í…œ êµ¬ì¶• (60ë¶„)
    // ========================================
    createChallengeTask('w5d3-challenge', 'ì²­í‚¹ & ê²€ìƒ‰ ìµœì í™” ì‹œìŠ¤í…œ êµ¬ì¶•', 60, {
      introduction: `
## ì±Œë¦°ì§€ ì‹œë‚˜ë¦¬ì˜¤

ë‹¹ì‹ ì€ ë²•ë¥  ìŠ¤íƒ€íŠ¸ì—…ì˜ AI ì—”ì§€ë‹ˆì–´ì…ë‹ˆë‹¤. íšŒì‚¬ëŠ” ë²•ë¥  ë¬¸ì„œ Q&A ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ë ¤ í•˜ëŠ”ë°,
ë²•ë¥  ë¬¸ì„œì˜ íŠ¹ì„±ìƒ ì •í™•í•œ ê²€ìƒ‰ê³¼ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë‹µë³€ì´ ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤.

**ìš”êµ¬ì‚¬í•­:**
1. ë²•ë¥  ë¬¸ì„œì— ìµœì í™”ëœ ì²­í‚¹ ì „ëµ ì„¤ê³„
2. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ + Re-ranking íŒŒì´í”„ë¼ì¸ êµ¬ì¶•
3. ê²€ìƒ‰ í’ˆì§ˆ í‰ê°€ ì‹œìŠ¤í…œ êµ¬í˜„
4. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ë° ìµœì í™”

---

## í‰ê°€ ê¸°ì¤€

| í•­ëª© | ë°°ì  | ê¸°ì¤€ |
|------|------|------|
| ì²­í‚¹ ì „ëµ | 25ì  | ë²•ë¥  ë¬¸ì„œì— ìµœì í™”ëœ ì „ëµ |
| ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸ | 25ì  | í•˜ì´ë¸Œë¦¬ë“œ + Re-ranking |
| í‰ê°€ ì‹œìŠ¤í…œ | 25ì  | Precision, Recall, MRR ì¸¡ì • |
| ìµœì í™” ë° ë¶„ì„ | 25ì  | ì„±ëŠ¥ ê°œì„  ë° ê²°ê³¼ ë¶„ì„ |

---

## í…ŒìŠ¤íŠ¸ ë°ì´í„°

\`\`\`python
# ë²•ë¥  ë¬¸ì„œ ìƒ˜í”Œ
LEGAL_DOCUMENTS = [
    {
        "id": "law001",
        "title": "ê°œì¸ì •ë³´ ë³´í˜¸ë²• ì œ1ì¡°",
        "content": """
        ì œ1ì¡°(ëª©ì ) ì´ ë²•ì€ ê°œì¸ì •ë³´ì˜ ì²˜ë¦¬ ë° ë³´í˜¸ì— ê´€í•œ ì‚¬í•­ì„ ì •í•¨ìœ¼ë¡œì¨
        ê°œì¸ì˜ ììœ ì™€ ê¶Œë¦¬ë¥¼ ë³´í˜¸í•˜ê³ , ë‚˜ì•„ê°€ ê°œì¸ì˜ ì¡´ì—„ê³¼ ê°€ì¹˜ë¥¼ êµ¬í˜„í•¨ì„
        ëª©ì ìœ¼ë¡œ í•œë‹¤.
        """
    },
    {
        "id": "law002",
        "title": "ê°œì¸ì •ë³´ ë³´í˜¸ë²• ì œ2ì¡°",
        "content": """
        ì œ2ì¡°(ì •ì˜) ì´ ë²•ì—ì„œ ì‚¬ìš©í•˜ëŠ” ìš©ì–´ì˜ ëœ»ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.
        1. "ê°œì¸ì •ë³´"ë€ ì‚´ì•„ ìˆëŠ” ê°œì¸ì— ê´€í•œ ì •ë³´ë¡œì„œ ë‹¤ìŒ ê° ëª©ì˜ ì–´ëŠ
           í•˜ë‚˜ì— í•´ë‹¹í•˜ëŠ” ì •ë³´ë¥¼ ë§í•œë‹¤.
        ê°€. ì„±ëª…, ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸ ë° ì˜ìƒ ë“±ì„ í†µí•˜ì—¬ ê°œì¸ì„ ì•Œì•„ë³¼ ìˆ˜ ìˆëŠ” ì •ë³´
        ë‚˜. í•´ë‹¹ ì •ë³´ë§Œìœ¼ë¡œëŠ” íŠ¹ì • ê°œì¸ì„ ì•Œì•„ë³¼ ìˆ˜ ì—†ë”ë¼ë„ ë‹¤ë¥¸ ì •ë³´ì™€
            ì‰½ê²Œ ê²°í•©í•˜ì—¬ ì•Œì•„ë³¼ ìˆ˜ ìˆëŠ” ì •ë³´
        """
    },
    # ... ë” ë§ì€ ë²•ë¥  ë¬¸ì„œ
]

# í‰ê°€ìš© í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤
TEST_CASES = [
    {
        "query": "ê°œì¸ì •ë³´ ë³´í˜¸ë²•ì˜ ëª©ì ì€?",
        "relevant_doc_ids": ["law001"],
        "expected_answer_contains": ["ê°œì¸ì˜ ììœ ì™€ ê¶Œë¦¬", "ì¡´ì—„ê³¼ ê°€ì¹˜"]
    },
    {
        "query": "ê°œì¸ì •ë³´ì˜ ë²•ì  ì •ì˜ëŠ”?",
        "relevant_doc_ids": ["law002"],
        "expected_answer_contains": ["ì‚´ì•„ ìˆëŠ” ê°œì¸", "ì„±ëª…", "ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸"]
    }
]
\`\`\`
      `,
      keyPoints: [
        'ë²•ë¥  ë¬¸ì„œ íŠ¹ì„±ì— ë§ëŠ” ì²­í‚¹ ì „ëµ êµ¬í˜„ (ì¡°í•­ ë‹¨ìœ„ ë³´ì¡´)',
        'í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (BM25 + ë²¡í„°) + Re-ranking íŒŒì´í”„ë¼ì¸',
        'Precision@K, Recall@K, MRR ìë™ ì¸¡ì • ì‹œìŠ¤í…œ',
        'ìµœì†Œ 3ê°€ì§€ ì„¤ì • ë¹„êµ ë° ìµœì  íŒŒë¼ë¯¸í„° ë„ì¶œ',
      ],
      hints: [
        '**ë²•ë¥  ë¬¸ì„œ ì²­í‚¹**: "ì œXì¡°", "í•­", "í˜¸" íŒ¨í„´ìœ¼ë¡œ ë¶„í• , ì¡°í•­ ë‹¨ìœ„ ë³´ì¡´ì´ í•µì‹¬',
        '**í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰**: BM25 + Vector ê²°í•© (ê°€ì¤‘ì¹˜ 0.5:0.5 ì‹œì‘), Re-rankingìœ¼ë¡œ ì •ë°€ë„ í–¥ìƒ',
        '**í‰ê°€ ì§€í‘œ**: Precision@5, Recall@5, MRR ê³„ì‚°í•˜ì—¬ ì„¤ì •ë³„ ë¹„êµ',
        '**ìµœì í™”**: ê°€ì¤‘ ì ìˆ˜(Precision 0.4 + Recall 0.3 + MRR 0.3)ë¡œ ìµœì  ì„¤ì • ë„ì¶œ',
      ],
    }),
  ],
}
